{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Header and SoilPrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Header.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb \n",
    "from Header import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from SoilPrep.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from SoilPrep import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data and MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from LoadDataMetaData.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from LoadDataMetaData import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed One Time Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_locs = [ '443', '490', '560', '665', '705', '740', '783', '842', '865', '940', '1375', '1610', '2190']\n",
    "band_widths = [ 21, 65, 36, 31, 14, 14, 20, 106, 21, 20, 31, 91, 176]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_at (spectrum, mid_locs, band_widths):\n",
    "    \n",
    "    #----- obtaining the sampling ilocations in indx----\n",
    "    mid_ilocs = []\n",
    "    for l in mid_locs:\n",
    "        #print(l)\n",
    "        i = spectrum.columns.get_loc(l)\n",
    "        mid_ilocs.append(i)\n",
    "    \n",
    "    #print(mid_ilocs)\n",
    "    #print(mid_ilocs)\n",
    "    #print(mid_locs)   \n",
    "    \n",
    "    #----- finding initial shape for red_spectra ------\n",
    "    red_spectra = spectrum.iloc[:, mid_ilocs].copy()\n",
    "    #print(red_spectra.head(5))\n",
    "    #print(len(mid_ilocs))\n",
    "    \n",
    "    for i in range(0, len(mid_ilocs)):\n",
    "        m = mid_ilocs[i]\n",
    "        l = mid_locs[i]\n",
    "        window = np.floor(0.5*band_widths[i]).astype(int)\n",
    "        #print('m: ', m, 'window:', window)\n",
    "        red_spectra.loc[:,l] = spectrum.iloc[:,(m-window):(m+window)].mean(axis=1).copy()\n",
    "        \n",
    "    return (red_spectra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>493</th>\n",
       "      <th>560</th>\n",
       "      <th>665</th>\n",
       "      <th>704</th>\n",
       "      <th>741</th>\n",
       "      <th>783</th>\n",
       "      <th>833</th>\n",
       "      <th>865</th>\n",
       "      <th>1614</th>\n",
       "      <th>2202</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.072686</td>\n",
       "      <td>0.121744</td>\n",
       "      <td>0.218400</td>\n",
       "      <td>0.247286</td>\n",
       "      <td>0.273071</td>\n",
       "      <td>0.293889</td>\n",
       "      <td>0.307471</td>\n",
       "      <td>0.31500</td>\n",
       "      <td>0.453300</td>\n",
       "      <td>0.444471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.076575</td>\n",
       "      <td>0.131882</td>\n",
       "      <td>0.234600</td>\n",
       "      <td>0.265571</td>\n",
       "      <td>0.293643</td>\n",
       "      <td>0.316556</td>\n",
       "      <td>0.331288</td>\n",
       "      <td>0.33915</td>\n",
       "      <td>0.490300</td>\n",
       "      <td>0.483753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.056931</td>\n",
       "      <td>0.100550</td>\n",
       "      <td>0.233533</td>\n",
       "      <td>0.266429</td>\n",
       "      <td>0.292500</td>\n",
       "      <td>0.303889</td>\n",
       "      <td>0.301779</td>\n",
       "      <td>0.30000</td>\n",
       "      <td>0.389411</td>\n",
       "      <td>0.351724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.065127</td>\n",
       "      <td>0.107206</td>\n",
       "      <td>0.195933</td>\n",
       "      <td>0.222857</td>\n",
       "      <td>0.247000</td>\n",
       "      <td>0.266389</td>\n",
       "      <td>0.278673</td>\n",
       "      <td>0.28530</td>\n",
       "      <td>0.378478</td>\n",
       "      <td>0.368224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.078336</td>\n",
       "      <td>0.129471</td>\n",
       "      <td>0.200933</td>\n",
       "      <td>0.216571</td>\n",
       "      <td>0.229643</td>\n",
       "      <td>0.235889</td>\n",
       "      <td>0.232952</td>\n",
       "      <td>0.23030</td>\n",
       "      <td>0.238444</td>\n",
       "      <td>0.229741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        493       560       665       704       741       783       833  \\\n",
       "0  0.072686  0.121744  0.218400  0.247286  0.273071  0.293889  0.307471   \n",
       "1  0.076575  0.131882  0.234600  0.265571  0.293643  0.316556  0.331288   \n",
       "2  0.056931  0.100550  0.233533  0.266429  0.292500  0.303889  0.301779   \n",
       "3  0.065127  0.107206  0.195933  0.222857  0.247000  0.266389  0.278673   \n",
       "4  0.078336  0.129471  0.200933  0.216571  0.229643  0.235889  0.232952   \n",
       "\n",
       "       865      1614      2202  \n",
       "0  0.31500  0.453300  0.444471  \n",
       "1  0.33915  0.490300  0.483753  \n",
       "2  0.30000  0.389411  0.351724  \n",
       "3  0.28530  0.378478  0.368224  \n",
       "4  0.23030  0.238444  0.229741  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_spec12 = resample_at (spec2[51], mid_locs, band_widths)\n",
    "sampled_spec12.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_cr12 = resample_at (cr_spec, mid_locs, band_widths)\n",
    "#sampled_cr10.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_log12 = resample_at(log_spec, mid_locs, band_widths)\n",
    "#sampled_log10.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fod_sampled12 = fod (sampled_spec12)\n",
    "#fod_sampled10.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fod_cr12 = fod (sampled_cr12)\n",
    "#fod_cr10.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fod_log12 = fod (sampled_log12)\n",
    "#fod_log10.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('say \"your Meta Tree started building\"')\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare_spec = ['none', 'fod2', 'continuum', 'log']\n",
    "# prepare_target = ['none', 'minmax']\n",
    "\n",
    "def find_X(p):\n",
    "    if p == 'fod':\n",
    "        X = fod_sampled12\n",
    "    elif p == 'cr':\n",
    "        X = sampled_cr12\n",
    "    elif p == 'log':\n",
    "        X = sampled_log12\n",
    "    elif p == 'none':\n",
    "        X = sampled_spec12\n",
    "    elif p == 'fod_cr':\n",
    "        X = fod_cr12\n",
    "    else:\n",
    "        X = fod_log12\n",
    "    return X\n",
    "\n",
    "def find_spec(p, m):    \n",
    "    spec = find_X(p)\n",
    "    return spec    \n",
    "\n",
    "\n",
    "def find_y(t):\n",
    "    i = target_names.index(t) \n",
    "    y = T[i]\n",
    "    return y\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recording Hypertuning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, r2_score\n",
    "\n",
    "model ={}\n",
    "param_grid ={}\n",
    "model['mult'] = LinearRegression()\n",
    "param_grid['mult'] = { 'fit_intercept': [True, False] }\n",
    "\n",
    "model['ridge'] = KernelRidge()\n",
    "param_grid['ridge']={'alpha': [ 0.00001,0.00002, 0.00005, 0.0001, 0.0002, 0.0005, 0.001, 0.002, \\\n",
    "                               0.005,  0.01, 0.05, 0.1, 0.5, 1]}\n",
    "\n",
    "model['plsr'] = PLSRegression()\n",
    "param_grid['plsr']={'n_components': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "\n",
    "\n",
    "model['cubist'] = Cubist(random_state = 42)  \n",
    "param_grid['cubist'] = { 'n_committees': [5, 10, 15, 20], 'n_rules': [10, 20, 30, 40, 50] }\n",
    "                        \n",
    "\n",
    "model['gbrt'] = GradientBoostingRegressor(random_state = 42)\n",
    "param_grid['gbrt'] = {\n",
    "    'n_estimators': [20,30,40,50],        # Number of boosting stages to be used\n",
    "    'learning_rate': [0.01, 0.1],     # Step size shrinkage used in updating weights\n",
    "    'max_depth': [3, 4, 5]                # Maximum depth of individual trees\n",
    "#     'min_samples_split': [2, 3],        # Minimum number of samples required to split an internal node\n",
    "#     'min_samples_leaf': [1, 2],         # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "model['svr'] = SVR()\n",
    "param_grid['svr'] = {\n",
    "    'C': [0.1, 1, 10],              # Regularization parameter\n",
    "    'kernel': ['linear', 'rbf'],   # Kernel function\n",
    "    'gamma': [0.01, 0.1, 1],      # Kernel coefficient (only for 'rbf' kernel)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Hypertuned Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_core_model_param_on (m, t, p, tp, n):\n",
    "#     Model = model[m]\n",
    "#     X = find_spec(p,n,m)\n",
    "#     y = find_y(t, tp)\n",
    "    \n",
    "#     row, col = X.shape\n",
    "\n",
    "#     scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "#     cv = RepeatedKFold(n_splits=row, n_repeats=1, random_state=3)\n",
    "        \n",
    "#     grid_search = GridSearchCV(Model, param_grid=param_grid[m], cv=cv,\\\n",
    "#                                 scoring= scorer, refit=True, verbose=1, error_score='raise', n_jobs=-1)\n",
    "#     grid_search.fit(X,y)\n",
    "    \n",
    "#     return (grid_search.best_params_)\n",
    "\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "\n",
    "def find_tuned_param_on (X_train, y_train, m):\n",
    "    Model = model[m]\n",
    "    X = X_train\n",
    "    y = y_train\n",
    "    \n",
    "    row, col = X.shape\n",
    "    \n",
    "    scorer = 'r2'\n",
    "    cv = RepeatedKFold(n_splits=5, n_repeats=10, random_state=3)\n",
    "        \n",
    "    grid_search = GridSearchCV(Model, param_grid=param_grid[m], cv=cv,\n",
    "                               scoring=scorer, refit=True, verbose=1, \n",
    "                               error_score='raise', n_jobs=-1, return_train_score=True)\n",
    "\n",
    "#     scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "#     cv = RepeatedKFold(n_splits=5, n_repeats=10, random_state=3)\n",
    "        \n",
    "#     grid_search = GridSearchCV(Model, param_grid=param_grid[m], cv=cv,\\\n",
    "#                                 scoring= scorer, refit=True, verbose=1, error_score='raise', n_jobs=-1, return_train_score=True)\n",
    "    \n",
    "    grid_search.fit(X,y)\n",
    "    \n",
    "    # Best parameters\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Best test score\n",
    "    best_index = grid_search.best_index_\n",
    "    best_test_score = grid_search.cv_results_['mean_test_score'][best_index]\n",
    "\n",
    "    # Best train score\n",
    "    best_train_score = grid_search.cv_results_['mean_train_score'][best_index]\n",
    "    \n",
    "    return (best_params, best_test_score, best_train_score)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Hypertuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_core_model_on (m, BP):\n",
    "    if m == 'mult':\n",
    "        Model = LinearRegression()\n",
    "        \n",
    "    elif m == 'ridge':\n",
    "        Model =  KernelRidge(alpha = BP['alpha'])\n",
    "        \n",
    "    elif m == 'plsr':\n",
    "        Model = PLSRegression(n_components = BP['n_components'])\n",
    "        \n",
    "    elif m == 'cubist':\n",
    "        Model =  Cubist( n_committees = BP['n_committees'], n_rules = BP['n_rules'], random_state = 42) \n",
    "    \n",
    "    elif m == 'gbrt':\n",
    "        Model = GradientBoostingRegressor(n_estimators = BP['n_estimators'], learning_rate = BP['learning_rate'], \\\n",
    "                                          max_depth = BP['max_depth'],  random_state = 42)\n",
    "    elif m == 'svr':\n",
    "        Model = SVR(C = BP['C'], kernel = BP['kernel'], gamma = BP['gamma'])\n",
    "        \n",
    "    return Model    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building HMtree and BPtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ml_methods = ['mult', 'ridge', 'plsr', 'svr', 'cubist', 'gbrt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L1_y_pred (spectra, target, method, bp):\n",
    "    m = method\n",
    "    (r,c) = spectra.shape\n",
    "    \n",
    "    Y_test = target.copy()\n",
    "    Y_pred = target.copy()\n",
    "    #print('r:', r)\n",
    "    for i in range (0, r): \n",
    "        #print('i: ', i)\n",
    "        full_spec = spectra.copy()\n",
    "        X_train = full_spec.drop(full_spec.index[i], axis=0)\n",
    "        X_test = full_spec.iloc[[i],:].copy()\n",
    "        full_tar = target.copy()\n",
    "        y_train = full_tar.drop(full_tar.index[i], axis=0)\n",
    "        y_test = full_tar.iloc[i].copy()        \n",
    "        #---- Model Creation, fitting, and predictions--------\n",
    "        Model = create_core_model_on (m, bp)\n",
    "        Model.fit(X_train, y_train)\n",
    "        y_pred = Model.predict(X_test)\n",
    "        Y_pred.iloc[i] = y_pred\n",
    "        \n",
    "    return Y_pred      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_HMtree_on (target, method_name):\n",
    "    \n",
    "    tree ={}\n",
    "    \n",
    "    start = time.time()\n",
    "    m = method_name\n",
    "    t = target\n",
    "    \n",
    "    #print('tree for: '+ m +' ------> running on: ' + t)\n",
    "    \n",
    "    for tp in prepare_target:\n",
    "        tree[tp] ={}        \n",
    "        for p in prepare_spec:\n",
    "            tree[tp][p] ={}            \n",
    "            for n in nbands_sampling:\n",
    "                tree[tp][p][n] ={}\n",
    "                Y = tree[tp][p][n]\n",
    "                                           \n",
    "                #------ setting spec to appropriate (sampled) spectra----                \n",
    "                spec = find_spec(p, n)                \n",
    "                                        \n",
    "                #---- target selection and normalization ---\n",
    "                y = find_y(t)\n",
    "                                \n",
    "                #---- performing train-test split----------------------\n",
    "                X_train, X_test, y_train, y_test = train_test_split(spec, y, test_size= 0.2, random_state=42)\n",
    "                            \n",
    "                #----- hypertuning parameter, model creation, fitting and prediction ----                \n",
    "                \n",
    "                #bp = find_tuned_param_on (X_train, y_train, m)\n",
    "                bp, best_test_score, best_train_score = find_tuned_param_on (spec, y, m)\n",
    "                \n",
    "                Y['bp'] = bp\n",
    "                print('Hypertuned on Target: '+ t+ '----> Method: '+ m + '--->  SpecProc: ' +p+ ' ---> n_band: ', n)\n",
    "                Model = create_core_model_on (m, bp)\n",
    "                Model.fit(X_train, y_train)\n",
    "                \n",
    "                y_pred = Model.predict(X_test)\n",
    "                yhat_pred = Model.predict(X_train)\n",
    "                    \n",
    "                #----- Data for Model accuracy and plotting -----------\n",
    "                Y['X_test'] = X_test                \n",
    "                Y['y_test'] = y_test\n",
    "                Y['y_testP'] = y_pred\n",
    "                \n",
    "                Y['X_train'] = X_train\n",
    "                Y['y_train'] = y_train\n",
    "                Y['y_trainP'] = yhat_pred\n",
    "\n",
    "                Y['r2_test'] = best_test_score\n",
    "                \n",
    "                Y['r2_train'] = best_train_score\n",
    "                \n",
    "                #------- L1 out prediction on test data -----------------\n",
    "                L1y_pred = L1_y_pred (spec, y, m, bp)\n",
    "                Y['L1y_testP'] = L1y_pred\n",
    "                Y['L1y_test'] = y\n",
    "                 \n",
    "                \n",
    "                Y['L1iqrp_test'] = find_iqrp(L1y_pred, y)\n",
    "                Y['L1r2_test'] = find_r2(L1y_pred, y)\n",
    "                Y['L1rpd_test'] = find_rpd(L1y_pred, y) \n",
    "                \n",
    "                                                                         \n",
    "    end = time.time()                            \n",
    "    os.system('say \"your hyper tuned meta tree finished for one more method\"')                            \n",
    "\n",
    "    print('End time - Start time =', (end-start)) \n",
    "    \n",
    "    return tree.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_HMtree_for (target_name):\n",
    "    tree ={}\n",
    "    \n",
    "    start = time.time()\n",
    "    t = target_name\n",
    "    for m in ml_methods:\n",
    "        print('tree for: '+ t +' ------> running on: ' + m)\n",
    "        tree[m] = build_HMtree_on (t, m)\n",
    "        os.system('say \"your meta tree finished for one more method\"')\n",
    "        \n",
    "    end = time.time()                            \n",
    "                                \n",
    "    print('End time - Start time =', (end-start))     \n",
    "    return tree.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build_HMtree_for('TOC')\n",
    "\n",
    "def BuildStore_HMtree_for (target_name, hmtree):\n",
    "    \n",
    "    start = time.time()\n",
    "    t = target_name\n",
    "    hmtree[t] ={}\n",
    "    \n",
    "    for m in ml_methods:\n",
    "        print('tree for: '+ t +' ------> running on: ' + m)\n",
    "        hmtree[t][m] = build_HMtree_on (t, m)\n",
    "        os.system('say \"your meta tree finished for one more method\"')\n",
    "        with open (f'HMtree_{m}.pickle', 'wb') as file:\n",
    "            pickle.dump(hmtree[t][m], file)\n",
    "        \n",
    "    end = time.time()                            \n",
    "    with open ('HMtree.pickle', 'wb') as file:\n",
    "            pickle.dump(hmtree, file)                            \n",
    "    print('End time - Start time =', (end-start))     \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_score_on (HMtree, target, method, scorer):\n",
    "    t=target\n",
    "    m= method\n",
    "    \n",
    "    best_score = -1\n",
    "    best_tp = None\n",
    "    best_n = None\n",
    "    best_p = None\n",
    "    \n",
    "    for tp in prepare_target:\n",
    "        for p in prepare_spec:\n",
    "            for n in nbands_sampling:\n",
    "                Y = HMtree[t][m][tp][p][n]\n",
    "                \n",
    "                if scorer == 'r2':\n",
    "                    cur_score = Y['r2_test'] \n",
    "                else:\n",
    "                    cur_score = Y['L1r2_test']    \n",
    "                    \n",
    "                if cur_score > best_score:\n",
    "                    best_score = cur_score\n",
    "                    best_tp = tp\n",
    "                    best_n = n\n",
    "                    best_p = p\n",
    "                            \n",
    "    param_list = [scorer, np.round(best_score,2), 'Spec:', best_p, 'bands:', best_n]                                 \n",
    "    return (param_list)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_score_for (HMtree, target, scorer):\n",
    "    \n",
    "    for method in ml_methods:\n",
    "        param_list= best_score_on (HMtree, target, method, scorer)\n",
    "        print('For:'+target+'->', param_list, ':'+method)\n",
    "     \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open ('HMtree.pickle', 'rb') as file:\n",
    "#     HMtree = pickle.load(file)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating different branches of Mtree (for separate methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "HMtree = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BuildStore_HMtree_for('Sand', HMtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HMtree['mult'] = build_HMtree_for('mult')\n",
    "# HMtree['plsr'] = build_HMtree_for('plsr')\n",
    "# HMtree['svr'] = build_HMtree_for('svr')\n",
    "# HMtree['ridge'] = build_HMtree_for('ridge')\n",
    "# HMtree['cubist'] = build_HMtree_for('cubist')\n",
    "# HMtree['gbrt'] = build_HMtree_for('gbrt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open ('HMtree.pickle', 'wb') as file:\n",
    "#     pickle.dump(HMtree, file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_acc_half (method, target, spec_preprocessing):\n",
    "    \n",
    "    m = method\n",
    "    t = target\n",
    "    \n",
    "    i = target_names.index(target)    \n",
    "    \n",
    "    p = spec_preprocessing\n",
    "    #n = n_bands\n",
    "    tp = 'none'\n",
    "    \n",
    "    Y = HMtree[m][t][tp][p]\n",
    "    \n",
    "    y_test = Y['y_test']\n",
    "    y_pred = Y['y_testP']\n",
    "    L1y_pred = Y['L1y_testP']\n",
    "    L1y_test = Y['L1y_test']\n",
    "    \n",
    "\n",
    "    \n",
    "    if m == 'plsr':\n",
    "        y_pred = y_pred[:,0]\n",
    "        #L1y_pred = L1y_pred[:,0]\n",
    "\n",
    "    \n",
    "    iqrp_test = Y['iqrp_test']\n",
    "    r2_test = Y['r2_test']\n",
    "    rpd_test = Y['rpd_test']\n",
    "    \n",
    "    L1iqrp_test = Y['L1iqrp_test']\n",
    "    L1r2_test = Y['L1r2_test']\n",
    "    L1rpd_test = Y['L1rpd_test']\n",
    "    \n",
    "    y_tp = pd.DataFrame({'actual':y_test.values, 'predic': y_pred})\n",
    "    z = np.polyfit(y_test, y_pred, 1)\n",
    "    \n",
    "    L1y_tp = pd.DataFrame({'actual':L1y_test.values, 'predic': L1y_pred})\n",
    "    L1z = np.polyfit(L1y_test, L1y_pred, 1)\n",
    "    \n",
    "    fig, (axes1,axes2) = plt.subplots(1,2, figsize=(10,5))\n",
    "    plt. grid(False)\n",
    "    \n",
    "    #with plt.style.context(('ggplot')): ---- PLOT of test-prediction --------------------------------------\n",
    "    y_tp.plot.scatter(ax= axes1, x=\"actual\", y=\"predic\", alpha=1.0, color = clr[i], edgecolors='k')\n",
    "    axes1.plot(y_test, np.polyval(z, y_test),  c='blue', linewidth=1)\n",
    "    axes1.plot(y_test, y_test, color='green', linewidth=1)\n",
    "    axes1.tick_params(axis='both', labelsize=10)\n",
    "    axes1.text(0.05, 0.95, target_names[i]+' (Train-Test Score)', transform=axes1.transAxes, fontsize = 14, color = clr[i])\n",
    "    axes1.text(0.05, 0.90, 'IQRP ={:.2f}'.format(iqrp_test), transform=axes1.transAxes, fontsize = 11)\n",
    "    axes1.text(0.05, 0.85, 'RPD ={:.2f}'.format(rpd_test), transform=axes1.transAxes, fontsize = 11)\n",
    "    axes1.text(0.05, 0.80, 'R2 ={:.2f}'.format(np.round(r2_test,3)), transform=axes1.transAxes, fontsize = 11)\n",
    "    axes1.text(0.95, 0.15, 'Method: '+method, transform=axes1.transAxes, \n",
    "                    horizontalalignment='right', fontsize = 12)\n",
    "    \n",
    "    L1y_tp.plot.scatter(ax= axes2, x=\"actual\", y=\"predic\", alpha=1.0, color = clr[i], edgecolors='k')\n",
    "    axes2.plot(L1y_test, np.polyval(L1z, L1y_test),  c='blue', linewidth=1)\n",
    "    axes2.plot(L1y_test, L1y_test, color='green', linewidth=1)\n",
    "    axes2.tick_params(axis='both', labelsize=10)\n",
    "    axes2.text(0.05, 0.95, target_names[i]+' (L1-out Score)', transform=axes2.transAxes, fontsize = 14, color = clr[i])\n",
    "    axes2.text(0.05, 0.90, 'IQRP ={:.2f}'.format(L1iqrp_test), transform=axes2.transAxes, fontsize = 11)\n",
    "    axes2.text(0.05, 0.85, 'RPD ={:.2f}'.format(L1rpd_test), transform=axes2.transAxes, fontsize = 11)\n",
    "    axes2.text(0.05, 0.80, 'R2 ={:.2f}'.format(np.round(L1r2_test,3)), transform=axes2.transAxes, fontsize = 11)\n",
    "    axes2.text(0.95, 0.15, 'Method: '+method, transform=axes2.transAxes, \n",
    "                    horizontalalignment='right', fontsize = 12)\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ml_methods = ['mult', 'ridge', 'plsr', 'svr', 'cubist', 'gbrt']\n",
    "\n",
    "#ml_methods = ['mult', 'plsr', 'svr', 'ridge', 'cubist','gbrt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score_for (HMtree, 'Sand', 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For:Sand-> ['L1r2', 0.49, 'Spec:', 'fod', 'bands: 10'] :mult\n",
      "For:Sand-> ['L1r2', 0.5, 'Spec:', 'fod', 'bands: 10'] :plsr\n",
      "For:Sand-> ['L1r2', 0.42, 'Spec:', 'log', 'bands: 10'] :svr\n",
      "For:Sand-> ['L1r2', 0.45, 'Spec:', 'none', 'bands: 10'] :ridge\n",
      "For:Sand-> ['L1r2', 0.6, 'Spec:', 'fod_log', 'bands: 10'] :cubist\n",
      "For:Sand-> ['L1r2', 0.56, 'Spec:', 'fod_log', 'bands: 10'] :gbrt\n"
     ]
    }
   ],
   "source": [
    "best_score_for (HMtree, 'Sand', 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score_for (HMtree, 'Silt', 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For:Silt-> ['L1r2', 0.28, 'Spec:', 'fod', 'bands: 10'] :mult\n",
      "For:Silt-> ['L1r2', 0.32, 'Spec:', 'fod', 'bands: 10'] :plsr\n",
      "For:Silt-> ['L1r2', 0.27, 'Spec:', 'fod_log', 'bands: 10'] :svr\n",
      "For:Silt-> ['L1r2', 0.27, 'Spec:', 'fod', 'bands: 10'] :ridge\n",
      "For:Silt-> ['L1r2', 0.29, 'Spec:', 'fod', 'bands: 10'] :cubist\n",
      "For:Silt-> ['L1r2', 0.41, 'Spec:', 'fod', 'bands: 10'] :gbrt\n"
     ]
    }
   ],
   "source": [
    "best_score_for (HMtree, 'Sand', 'L1r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score_for (HMtree, 'Clay', 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For:Clay-> ['L1r2', 0.56, 'Spec:', 'fod', 'bands: 10'] :mult\n",
      "For:Clay-> ['L1r2', 0.61, 'Spec:', 'log', 'bands: 10'] :plsr\n",
      "For:Clay-> ['L1r2', 0.51, 'Spec:', 'log', 'bands: 10'] :svr\n",
      "For:Clay-> ['L1r2', 0.58, 'Spec:', 'log', 'bands: 10'] :ridge\n",
      "For:Clay-> ['L1r2', 0.55, 'Spec:', 'fod', 'bands: 10'] :cubist\n",
      "For:Clay-> ['L1r2', 0.4, 'Spec:', 'fod_log', 'bands: 10'] :gbrt\n"
     ]
    }
   ],
   "source": [
    "best_score_for (HMtree, 'Clay', 'L1r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score_for (HMtree, 'TOC', 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For:TOC-> ['L1r2', 0.37, 'Spec:', 'log', 'bands: 10'] :mult\n",
      "For:TOC-> ['L1r2', 0.37, 'Spec:', 'log', 'bands: 10'] :plsr\n",
      "For:TOC-> ['L1r2', 0.37, 'Spec:', 'log', 'bands: 10'] :svr\n",
      "For:TOC-> ['L1r2', 0.38, 'Spec:', 'log', 'bands: 10'] :ridge\n",
      "For:TOC-> ['L1r2', 0.41, 'Spec:', 'log', 'bands: 10'] :cubist\n",
      "For:TOC-> ['L1r2', 0.49, 'Spec:', 'cr', 'bands: 10'] :gbrt\n"
     ]
    }
   ],
   "source": [
    "best_score_for (HMtree, 'TOC', 'L1r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score_for (HMtree, 'CaCO3', 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For:CaCO3-> ['L1r2', 0.63, 'Spec:', 'none', 'bands: 10'] :mult\n",
      "For:CaCO3-> ['L1r2', 0.63, 'Spec:', 'none', 'bands: 10'] :plsr\n",
      "For:CaCO3-> ['L1r2', 0.41, 'Spec:', 'log', 'bands: 10'] :svr\n",
      "For:CaCO3-> ['L1r2', 0.6, 'Spec:', 'fod', 'bands: 10'] :ridge\n",
      "For:CaCO3-> ['L1r2', 0.63, 'Spec:', 'fod', 'bands: 10'] :cubist\n",
      "For:CaCO3-> ['L1r2', 0.48, 'Spec:', 'fod_log', 'bands: 10'] :gbrt\n"
     ]
    }
   ],
   "source": [
    "best_score_for (HMtree, 'CaCO3', 'L1r2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Model Accuracy (ipywidgets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ff6be8a2e74f05ada982c57e9f19c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='method', options=('mult', 'plsr', 'svr', 'ridge', 'cubist', 'gbrt'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_model_acc_half(method, target, spec_preprocessing)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipywidgets.interact( plot_model_acc_half, target = target_names, method = ml_methods, \\\n",
    "                    spec_preprocessing = prepare_spec,  \\\n",
    "                    target_preprocessing = prepare_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open ('HMtree.pickle', 'wb') as file:\n",
    "#     pickle.dump(HMtree, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MTable = {'Input': ['Hyperspectral', 'Sentinal', 'Venus'], \n",
    "#           'Target': ['Sand', 'Sand', 'Sand'], \n",
    "#           'plsr': ['R2:0.57  bands:13','R2:0.57 bands:13','R2:0.57  bands:13'],\n",
    "#           'cubist': ['R2:0.57  bands:13','R2:0.57 bands:13','R2:0.57  bands:13'],\n",
    "#           'gbrt': ['R2:0.57  bands:13','R2:0.57 bands:13','R2:0.57  bands:13'],\n",
    "#           'svr': ['R2:0.57  bands:13','R2:0.57 bands:13','R2:0.57  bands:13'],\n",
    "#           'kridge': ['R2:0.57  bands:13','R2:0.57 bands:13','R2:0.57  bands:13']}\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MTable = pd.DataFrame.from_dict(MTable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.colheader_justify', 'center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
