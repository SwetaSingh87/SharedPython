{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Header and SoilPrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Header.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb \n",
    "from Header import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from SoilPrep.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from SoilPrep import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data and MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from LoadDataMetaData.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from LoadDataMetaData import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('say \"your Meta Tree started building\"')\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare_spec = ['none', 'fod2', 'continuum', 'log']\n",
    "# prepare_target = ['none', 'minmax']\n",
    "\n",
    "def find_X(p, n):\n",
    "    if p == 'fod':\n",
    "        X = fod_sampled[n]\n",
    "    elif p == 'cr':\n",
    "        X = sampled_cr[n]\n",
    "    elif p == 'log':\n",
    "        X = sampled_log[n]\n",
    "    elif p == 'none':\n",
    "        X = sampled_spec[n]\n",
    "    elif p == 'fod_cr':\n",
    "        X = fod_cr[n]\n",
    "    else:\n",
    "        X = fod_log[n]\n",
    "    return X\n",
    "\n",
    "def find_spec(p, n, m):\n",
    "    if n == 0:\n",
    "        if m == 'randomforest' or m == 'cubist' or m == 'gbrt':\n",
    "            spec = find_X(p, 100)\n",
    "        else:\n",
    "            spec = find_X(p,n)            \n",
    "    else:\n",
    "        spec = find_X(p,n)\n",
    "    return spec    \n",
    "\n",
    "\n",
    "def find_y(t):\n",
    "    i = target_names.index(t) \n",
    "    y = T[i]\n",
    "    return y\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recording Hypertuning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, r2_score\n",
    "\n",
    "model ={}\n",
    "param_grid ={}\n",
    "model['mult'] = LinearRegression()\n",
    "param_grid['mult'] = { 'fit_intercept': [True, False] }\n",
    "\n",
    "model['ridge'] = KernelRidge()\n",
    "param_grid['ridge']={'alpha': [ 0.00001,0.00002, 0.00005, 0.0001, 0.0002, 0.0005, 0.001, 0.002, \\\n",
    "                               0.005,  0.01, 0.05, 0.1, 0.5, 1]}\n",
    "\n",
    "model['plsr'] = PLSRegression()\n",
    "param_grid['plsr']={'n_components': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "\n",
    "\n",
    "model['cubist'] = Cubist(random_state = 42)  \n",
    "param_grid['cubist'] = { 'n_committees': [5, 10, 15, 20], 'n_rules': [10, 20, 30, 40, 50] }\n",
    "                        \n",
    "\n",
    "model['gbrt'] = GradientBoostingRegressor(random_state = 42)\n",
    "param_grid['gbrt'] = {\n",
    "    'n_estimators': [30,40,50],        # Number of boosting stages to be used\n",
    "    'learning_rate': [0.01, 0.1],     # Step size shrinkage used in updating weights\n",
    "    'max_depth': [3, 4, 5]                # Maximum depth of individual trees\n",
    "#     'min_samples_split': [2, 3],        # Minimum number of samples required to split an internal node\n",
    "#     'min_samples_leaf': [1, 2],         # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "model['svr'] = SVR()\n",
    "param_grid['svr'] = {\n",
    "    'C': [0.1, 1, 10],              # Regularization parameter\n",
    "    'kernel': ['linear', 'rbf'],   # Kernel function\n",
    "    'gamma': [0.01, 0.1, 1],      # Kernel coefficient (only for 'rbf' kernel)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Hypertuned Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_core_model_param_on (m, t, p, tp, n):\n",
    "#     Model = model[m]\n",
    "#     X = find_spec(p,n,m)\n",
    "#     y = find_y(t, tp)\n",
    "    \n",
    "#     row, col = X.shape\n",
    "\n",
    "#     scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "#     cv = RepeatedKFold(n_splits=row, n_repeats=1, random_state=3)\n",
    "        \n",
    "#     grid_search = GridSearchCV(Model, param_grid=param_grid[m], cv=cv,\\\n",
    "#                                 scoring= scorer, refit=True, verbose=1, error_score='raise', n_jobs=-1)\n",
    "#     grid_search.fit(X,y)\n",
    "    \n",
    "#     return (grid_search.best_params_)\n",
    "\n",
    "def find_tuned_param_on (X_train, y_train, m):\n",
    "    Model = model[m]\n",
    "    X = X_train\n",
    "    y = y_train\n",
    "    \n",
    "    row, col = X.shape\n",
    "\n",
    "    scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=10, random_state=3)\n",
    "        \n",
    "    grid_search = GridSearchCV(Model, param_grid=param_grid[m], cv=cv,\\\n",
    "                                scoring= scorer, refit=True, verbose=1, error_score='raise', n_jobs=-1)\n",
    "    grid_search.fit(X,y)\n",
    "    \n",
    "    return (grid_search.best_params_)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Hypertuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_core_model_on (m, BP):\n",
    "    if m == 'mult':\n",
    "        Model = LinearRegression()\n",
    "        \n",
    "    elif m == 'ridge':\n",
    "        Model =  KernelRidge(alpha = BP['alpha'])\n",
    "        \n",
    "    elif m == 'plsr':\n",
    "        Model = PLSRegression(n_components = BP['n_components'])\n",
    "        \n",
    "    elif m == 'cubist':\n",
    "        Model =  Cubist( n_committees = BP['n_committees'], n_rules = BP['n_rules'], random_state = 42) \n",
    "    \n",
    "    elif m == 'gbrt':\n",
    "        Model = GradientBoostingRegressor(n_estimators = BP['n_estimators'], learning_rate = BP['learning_rate'], \\\n",
    "                                          max_depth = BP['max_depth'],  random_state = 42)\n",
    "    elif m == 'svr':\n",
    "        Model = SVR(C = BP['C'], kernel = BP['kernel'], gamma = BP['gamma'])\n",
    "        \n",
    "    return Model    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building HMtree and BPtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ml_methods = ['mult', 'ridge', 'plsr', 'svr', 'cubist', 'gbrt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L1_y_pred (spectra, target, method, bp):\n",
    "    m = method\n",
    "    (r,c) = spectra.shape\n",
    "    \n",
    "    Y_test = target.copy()\n",
    "    Y_pred = target.copy()\n",
    "    #print('r:', r)\n",
    "    for i in range (0, r): \n",
    "        #print('i: ', i)\n",
    "        full_spec = spectra.copy()\n",
    "        X_train = full_spec.drop(full_spec.index[i], axis=0)\n",
    "        X_test = full_spec.iloc[[i],:].copy()\n",
    "        full_tar = target.copy()\n",
    "        y_train = full_tar.drop(full_tar.index[i], axis=0)\n",
    "        y_test = full_tar.iloc[i].copy()        \n",
    "        #---- Model Creation, fitting, and predictions--------\n",
    "        Model = create_core_model_on (m, bp)\n",
    "        Model.fit(X_train, y_train)\n",
    "        y_pred = Model.predict(X_test)\n",
    "        Y_pred.iloc[i] = y_pred\n",
    "        \n",
    "    return Y_pred      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_HMtree_on (target, method_name):\n",
    "    \n",
    "    tree ={}\n",
    "    \n",
    "    start = time.time()\n",
    "    m = method_name\n",
    "    t = target\n",
    "    \n",
    "    print('tree for: '+ m +' ------> running on: ' + t)\n",
    "    \n",
    "    for tp in prepare_target:\n",
    "        tree[tp] ={}        \n",
    "        for p in prepare_spec:\n",
    "            tree[tp][p] ={}            \n",
    "            for n in nbands_sampling:\n",
    "                tree[tp][p][n] ={}\n",
    "                Y = tree[tp][p][n]\n",
    "                                           \n",
    "                #------ setting spec to appropriate (sampled) spectra----                \n",
    "                spec = find_spec(p, n, m)                \n",
    "                                        \n",
    "                #---- target selection and normalization ---\n",
    "                y = find_y(t)\n",
    "                                \n",
    "                #---- performing train-test split----------------------\n",
    "                X_train, X_test, y_train, y_test = train_test_split(spec, y, test_size= 0.3, random_state=42)\n",
    "                            \n",
    "                #----- hypertuning parameter, model creation, fitting and prediction ----                \n",
    "                \n",
    "                #bp = find_tuned_param_on (X_train, y_train, m)\n",
    "                bp = find_tuned_param_on (spec, y, m)\n",
    "                \n",
    "                Y['bp'] = bp\n",
    "                print('Method: '+ m + '---> Target: '+ t+ '----> SpecProc: ' +p+ ' ---> n_band: ', n)\n",
    "                Model = create_core_model_on (m, bp)\n",
    "                Model.fit(X_train, y_train)\n",
    "                \n",
    "                y_pred = Model.predict(X_test)\n",
    "                yhat_pred = Model.predict(X_train)\n",
    "                    \n",
    "                #----- Data for Model accuracy and plotting -----------\n",
    "                Y['X_test'] = X_test                \n",
    "                Y['y_test'] = y_test\n",
    "                Y['y_testP'] = y_pred\n",
    "                \n",
    "                Y['X_train'] = X_train\n",
    "                Y['y_train'] = y_train\n",
    "                Y['y_trainP'] = yhat_pred\n",
    "                    \n",
    "                Y['iqrp_test'] = find_iqrp(y_pred, y_test)\n",
    "                Y['r2_test'] = find_r2(y_pred, y_test)\n",
    "                Y['rpd_test'] = find_rpd(y_pred, y_test)                 \n",
    "                \n",
    "                Y['r2_train'] = find_r2(yhat_pred, y_train)\n",
    "                \n",
    "                #------- L1 out prediction on test data -----------------\n",
    "                L1y_pred = L1_y_pred (spec, y, m, bp)\n",
    "                Y['L1y_testP'] = L1y_pred\n",
    "                Y['L1y_test'] = y\n",
    "                 \n",
    "                \n",
    "                Y['L1iqrp_test'] = find_iqrp(L1y_pred, y)\n",
    "                Y['L1r2_test'] = find_r2(L1y_pred, y)\n",
    "                Y['L1rpd_test'] = find_rpd(L1y_pred, y) \n",
    "                \n",
    "                                                                         \n",
    "    end = time.time()                            \n",
    "    os.system('say \"your hyper tuned meta tree finished for one more method\"')                            \n",
    "\n",
    "    print('End time - Start time =', (end-start)) \n",
    "    \n",
    "    return tree.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_HMtree_for (target_name):\n",
    "    tree ={}\n",
    "    \n",
    "    start = time.time()\n",
    "    t = target_name\n",
    "    for m in ml_methods:\n",
    "        #print('tree for: '+ m +' ------> running on: ' + t)\n",
    "        tree[m] = build_HMtree_on (t, m)\n",
    "        os.system('say \"your meta tree finished for one more method\"')\n",
    "        \n",
    "    end = time.time()                            \n",
    "                                \n",
    "    print('End time - Start time =', (end-start))     \n",
    "    return tree.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_score_on (HMtree, target, method, scorer):\n",
    "    t=target\n",
    "    m= method\n",
    "    \n",
    "    best_score = -1\n",
    "    #best_n_comp = 'NA'\n",
    "    \n",
    "    \n",
    "    for tp in prepare_target:\n",
    "        for p in prepare_spec:\n",
    "            for n in nbands_sampling:\n",
    "                Y = HMtree[t][m][tp][p][n]\n",
    "                #r2_train = Y['r2_train']\n",
    "                #r2_test = Y['r2_test']\n",
    "                #L1r2_test = Y['L1r2_test']\n",
    "                 \n",
    "                    \n",
    "                if scorer == 'iqrp':\n",
    "                    cur_score = Y['iqrp_test']\n",
    "                elif scorer == 'L1iqrp':\n",
    "                    cur_score = Y['L1iqrp_test']\n",
    "                elif scorer == 'r2':\n",
    "                    cur_score = Y['r2_test'] \n",
    "                else:\n",
    "                    cur_score = Y['L1r2_test']  \n",
    "                    \n",
    "                if cur_score > best_score:\n",
    "                    best_score = cur_score\n",
    "                    best_tp = tp\n",
    "                    best_n = n\n",
    "                    best_p = p\n",
    "                            \n",
    "    param_list = [scorer, np.round(best_score,2), 'Spec:', best_p, 'bands:', best_n]                                 \n",
    "    return (param_list)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_score_for (HMtree, target, scorer):\n",
    "    \n",
    "    for method in ml_methods:\n",
    "        param_list= best_score_on (HMtree, target, method, scorer)\n",
    "        print('For:'+target+'->', param_list, ':'+method)\n",
    "     \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open ('HMtree.pickle', 'rb') as file:\n",
    "#     HMtree = pickle.load(file)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating different branches of Mtree (for separate methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "HMtree = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree for: ridge ------> running on: Sand\n",
      "Fitting 100 folds for each of 14 candidates, totalling 1400 fits\n",
      "Method: ridge---> Target: Sand----> SpecProc: none ---> n_band:  0\n"
     ]
    }
   ],
   "source": [
    "HMtree['Sand'] = build_HMtree_for('Sand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('HMtree.pickle', 'wb') as file:\n",
    "    pickle.dump(HMtree, file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Model Accuracy (ipywidgets)\n",
    "def plot_model_acc (method, target, spec_preprocessing, n_bands):\n",
    "    \n",
    "    m = method\n",
    "    t = target\n",
    "    \n",
    "    i = target_names.index(target)    \n",
    "    \n",
    "    p = spec_preprocessing\n",
    "    n = n_bands\n",
    "    tp = 'none'\n",
    "    \n",
    "    Y = HMtree[t][m][tp][p][n]\n",
    "    \n",
    "    y_test = Y['y_test']\n",
    "    y_pred = Y['y_testP']\n",
    "    L1y_pred = Y['L1y_testP']\n",
    "    L1y_test = Y['L1y_test']\n",
    "    \n",
    "\n",
    "    \n",
    "    if m == 'plsr':\n",
    "        y_pred = y_pred[:,0]\n",
    "        #L1y_pred = L1y_pred[:,0]\n",
    "\n",
    "    \n",
    "    iqrp_test = Y['iqrp_test']\n",
    "    r2_test = Y['r2_test']\n",
    "    rpd_test = Y['rpd_test']\n",
    "    \n",
    "    L1iqrp_test = Y['L1iqrp_test']\n",
    "    L1r2_test = Y['L1r2_test']\n",
    "    L1rpd_test = Y['L1rpd_test']\n",
    "    \n",
    "    y_tp = pd.DataFrame({'actual':y_test.values, 'predic': y_pred})\n",
    "    z = np.polyfit(y_test, y_pred, 1)\n",
    "    \n",
    "    L1y_tp = pd.DataFrame({'actual':L1y_test.values, 'predic': L1y_pred})\n",
    "    L1z = np.polyfit(L1y_test, L1y_pred, 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(2,2, figsize=(18,16))\n",
    "    \n",
    "    #with plt.style.context(('ggplot')): ---- PLOT of test-prediction --------------------------------------\n",
    "    y_tp.plot.scatter(ax= axes[0][0], x=\"actual\", y=\"predic\", alpha=0.8, color = clr[i], edgecolors='k')\n",
    "    axes[0][0].plot(y_test, np.polyval(z, y_test),  c='blue', linewidth=1)\n",
    "    axes[0][0].plot(y_test, y_test, color='green', linewidth=1)\n",
    "    axes[0][0].tick_params(axis='both', labelsize=10)\n",
    "    axes[0][0].text(0.05, 0.95, target_names[i]+' (Train-Test Score)', transform=axes[0][0].transAxes, fontsize = 20, color = clr[i])\n",
    "    axes[0][0].text(0.05, 0.90, 'IQRP ={:.2f}'.format(iqrp_test), transform=axes[0][0].transAxes, fontsize = 16)\n",
    "    axes[0][0].text(0.05, 0.85, 'RPD ={:.2f}'.format(rpd_test), transform=axes[0][0].transAxes, fontsize = 16)\n",
    "    axes[0][0].text(0.05, 0.80, 'R2 ={:.2f}'.format(np.round(r2_test,3)), transform=axes[0][0].transAxes, fontsize = 16)\n",
    "    axes[0][0].text(0.95, 0.15, 'Method: '+method, transform=axes[0][0].transAxes, \n",
    "                    horizontalalignment='right', fontsize = 20)\n",
    "    \n",
    "    L1y_tp.plot.scatter(ax= axes[0][1], x=\"actual\", y=\"predic\", alpha=0.8, color = clr[i], edgecolors='k')\n",
    "    axes[0][1].plot(L1y_test, np.polyval(L1z, L1y_test),  c='blue', linewidth=1)\n",
    "    axes[0][1].plot(L1y_test, L1y_test, color='green', linewidth=1)\n",
    "    axes[0][1].tick_params(axis='both', labelsize=10)\n",
    "    axes[0][1].text(0.05, 0.95, target_names[i]+' (L1-out Score)', transform=axes[0][1].transAxes, fontsize = 20, color = clr[i])\n",
    "    axes[0][1].text(0.05, 0.90, 'IQRP ={:.2f}'.format(L1iqrp_test), transform=axes[0][1].transAxes, fontsize = 16)\n",
    "    axes[0][1].text(0.05, 0.85, 'RPD ={:.2f}'.format(L1rpd_test), transform=axes[0][1].transAxes, fontsize = 16)\n",
    "    axes[0][1].text(0.05, 0.80, 'R2 ={:.2f}'.format(np.round(L1r2_test,3)), transform=axes[0][1].transAxes, fontsize = 16)\n",
    "    axes[0][1].text(0.95, 0.15, 'Method: '+method, transform=axes[0][1].transAxes, \n",
    "                    horizontalalignment='right', fontsize = 20)\n",
    "\n",
    "    \n",
    "     #------------------------ Ploting R2 Vs N_bands-----------------------------------\n",
    "    \n",
    "    #--- data for creating n_bands vs r2 scores plot -------------------------------\n",
    "    \n",
    "    pY = HMtree[t][m]['none'][p]        \n",
    "    X = nbands_sampling\n",
    "    \n",
    "    Yr2 = []\n",
    "    L1Yr2 = []\n",
    "    \n",
    "    for j in X:\n",
    "        Yr2.append(pY[j]['r2_test'])\n",
    "        L1Yr2.append(pY[j]['L1r2_test'])  \n",
    "   \n",
    "    j = 0\n",
    "    while j < len(Yr2): \n",
    "        if Yr2[j] <= 0:\n",
    "            Yr2[j] = 0\n",
    "        if L1Yr2[j] <= 0:\n",
    "            L1Yr2[j] = 0\n",
    "        j = j + 1\n",
    " \n",
    "    #------------------------------ STEM PLOT ---- for accuracy Vs n_bands ---------------------------------- \n",
    "    \n",
    "    axes[1][0].stem(X,Yr2)\n",
    "    axes[1][0].tick_params(axis='both', labelsize=10)\n",
    "    axes[1][0].text(0.00, 1.01,  target_names[i], transform=axes[1][0].transAxes,fontsize = 20, color = clr[i])\n",
    "    axes[1][0].text(0.99, 1.01, 'Spec_prep: '+ p, transform=axes[1][0].transAxes, horizontalalignment='right', fontsize = 16)\n",
    "    axes[1][0].text(0.17, 1.01, '(train-test)', transform=axes[1][0].transAxes, horizontalalignment='left', fontsize = 16)\n",
    "    axes[1][0].text(0.60, -0.1, 'n_bands', transform=axes[1][0].transAxes, horizontalalignment='right', fontsize = 16)\n",
    "    axes[1][0].text(-0.1, 0.5, 'R2 Scores', horizontalalignment='left', verticalalignment='center', \\\n",
    "                rotation='vertical', transform=axes[1][0].transAxes, fontsize = 16)\n",
    "    \n",
    "    \n",
    "    axes[1][1].stem(X,L1Yr2)\n",
    "    axes[1][1].tick_params(axis='both', labelsize=10)\n",
    "    axes[1][1].text(0.00, 1.01,  target_names[i], transform=axes[1][1].transAxes,fontsize = 20, color = clr[i])\n",
    "    axes[1][1].text(0.99, 1.01, 'Spec_prep: '+ p, transform=axes[1][1].transAxes, horizontalalignment='right', fontsize = 16)\n",
    "    axes[1][1].text(0.17, 1.01, '(L1-out)', transform=axes[1][1].transAxes, horizontalalignment='left', fontsize = 16)\n",
    "    axes[1][1].text(0.60, -0.1, 'n_bands', transform=axes[1][1].transAxes, horizontalalignment='right', fontsize = 16)\n",
    "    axes[1][1].text(-0.1, 0.5, 'R2 Scores', horizontalalignment='left', verticalalignment='center', \\\n",
    "                rotation='vertical', transform=axes[1][1].transAxes, fontsize = 16)\n",
    "        \n",
    "   \n",
    "    return    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ml_methods = ['mult', 'ridge', 'plsr', 'svr', 'cubist', 'gbrt']\n",
    "\n",
    "#ml_methods = ['mult', 'plsr', 'svr', 'ridge', 'cubist','gbrt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score_for (HMtree, 'Sand', 'r2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score_for (HMtree, 'Sand', 'L1r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score_for (HMtree, 'Silt', 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score_for (HMtree, 'Silt', 'L1r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score_for (HMtree, 'Clay', 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score_for (HMtree, 'Clay', 'L1r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score_for (HMtree, 'TOC', 'r2')-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score_for (HMtree, 'TOC', 'L1r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score_for (HMtree, 'CaCO3', 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score_for (HMtree, 'CaCO3', 'L1r2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Model Accuracy (ipywidgets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipywidgets.interact( plot_model_acc, target = target_names, method = ml_methods, \\\n",
    "                    spec_preprocessing = prepare_spec,  \\\n",
    "                    target_preprocessing = prepare_target, n_bands = nbands_sampling )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
