{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Header and SoilPrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Header.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb \n",
    "from Header import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from SoilPrep.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from SoilPrep import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data and MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from LoadDataMetaData.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from LoadDataMetaData import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('say \"your Meta Tree started building\"')\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare_spec = ['none', 'fod2', 'continuum', 'log']\n",
    "# prepare_target = ['none', 'minmax']\n",
    "\n",
    "def find_X(p, n):\n",
    "    if p == 'fod':\n",
    "        X = fod_sampled[n]\n",
    "    elif p == 'cr':\n",
    "        X = sampled_cr[n]\n",
    "    elif p == 'log':\n",
    "        X = sampled_log[n]\n",
    "    elif p == 'none':\n",
    "        X = sampled_spec[n]\n",
    "    elif p == 'fod_cr':\n",
    "        X = fod_cr[n]\n",
    "    else:\n",
    "        X = fod_log[n]\n",
    "    return X\n",
    "\n",
    "def find_spec(p, n):\n",
    "    if n == 0:\n",
    "        spec = find_X(p, 100)            \n",
    "    else:\n",
    "        spec = find_X(p,n)\n",
    "    return spec    \n",
    "\n",
    "\n",
    "def find_y(t):\n",
    "    i = target_names.index(t) \n",
    "    y = T[i]\n",
    "    return y\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recording Hypertuning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, r2_score\n",
    "\n",
    "model ={}\n",
    "param_grid ={}\n",
    "model['mult'] = LinearRegression()\n",
    "param_grid['mult'] = { 'fit_intercept': [True, False] }\n",
    "\n",
    "model['ridge'] = KernelRidge()\n",
    "param_grid['ridge']={'alpha': [ 0.00001,0.00002, 0.00005, 0.0001, 0.0002, 0.0005, 0.001, 0.002, \\\n",
    "                               0.005,  0.01, 0.05, 0.1, 0.5, 1]}\n",
    "\n",
    "model['plsr'] = PLSRegression()\n",
    "param_grid['plsr']={'n_components': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "\n",
    "\n",
    "model['cubist'] = Cubist(random_state = 42)  \n",
    "param_grid['cubist'] = { \n",
    "    'n_committees': [1, 5, 10, 15, 20, 25, 30], \n",
    "    'n_rules': [10, 20, 30, 40, 50]\n",
    "}\n",
    "                        \n",
    "\n",
    "model['gbrt'] = GradientBoostingRegressor(random_state = 42)\n",
    "param_grid['gbrt'] = {\n",
    "    'n_estimators': [30,40,50],        # Number of boosting stages to be used\n",
    "    'learning_rate': [0.01, 0.1],     # Step size shrinkage used in updating weights\n",
    "    'max_depth': [3, 4, 5]                # Maximum depth of individual trees\n",
    "#     'min_samples_split': [2, 3],        # Minimum number of samples required to split an internal node\n",
    "#     'min_samples_leaf': [1, 2],         # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "model['svr'] = SVR()\n",
    "param_grid['svr'] = {\n",
    "    'C': [0.1, 1, 10],              # Regularization parameter\n",
    "    'kernel': ['linear', 'rbf'],   # Kernel function\n",
    "    'gamma': [0.01, 0.1, 1],      # Kernel coefficient (only for 'rbf' kernel)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Hypertuned Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_core_model_param_on (m, t, p, tp, n):\n",
    "#     Model = model[m]\n",
    "#     X = find_spec(p,n,m)\n",
    "#     y = find_y(t, tp)\n",
    "    \n",
    "#     row, col = X.shape\n",
    "\n",
    "#     scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "#     cv = RepeatedKFold(n_splits=row, n_repeats=1, random_state=3)\n",
    "        \n",
    "#     grid_search = GridSearchCV(Model, param_grid=param_grid[m], cv=cv,\\\n",
    "#                                 scoring= scorer, refit=True, verbose=1, error_score='raise', n_jobs=-1)\n",
    "#     grid_search.fit(X,y)\n",
    "    \n",
    "#     return (grid_search.best_params_)\n",
    "\n",
    "def find_tuned_param_on (X_train, y_train, m):\n",
    "    Model = model[m]\n",
    "    X = X_train\n",
    "    y = y_train\n",
    "    \n",
    "    row, col = X.shape\n",
    "\n",
    "    scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "    cv = RepeatedKFold(n_splits=5, n_repeats=10, random_state=3)\n",
    "        \n",
    "    grid_search = GridSearchCV(Model, param_grid=param_grid[m], cv=cv,\\\n",
    "                                scoring= scorer, refit=True, verbose=1, error_score='raise', n_jobs=-1)\n",
    "    grid_search.fit(X,y)\n",
    "    \n",
    "    return (grid_search.best_params_)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Hypertuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_core_model_on (m, BP):\n",
    "    if m == 'mult':\n",
    "        Model = LinearRegression()\n",
    "        \n",
    "    elif m == 'ridge':\n",
    "        Model =  KernelRidge(alpha = BP['alpha'])\n",
    "        \n",
    "    elif m == 'plsr':\n",
    "        Model = PLSRegression(n_components = BP['n_components'])\n",
    "        \n",
    "    elif m == 'cubist':\n",
    "        Model =  Cubist( n_committees = BP['n_committees'], n_rules = BP['n_rules'], \\\n",
    "                         random_state = 42) \n",
    "    \n",
    "    elif m == 'gbrt':\n",
    "        Model = GradientBoostingRegressor(n_estimators = BP['n_estimators'], learning_rate = BP['learning_rate'], \\\n",
    "                                          max_depth = BP['max_depth'],  random_state = 42)\n",
    "    elif m == 'svr':\n",
    "        Model = SVR(C = BP['C'], kernel = BP['kernel'], gamma = BP['gamma'])\n",
    "        \n",
    "    return Model    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building HMtree and BPtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ml_methods = ['mult', 'ridge', 'plsr', 'svr', 'cubist', 'gbrt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L1_y_pred (spectra, target, method, bp):\n",
    "    m = method\n",
    "    (r,c) = spectra.shape\n",
    "    \n",
    "    Y_test = target.copy()\n",
    "    Y_pred = target.copy()\n",
    "    #print('r:', r)\n",
    "    for i in range (0, r): \n",
    "        #print('i: ', i)\n",
    "        full_spec = spectra.copy()\n",
    "        X_train = full_spec.drop(full_spec.index[i], axis=0)\n",
    "        X_test = full_spec.iloc[[i],:].copy()\n",
    "        full_tar = target.copy()\n",
    "        y_train = full_tar.drop(full_tar.index[i], axis=0)\n",
    "        y_test = full_tar.iloc[i].copy()        \n",
    "        #---- Model Creation, fitting, and predictions--------\n",
    "        Model = create_core_model_on (m, bp)\n",
    "        Model.fit(X_train, y_train)\n",
    "        y_pred = Model.predict(X_test)\n",
    "        Y_pred.iloc[i] = y_pred\n",
    "        \n",
    "    return Y_pred      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split (X,y,tst_siz, num_bins):\n",
    "    ymin = y.min()\n",
    "    ymax = y.max()\n",
    "    trn_siz = 1-tst_siz\n",
    "\n",
    "    Y_binned, bin_edges = pd.qcut(y, q=num_bins, labels=False, retbins=True)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= tst_siz, stratify=Y_binned, random_state=0)\n",
    "    rand_st = 0\n",
    "    bin_train = np.histogram(y_train, bins = num_bins, range = (ymin,ymax), density=False)\n",
    "    bin_test = np.histogram(y_test, bins = num_bins, range = (ymin,ymax), density=False)\n",
    "    error = abs((bin_train[0])/trn_siz - (bin_test[0])/tst_siz)\n",
    "    cum_error = error.sum()\n",
    "    min_err= cum_error\n",
    "    \n",
    "    for i in np.arange(1,999,1):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= tst_siz, stratify=Y_binned, random_state=i)\n",
    "        bin_train = np.histogram(y_train, bins = num_bins, range = (ymin,ymax), density=False)\n",
    "        bin_test = np.histogram(y_test, bins = num_bins, range = (ymin,ymax), density=False)\n",
    "        error = abs((bin_train[0])/trn_siz - (bin_test[0])/tst_siz)\n",
    "        cum_error = error.sum()\n",
    "        if cum_error < min_err:\n",
    "            min_err = cum_error\n",
    "            rand_st = i\n",
    "            #print(i)\n",
    "\n",
    "    return (rand_st, min_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(301, 19.99999999999998)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec = find_spec('none',50, 'cubist')  \n",
    "y = T[0]\n",
    "\n",
    "num_bins = 10\n",
    "tst_siz = 0.25\n",
    "\n",
    "rand_st, min_err = best_split (spec,y,tst_siz, num_bins)\n",
    "rand_st, min_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (686, 50), (686,)\n",
      "Test set: (229, 50), (229,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_binned, bin_edges = pd.qcut(y, q=num_bins, labels=False, retbins=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(spec, y, test_size= tst_siz, stratify=Y_binned, random_state=rand_st)\n",
    "\n",
    "print(f'Training set: {X_train.shape}, {y_train.shape}')\n",
    "print(f'Test set: {X_test.shape}, {y_test.shape}')\n",
    "\n",
    "# Plot histograms of the train and test sets\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(y_train, bins=num_bins, kde=False, color='blue', edgecolor='black')\n",
    "plt.title('Train Set TOC Distribution')\n",
    "plt.xlabel('Total Organic Carbon (TOC)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(y_test, bins=num_bins, kde=False, color='green', edgecolor='black')\n",
    "plt.title('Test Set TOC Distribution')\n",
    "plt.xlabel('Total Organic Carbon (TOC)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#halt here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_HMtree_on (target, method_name):\n",
    "    \n",
    "    tree ={}\n",
    "    \n",
    "    start = time.time()\n",
    "    m = method_name\n",
    "    t = target\n",
    "    \n",
    "    #print('tree for: '+ m +' ------> running on: ' + t)\n",
    "    \n",
    "    for tp in prepare_target:\n",
    "        tree[tp] ={}        \n",
    "        for p in prepare_spec:\n",
    "            tree[tp][p] ={}            \n",
    "            for n in nbands_sampling:\n",
    "                tree[tp][p][n] ={}\n",
    "                Y = tree[tp][p][n]\n",
    "                                           \n",
    "                #------ setting spec to appropriate (sampled) spectra----                \n",
    "                spec = find_spec(p, n)                \n",
    "                                        \n",
    "                #---- target selection and normalization ---\n",
    "                y = find_y(t)\n",
    "                                \n",
    "                #---- performing stratified split to obtain 25% data for hypertuning ----------------------\n",
    "                X_loose, X_keep, y_loose, y_keep = train_test_split(spec, y, test_size= tst_siz,stratify=Y_binned, random_state=rand_st)\n",
    "                            \n",
    "                #----- hypertuning parameter, model creation, fitting and prediction ----                \n",
    "                \n",
    "                #bp = find_tuned_param_on (X_train, y_train, m)\n",
    "                bp = find_tuned_param_on (X_keep, y_keep, m)\n",
    "                \n",
    "                Y['bp'] = bp\n",
    "                print('Hypertuned on Target: '+ t+ '----> Method: '+ m + '--->  SpecProc: ' +p+ ' ---> n_band: ', n)\n",
    "                Model = create_core_model_on (m, bp)\n",
    "                \n",
    "                #---- performing train-test split for evaluation and plots----------------------\n",
    "                X_train, X_test, y_train, y_test = train_test_split(spec, y, test_size= tst_siz,stratify=Y_binned, random_state=rand_st)\n",
    "                \n",
    "                Model.fit(X_train, y_train)\n",
    "                \n",
    "                y_pred = Model.predict(X_test)\n",
    "                yhat_pred = Model.predict(X_train)\n",
    "                    \n",
    "                #----- Data for Model accuracy and plotting -----------\n",
    "                Y['X_test'] = X_test                \n",
    "                Y['y_test'] = y_test\n",
    "                Y['y_testP'] = y_pred\n",
    "                \n",
    "                Y['X_train'] = X_train\n",
    "                Y['y_train'] = y_train\n",
    "                Y['y_trainP'] = yhat_pred\n",
    "                    \n",
    "                Y['iqrp_test'] = find_iqrp(y_pred, y_test)\n",
    "                Y['r2_test'] = find_r2(y_pred, y_test)\n",
    "                Y['rpd_test'] = find_rpd(y_pred, y_test)                 \n",
    "                \n",
    "                Y['r2_train'] = find_r2(yhat_pred, y_train)\n",
    "                \n",
    "                #------- L1 out prediction on test data -----------------\n",
    "                L1y_pred = L1_y_pred (spec, y, m, bp)\n",
    "                Y['L1y_testP'] = L1y_pred\n",
    "                Y['L1y_test'] = y\n",
    "                 \n",
    "                \n",
    "                Y['L1iqrp_test'] = find_iqrp(L1y_pred, y)\n",
    "                Y['L1r2_test'] = find_r2(L1y_pred, y)\n",
    "                Y['L1rpd_test'] = find_rpd(L1y_pred, y) \n",
    "                \n",
    "                                                                         \n",
    "    end = time.time()                            \n",
    "    os.system('say \"your hyper tuned meta tree finished for one more method\"')                            \n",
    "\n",
    "    print('End time - Start time =', (end-start)) \n",
    "    \n",
    "    return tree.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_HMtree_for (target_name):\n",
    "    tree ={}\n",
    "    \n",
    "    start = time.time()\n",
    "    t = target_name\n",
    "    for m in ml_methods:\n",
    "        print('tree for: '+ t +' ------> running on: ' + m)\n",
    "        tree[m] = build_HMtree_on (t, m)\n",
    "        os.system('say \"your meta tree finished for one more method\"')\n",
    "        \n",
    "    end = time.time()                            \n",
    "                                \n",
    "    print('End time - Start time =', (end-start))     \n",
    "    return tree.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build_HMtree_for('TOC')\n",
    "\n",
    "def BuildStore_HMtree_for (target_name, hmtree):\n",
    "    \n",
    "    start = time.time()\n",
    "    t = target_name\n",
    "    hmtree[t] ={}\n",
    "    \n",
    "    for m in ml_methods:\n",
    "        print('tree for: '+ t +' ------> running on: ' + m)\n",
    "        hmtree[t][m] = build_HMtree_on (t, m)\n",
    "        os.system('say \"your meta tree finished for one more method\"')\n",
    "        \n",
    "    end = time.time()                            \n",
    "                                \n",
    "    print('End time - Start time =', (end-start))     \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_score_on (HMtree, target, method, scorer):\n",
    "    t=target\n",
    "    m= method\n",
    "    \n",
    "    best_score = -1\n",
    "    #best_n_comp = 'NA'\n",
    "    \n",
    "    \n",
    "    for tp in prepare_target:\n",
    "        for p in prepare_spec:\n",
    "            for n in nbands_sampling:\n",
    "                Y = HMtree[t][m][tp][p][n]\n",
    "                #r2_train = Y['r2_train']\n",
    "                #r2_test = Y['r2_test']\n",
    "                #L1r2_test = Y['L1r2_test']\n",
    "                 \n",
    "                    \n",
    "                if scorer == 'iqrp':\n",
    "                    cur_score = Y['iqrp_test']\n",
    "                elif scorer == 'L1iqrp':\n",
    "                    cur_score = Y['L1iqrp_test']\n",
    "                elif scorer == 'r2':\n",
    "                    cur_score = Y['r2_test'] \n",
    "                else:\n",
    "                    cur_score = Y['L1r2_test']  \n",
    "                    \n",
    "                if cur_score > best_score:\n",
    "                    best_score = cur_score\n",
    "                    best_tp = tp\n",
    "                    best_n = n\n",
    "                    best_p = p\n",
    "                            \n",
    "    param_list = [scorer, np.round(best_score,2), 'Spec:', best_p, 'bands:', best_n]                                 \n",
    "    return (param_list)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_score_for (HMtree, target, scorer):\n",
    "    \n",
    "    for method in ml_methods:\n",
    "        param_list= best_score_on (HMtree, target, method, scorer)\n",
    "        print('For:'+target+'->', param_list, ':'+method)\n",
    "     \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open ('HMtree.pickle', 'rb') as file:\n",
    "#     HMtree = pickle.load(file)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating different branches of Mtree (for separate methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "HMtree = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree for: TOC ------> running on: ridge\n",
      "tree for: ridge ------> running on: TOC\n",
      "Fitting 50 folds for each of 14 candidates, totalling 700 fits\n",
      "Hypertuned on Method: ridge---> Target: TOC----> SpecProc: none ---> n_band:  0\n",
      "Fitting 50 folds for each of 14 candidates, totalling 700 fits\n",
      "Hypertuned on Method: ridge---> Target: TOC----> SpecProc: none ---> n_band:  3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-87a7a585bd34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mBuildStore_HMtree_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TOC'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHMtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-44e673535a78>\u001b[0m in \u001b[0;36mBuildStore_HMtree_for\u001b[1;34m(target_name, hmtree)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mml_methods\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tree for: '\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m' ------> running on: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mhmtree\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_HMtree_on\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'say \"your meta tree finished for one more method\"'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-ae362d02a34b>\u001b[0m in \u001b[0;36mbuild_HMtree_on\u001b[1;34m(target, method_name)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m                 \u001b[1;31m#------- L1 out prediction on test data -----------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                 \u001b[0mL1y_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mL1_y_pred\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m                 \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'L1y_testP'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mL1y_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m                 \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'L1y_test'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-3306c2160613>\u001b[0m in \u001b[0;36mL1_y_pred\u001b[1;34m(spectra, target, method, bp)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m#---- Model Creation, fitting, and predictions--------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_core_model_on\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mY_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\kernel_ridge.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"precomputed\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual_coef_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_solve_cholesky_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mravel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual_coef_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual_coef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_ridge.py\u001b[0m in \u001b[0;36m_solve_cholesky_kernel\u001b[1;34m(K, y, alpha, sample_weight, copy)\u001b[0m\n\u001b[0;32m    192\u001b[0m             \u001b[1;31m#       use the fall-back solution below in case a LinAlgError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[1;31m#       is raised\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m             \u001b[0mdual_coef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msym_pos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinAlgError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m             warnings.warn(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\linalg\\basic.py\u001b[0m in \u001b[0;36msolve\u001b[1;34m(a, b, sym_pos, lower, overwrite_a, overwrite_b, debug, check_finite, assume_a, transposed)\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[0mnorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'1'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m     \u001b[0manorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;31m# Generalized case 'gesv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BuildStore_HMtree_for('TOC', HMtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HMtree['TOC'] = build_HMtree_for('TOC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree['svr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('HMtree.pickle', 'wb') as file:\n",
    "    pickle.dump(HMtree, file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Model Accuracy (ipywidgets)\n",
    "def plot_model_acc (method, target, spec_preprocessing, n_bands):\n",
    "    \n",
    "    m = method\n",
    "    t = target\n",
    "    \n",
    "    i = target_names.index(target)    \n",
    "    \n",
    "    p = spec_preprocessing\n",
    "    n = n_bands\n",
    "    tp = 'none'\n",
    "    \n",
    "    Y = HMtree[t][m][tp][p][n]\n",
    "    \n",
    "    y_test = Y['y_test']\n",
    "    y_pred = Y['y_testP']\n",
    "    L1y_pred = Y['L1y_testP']\n",
    "    L1y_test = Y['L1y_test']\n",
    "\n",
    "    y_train = Y['y_train']\n",
    "    yhat_pred = Y['y_trainP']\n",
    "    \n",
    "\n",
    "    \n",
    "    if m == 'plsr':\n",
    "        y_pred = y_pred[:,0]\n",
    "        #L1y_pred = L1y_pred[:,0]\n",
    "\n",
    "    \n",
    "    iqrp_test = Y['iqrp_test']\n",
    "    r2_test = Y['r2_test']\n",
    "    rpd_test = Y['rpd_test']\n",
    "\n",
    "    #iqrp_train = find_iqrp(yhat_pred, y_train)\n",
    "    r2_train = Y['r2_train']\n",
    "    #rpd_train = find_rpd(yhat_pred, y_train)\n",
    "    \n",
    "    L1iqrp_test = Y['L1iqrp_test']\n",
    "    L1r2_test = Y['L1r2_test']\n",
    "    L1rpd_test = Y['L1rpd_test']\n",
    "    \n",
    "    y_tp = pd.DataFrame({'actual':y_test.values, 'predic': y_pred})\n",
    "    z = np.polyfit(y_test, y_pred, 1)\n",
    "\n",
    "    yhat_tp = pd.DataFrame({'actual':y_train.values, 'predic': yhat_pred})\n",
    "    zhat = np.polyfit(y_train, yhat_pred, 1)\n",
    "    \n",
    "    L1y_tp = pd.DataFrame({'actual':L1y_test.values, 'predic': L1y_pred})\n",
    "    L1z = np.polyfit(L1y_test, L1y_pred, 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(2,2, figsize=(18,16))\n",
    "    \n",
    "    #with plt.style.context(('ggplot')): ---- PLOT of test-prediction --------------------------------------\n",
    "    y_tp.plot.scatter(ax= axes[0][0], x=\"actual\", y=\"predic\", alpha=0.8, color = clr[i], edgecolors='k')\n",
    "    axes[0][0].plot(y_test, np.polyval(z, y_test),  c='blue', linewidth=1)\n",
    "    axes[0][0].plot(y_test, y_test, color='green', linewidth=1)\n",
    "    axes[0][0].tick_params(axis='both', labelsize=10)\n",
    "    axes[0][0].text(0.05, 0.95, target_names[i]+' (Test Score)', transform=axes[0][0].transAxes, fontsize = 20, color = clr[i])\n",
    "    axes[0][0].text(0.05, 0.90, 'IQRP ={:.2f}'.format(iqrp_test), transform=axes[0][0].transAxes, fontsize = 16)\n",
    "    axes[0][0].text(0.05, 0.85, 'RPD ={:.2f}'.format(rpd_test), transform=axes[0][0].transAxes, fontsize = 16)\n",
    "    axes[0][0].text(0.05, 0.80, 'R2 ={:.2f}'.format(np.round(r2_test,3)), transform=axes[0][0].transAxes, fontsize = 16)\n",
    "    axes[0][0].text(0.95, 0.15, 'Method: '+method, transform=axes[0][0].transAxes, \n",
    "                    horizontalalignment='right', fontsize = 20)\n",
    "    \n",
    "    L1y_tp.plot.scatter(ax= axes[0][1], x=\"actual\", y=\"predic\", alpha=0.8, color = clr[i], edgecolors='k')\n",
    "    axes[0][1].plot(L1y_test, np.polyval(L1z, L1y_test),  c='blue', linewidth=1)\n",
    "    axes[0][1].plot(L1y_test, L1y_test, color='green', linewidth=1)\n",
    "    axes[0][1].tick_params(axis='both', labelsize=10)\n",
    "    axes[0][1].text(0.05, 0.95, target_names[i]+' (L1-out Score)', transform=axes[0][1].transAxes, fontsize = 20, color = clr[i])\n",
    "    axes[0][1].text(0.05, 0.90, 'IQRP ={:.2f}'.format(L1iqrp_test), transform=axes[0][1].transAxes, fontsize = 16)\n",
    "    axes[0][1].text(0.05, 0.85, 'RPD ={:.2f}'.format(L1rpd_test), transform=axes[0][1].transAxes, fontsize = 16)\n",
    "    axes[0][1].text(0.05, 0.80, 'R2 ={:.2f}'.format(np.round(L1r2_test,3)), transform=axes[0][1].transAxes, fontsize = 16)\n",
    "    axes[0][1].text(0.95, 0.15, 'Method: '+method, transform=axes[0][1].transAxes, \n",
    "                    horizontalalignment='right', fontsize = 20)\n",
    "\n",
    "    \n",
    "     #------------------------ Ploting R2 Vs N_bands-----------------------------------\n",
    "    \n",
    "    #--- data for creating n_bands vs r2 scores plot -------------------------------\n",
    "    \n",
    "    pY = HMtree[t][m]['none'][p]        \n",
    "    X = nbands_sampling\n",
    "    \n",
    "    Yr2 = []\n",
    "    L1Yr2 = []\n",
    "    \n",
    "    for j in X:\n",
    "        Yr2.append(pY[j]['r2_test'])\n",
    "        L1Yr2.append(pY[j]['L1r2_test'])  \n",
    "   \n",
    "    j = 0\n",
    "    while j < len(Yr2): \n",
    "        if Yr2[j] <= 0:\n",
    "            Yr2[j] = 0\n",
    "        if L1Yr2[j] <= 0:\n",
    "            L1Yr2[j] = 0\n",
    "        j = j + 1\n",
    " \n",
    "    #------------------------------ STEM PLOT ---- for accuracy Vs n_bands ---------------------------------- \n",
    "    \n",
    "    #with plt.style.context(('ggplot')): ---- PLOT of test-prediction --------------------------------------\n",
    "    yhat_tp.plot.scatter(ax= axes[1][0], x=\"actual\", y=\"predic\", alpha=0.8, color = clr[i], edgecolors='k')\n",
    "    axes[1][0].plot(y_train, np.polyval(zhat, y_train),  c='blue', linewidth=1)\n",
    "    axes[1][0].plot(y_train, y_train, color='green', linewidth=1)\n",
    "    axes[1][0].tick_params(axis='both', labelsize=10)\n",
    "    axes[1][0].text(0.05, 0.95, target_names[i]+' (Train Score)', transform=axes[1][0].transAxes, fontsize = 20, color = clr[i])\n",
    "    #axes[1][0].text(0.05, 0.90, 'IQRP ={:.2f}'.format(iqrp_train), transform=axes[1][0].transAxes, fontsize = 16)\n",
    "    #axes[1][0].text(0.05, 0.85, 'RPD ={:.2f}'.format(rpd_train), transform=axes[1][0].transAxes, fontsize = 16)\n",
    "    axes[1][0].text(0.05, 0.80, 'R2 ={:.2f}'.format(np.round(r2_train,3)), transform=axes[1][0].transAxes, fontsize = 16)\n",
    "    axes[1][0].text(0.95, 0.15, 'Method: '+method, transform=axes[1][0].transAxes, \n",
    "                    horizontalalignment='right', fontsize = 20)\n",
    "    \n",
    "    \n",
    "    axes[1][1].stem(X,L1Yr2)\n",
    "    axes[1][1].tick_params(axis='both', labelsize=10)\n",
    "    axes[1][1].text(0.00, 1.01,  target_names[i], transform=axes[1][1].transAxes,fontsize = 20, color = clr[i])\n",
    "    axes[1][1].text(0.99, 1.01, 'Spec_prep: '+ p, transform=axes[1][1].transAxes, horizontalalignment='right', fontsize = 16)\n",
    "    axes[1][1].text(0.17, 1.01, '(L1-out)', transform=axes[1][1].transAxes, horizontalalignment='left', fontsize = 16)\n",
    "    axes[1][1].text(0.60, -0.1, 'n_bands', transform=axes[1][1].transAxes, horizontalalignment='right', fontsize = 16)\n",
    "    axes[1][1].text(-0.1, 0.5, 'R2 Scores', horizontalalignment='left', verticalalignment='center', \\\n",
    "                rotation='vertical', transform=axes[1][1].transAxes, fontsize = 16)\n",
    "        \n",
    "   \n",
    "    return    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ml_methods = ['mult', 'ridge', 'plsr', 'svr', 'cubist', 'gbrt']\n",
    "\n",
    "#ml_methods = ['mult', 'plsr', 'svr', 'ridge', 'cubist','gbrt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score_for (HMtree, 'TOC', 'r2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score_for (HMtree, 'TOC', 'L1r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score_for (HMtree, 'Silt', 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score_for (HMtree, 'Silt', 'L1r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score_for (HMtree, 'Clay', 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score_for (HMtree, 'Clay', 'L1r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score_for (HMtree, 'TOC', 'r2')-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score_for (HMtree, 'TOC', 'L1r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score_for (HMtree, 'CaCO3', 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score_for (HMtree, 'CaCO3', 'L1r2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Model Accuracy (ipywidgets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipywidgets.interact( plot_model_acc, target = target_names, method = ml_methods, \\\n",
    "                    spec_preprocessing = prepare_spec,  \\\n",
    "                    target_preprocessing = prepare_target, n_bands = nbands_sampling )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
