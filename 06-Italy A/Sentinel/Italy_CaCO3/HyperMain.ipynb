{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Header and SoilPrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Header.ipynb\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _path: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9b6ebadd4454>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimport_ipynb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mHeader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\import_ipynb.py\u001b[0m in \u001b[0;36mload_module\u001b[1;34m(self, fullname)\u001b[0m\n\u001b[0;32m     59\u001b[0m                 \u001b[0mcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_transformer_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m                 \u001b[1;31m# run the code in themodule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                 \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_ns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msave_user_ns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Sweta\\GitRepo\\06-Italy A\\Sentinel\\Italy_CaCO3\\Header.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;31m# cbook must import matplotlib only within function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[1;31m# definitions, so it is safe to import from it here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_docstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcsetup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msanitize_sequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMatplotlibDeprecationWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\rcsetup.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mls_mapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mColormap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_color_like\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fontconfig_pattern\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparse_fontconfig_pattern\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_enums\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mJoinStyle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCapStyle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\colors.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_cm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_color_data\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBASE_COLORS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTABLEAU_COLORS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCSS4_COLORS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXKCD_COLORS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\scale.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_docstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m from matplotlib.ticker import (\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mNullFormatter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mScalarFormatter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLogFormatterSciNotation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLogitFormatter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mNullLocator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLogLocator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAutoLocator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAutoMinorLocator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\ticker.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[0m_log\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\transforms.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m from matplotlib._path import (\n\u001b[0m\u001b[0;32m     50\u001b[0m     affine_transform, count_bboxes_overlapping_bbox, update_path_extents)\n\u001b[0;32m     51\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _path: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "import import_ipynb \n",
    "from Header import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "from SoilPrep import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data and MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "from LoadDataMetaData import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed One Time Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_locs = [ '443', '490', '560', '665', '705', '740', '783', '842', '865', '940', '1375', '1610', '2190']\n",
    "band_widths = [ 21, 65, 36, 31, 14, 14, 20, 106, 21, 20, 31, 91, 176]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_at (spectrum, mid_locs, band_widths):\n",
    "    \n",
    "    #----- obtaining the sampling ilocations in indx----\n",
    "    mid_ilocs = []\n",
    "    for l in mid_locs:\n",
    "        #print(l)\n",
    "        i = spectrum.columns.get_loc(l)\n",
    "        mid_ilocs.append(i)\n",
    "    \n",
    "    #print(mid_ilocs)\n",
    "    #print(mid_ilocs)\n",
    "    #print(mid_locs)   \n",
    "    \n",
    "    #----- finding initial shape for red_spectra ------\n",
    "    red_spectra = spectrum.iloc[:, mid_ilocs].copy()\n",
    "    #print(red_spectra.head(5))\n",
    "    #print(len(mid_ilocs))\n",
    "    \n",
    "    for i in range(0, len(mid_ilocs)):\n",
    "        m = mid_ilocs[i]\n",
    "        l = mid_locs[i]\n",
    "        window = np.floor(0.5*band_widths[i]).astype(int)\n",
    "        #print('m: ', m, 'window:', window)\n",
    "        red_spectra.loc[:,l] = spectrum.iloc[:,(m-window):(m+window)].mean(axis=1).copy()\n",
    "        \n",
    "    return (red_spectra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_spec13 = resample_at (spec2[51], mid_locs, band_widths)\n",
    "sampled_spec13.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_cr13 = resample_at (cr_spec, mid_locs, band_widths)\n",
    "#sampled_cr13.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_log13 = resample_at(log_spec, mid_locs, band_widths)\n",
    "#sampled_log13.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fod_sampled13 = fod (sampled_spec13)\n",
    "#fod_sampled13.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fod_cr13 = fod (sampled_cr13)\n",
    "#fod_cr13.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fod_log13 = fod (sampled_log13)\n",
    "#fod_log13.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('say \"your Meta Tree started building\"')\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare_spec = ['none', 'fod2', 'continuum', 'log']\n",
    "# prepare_target = ['none', 'minmax']\n",
    "\n",
    "def find_X(p):\n",
    "    if p == 'fod':\n",
    "        X = fod_sampled13\n",
    "    elif p == 'cr':\n",
    "        X = sampled_cr13\n",
    "    elif p == 'log':\n",
    "        X = sampled_log13\n",
    "    elif p == 'none':\n",
    "        X = sampled_spec13\n",
    "    elif p == 'fod_cr':\n",
    "        X = fod_cr13\n",
    "    else:\n",
    "        X = fod_log13\n",
    "    return X\n",
    "\n",
    "\n",
    "def find_y(t):\n",
    "    i = target_names.index(t) \n",
    "    y = T[i]\n",
    "    return y\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recording Hypertuning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, r2_score\n",
    "\n",
    "model ={}\n",
    "param_grid ={}\n",
    "model['mult'] = LinearRegression()\n",
    "param_grid['mult'] = { 'fit_intercept': [True, False] }\n",
    "\n",
    "model['ridge'] = KernelRidge()\n",
    "param_grid['ridge']={'alpha': [ 0.00001,0.00002, 0.00005, 0.0001, 0.0002, 0.0005, 0.001, 0.002, \\\n",
    "                               0.005,  0.01, 0.05, 0.1, 0.5, 1]}\n",
    "\n",
    "model['plsr'] = PLSRegression()\n",
    "param_grid['plsr']={'n_components': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "\n",
    "\n",
    "model['cubist'] = Cubist(random_state = 42)  \n",
    "param_grid['cubist'] = { 'n_committees': [5, 10, 15, 20], 'n_rules': [10, 20, 30, 40, 50] }\n",
    "                        \n",
    "\n",
    "model['gbrt'] = GradientBoostingRegressor(random_state = 42)\n",
    "param_grid['gbrt'] = {\n",
    "    'n_estimators': [20,30,40,50],        # Number of boosting stages to be used\n",
    "    'learning_rate': [0.01, 0.1],     # Step size shrinkage used in updating weights\n",
    "    'max_depth': [3, 4, 5]                # Maximum depth of individual trees\n",
    "#     'min_samples_split': [2, 3],        # Minimum number of samples required to split an internal node\n",
    "#     'min_samples_leaf': [1, 2],         # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "model['svr'] = SVR()\n",
    "param_grid['svr'] = {\n",
    "    'C': [0.1, 1, 10],              # Regularization parameter\n",
    "    'kernel': ['linear', 'rbf'],   # Kernel function\n",
    "    'gamma': [0.01, 0.1, 1],      # Kernel coefficient (only for 'rbf' kernel)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Hypertuned Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_core_model_param_on (m, t, p, tp, n):\n",
    "#     Model = model[m]\n",
    "#     X = find_spec(p,n,m)\n",
    "#     y = find_y(t, tp)\n",
    "    \n",
    "#     row, col = X.shape\n",
    "\n",
    "#     scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "#     cv = RepeatedKFold(n_splits=row, n_repeats=1, random_state=3)\n",
    "        \n",
    "#     grid_search = GridSearchCV(Model, param_grid=param_grid[m], cv=cv,\\\n",
    "#                                 scoring= scorer, refit=True, verbose=1, error_score='raise', n_jobs=-1)\n",
    "#     grid_search.fit(X,y)\n",
    "    \n",
    "#     return (grid_search.best_params_)\n",
    "\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "\n",
    "def find_tuned_param_on (X_train, y_train, m):\n",
    "    Model = model[m]\n",
    "    X = X_train\n",
    "    y = y_train\n",
    "    \n",
    "    row, col = X.shape\n",
    "    \n",
    "    scorer = 'r2'\n",
    "    cv = RepeatedKFold(n_splits=5, n_repeats=10, random_state=3)\n",
    "        \n",
    "    grid_search = GridSearchCV(Model, param_grid=param_grid[m], cv=cv,\n",
    "                               scoring=scorer, refit=True, verbose=1, \n",
    "                               error_score='raise', n_jobs=-1, return_train_score=True)\n",
    "\n",
    "#     scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "#     cv = RepeatedKFold(n_splits=5, n_repeats=10, random_state=3)\n",
    "        \n",
    "#     grid_search = GridSearchCV(Model, param_grid=param_grid[m], cv=cv,\\\n",
    "#                                 scoring= scorer, refit=True, verbose=1, error_score='raise', n_jobs=-1, return_train_score=True)\n",
    "    \n",
    "    grid_search.fit(X,y)\n",
    "    \n",
    "    # Best parameters\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Best test score\n",
    "    best_index = grid_search.best_index_\n",
    "    best_test_score = grid_search.cv_results_['mean_test_score'][best_index]\n",
    "\n",
    "    # Best train score\n",
    "    best_train_score = grid_search.cv_results_['mean_train_score'][best_index]\n",
    "    \n",
    "    return (best_params, best_test_score, best_train_score)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Hypertuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_core_model_on (m, BP):\n",
    "    if m == 'mult':\n",
    "        Model = LinearRegression()\n",
    "        \n",
    "    elif m == 'ridge':\n",
    "        Model =  KernelRidge(alpha = BP['alpha'])\n",
    "        \n",
    "    elif m == 'plsr':\n",
    "        Model = PLSRegression(n_components = BP['n_components'])\n",
    "        \n",
    "    elif m == 'cubist':\n",
    "        Model =  Cubist( n_committees = BP['n_committees'], n_rules = BP['n_rules'], random_state = 42) \n",
    "    \n",
    "    elif m == 'gbrt':\n",
    "        Model = GradientBoostingRegressor(n_estimators = BP['n_estimators'], learning_rate = BP['learning_rate'], \\\n",
    "                                          max_depth = BP['max_depth'],  random_state = 42)\n",
    "    elif m == 'svr':\n",
    "        Model = SVR(C = BP['C'], kernel = BP['kernel'], gamma = BP['gamma'])\n",
    "        \n",
    "    return Model    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building HMtree and BPtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ml_methods = ['ridge', 'plsr', 'svr', 'cubist', 'gbrt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L1_y_pred (spectra, target, method, bp):\n",
    "    m = method\n",
    "    (r,c) = spectra.shape\n",
    "    \n",
    "    Y_test = target.copy()\n",
    "    Y_pred = target.copy()\n",
    "    #print('r:', r)\n",
    "    for i in range (0, r): \n",
    "        #print('i: ', i)\n",
    "        full_spec = spectra.copy()\n",
    "        X_train = full_spec.drop(full_spec.index[i], axis=0)\n",
    "        X_test = full_spec.iloc[[i],:].copy()\n",
    "        full_tar = target.copy()\n",
    "        y_train = full_tar.drop(full_tar.index[i], axis=0)\n",
    "        y_test = full_tar.iloc[i].copy()        \n",
    "        #---- Model Creation, fitting, and predictions--------\n",
    "        Model = create_core_model_on (m, bp)\n",
    "        Model.fit(X_train, y_train)\n",
    "        y_pred = Model.predict(X_test)\n",
    "        Y_pred.iloc[i] = y_pred\n",
    "        \n",
    "    return Y_pred      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_HMtree_on (target, method_name):\n",
    "    \n",
    "    tree ={}\n",
    "    \n",
    "    start = time.time()\n",
    "    m = method_name\n",
    "    t = target\n",
    "    \n",
    "    #print('tree for: '+ m +' ------> running on: ' + t)\n",
    "    \n",
    "    for tp in prepare_target:\n",
    "        tree[tp] ={}        \n",
    "        for p in prepare_spec:\n",
    "            tree[tp][p] ={}            \n",
    "            \n",
    "            Y = tree[tp][p]\n",
    "                                           \n",
    "            #------ setting spec to appropriate (sampled) spectra----                \n",
    "            spec = find_X(p)                \n",
    "                                        \n",
    "            #---- target selection and normalization ---\n",
    "            y = find_y(t)\n",
    "                                \n",
    "            #---- performing train-test split----------------------\n",
    "            X_train, X_test, y_train, y_test = train_test_split(spec, y, test_size= 0.2, random_state=42)\n",
    "                            \n",
    "            #----- hypertuning parameter, model creation, fitting and prediction ----                \n",
    "                \n",
    "            #bp = find_tuned_param_on (X_train, y_train, m)\n",
    "            bp, best_test_score, best_train_score = find_tuned_param_on (spec, y, m)\n",
    "                \n",
    "            Y['bp'] = bp\n",
    "            print('Method: '+ m + '---> Target: '+ t+ '----> SpecProc: ' +p+ ' ---> n_band: 13')\n",
    "            Model = create_core_model_on (m, bp)\n",
    "            Model.fit(X_train, y_train)\n",
    "                \n",
    "            y_pred = Model.predict(X_test)\n",
    "            yhat_pred = Model.predict(X_train)\n",
    "                    \n",
    "            #----- Data for Model accuracy and plotting -----------\n",
    "            Y['X_test'] = X_test                \n",
    "            Y['y_test'] = y_test\n",
    "            Y['y_testP'] = y_pred\n",
    "                \n",
    "            Y['X_train'] = X_train\n",
    "            Y['y_train'] = y_train\n",
    "            Y['y_trainP'] = yhat_pred\n",
    "                    \n",
    "            Y['r2_test'] = best_test_score\n",
    "            Y['r2_train'] = best_train_score\n",
    "                \n",
    "            #------- L1 out prediction on test data -----------------\n",
    "            L1y_pred = L1_y_pred (spec, y, m, bp)\n",
    "            Y['L1y_testP'] = L1y_pred\n",
    "            Y['L1y_test'] = y\n",
    "             \n",
    "            \n",
    "            Y['L1iqrp_test'] = find_iqrp(L1y_pred, y)\n",
    "            Y['L1r2_test'] = find_r2(L1y_pred, y)\n",
    "            Y['L1rpd_test'] = find_rpd(L1y_pred, y) \n",
    "                \n",
    "                                                                         \n",
    "    end = time.time()                            \n",
    "    os.system('say \"your hyper tuned meta tree finished for one more method\"')                            \n",
    "\n",
    "    print('End time - Start time =', (end-start)) \n",
    "    \n",
    "    return tree.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_HMtree_for (target_name):\n",
    "    tree ={}\n",
    "    \n",
    "    start = time.time()\n",
    "    t = target_name\n",
    "    for m in ml_methods:\n",
    "        print('tree for: '+ t +' ------> running on: ' + m)\n",
    "        tree[m] = build_HMtree_on (t, m)\n",
    "        os.system('say \"your meta tree finished for one more method\"')\n",
    "        \n",
    "    end = time.time()                            \n",
    "                                \n",
    "    print('End time - Start time =', (end-start))     \n",
    "    return tree.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build_HMtree_for('TOC')\n",
    "\n",
    "def BuildStore_HMtree_for (target_name, hmtree):\n",
    "    \n",
    "    start = time.time()\n",
    "    t = target_name\n",
    "    hmtree[t] ={}\n",
    "    \n",
    "    for m in ml_methods:\n",
    "        print('tree for: '+ t +' ------> running on: ' + m)\n",
    "        hmtree[t][m] = build_HMtree_on (t, m)\n",
    "        os.system('say \"your meta tree finished for one more method\"')\n",
    "        with open (f'HMtree_{m}.pickle', 'wb') as file:\n",
    "            pickle.dump(hmtree[t][m], file)\n",
    "        \n",
    "    end = time.time()                            \n",
    "    with open ('HMtree.pickle', 'wb') as file:\n",
    "            pickle.dump(hmtree, file)                            \n",
    "    print('End time - Start time =', (end-start))     \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_score_on (HMtree, target, method, scorer):\n",
    "    t=target\n",
    "    m= method\n",
    "    \n",
    "    best_score = -1\n",
    "    best_tp = None\n",
    "    best_n = None\n",
    "    best_p = None\n",
    "    \n",
    "    for tp in prepare_target:\n",
    "        for p in prepare_spec:\n",
    "            \n",
    "            Y = HMtree[t][m][tp][p]\n",
    "            #r2_train = Y['r2_train']\n",
    "            #r2_test = Y['r2_test']\n",
    "            #L1r2_test = Y['L1r2_test']\n",
    "                 \n",
    "                    \n",
    "            if scorer == 'r2':\n",
    "                cur_score = Y['r2_test'] \n",
    "            else:\n",
    "                cur_score = Y['L1r2_test'] \n",
    "                    \n",
    "            if cur_score > best_score:\n",
    "                best_score = cur_score\n",
    "                best_tp = tp\n",
    "                best_n = 13\n",
    "                best_p = p\n",
    "                            \n",
    "    param_list = [scorer, np.round(best_score,2), 'Spec:', best_p, 'bands: 13']                                 \n",
    "    return (param_list)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_score_for (HMtree, target, scorer):\n",
    "    \n",
    "    for method in ml_methods:\n",
    "        param_list= best_score_on (HMtree, target, method, scorer)\n",
    "        print('For:'+target+'->', param_list, ':'+method)\n",
    "     \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open ('HMtree.pickle', 'rb') as file:\n",
    "#     HMtree = pickle.load(file)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating different branches of Mtree (for separate methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HMtree = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BuildStore_HMtree_for('CaCO3', HMtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HMtree['mult'] = build_HMtree_for('mult')\n",
    "# HMtree['plsr'] = build_HMtree_for('plsr')\n",
    "# HMtree['svr'] = build_HMtree_for('svr')\n",
    "# HMtree['ridge'] = build_HMtree_for('ridge')\n",
    "# HMtree['cubist'] = build_HMtree_for('cubist')\n",
    "# HMtree['gbrt'] = build_HMtree_for('gbrt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open ('HMtree.pickle', 'wb') as file:\n",
    "#     pickle.dump(HMtree, file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_acc_half (method, target, spec_preprocessing):\n",
    "    \n",
    "    m = method\n",
    "    t = target\n",
    "    \n",
    "    i = target_names.index(target)    \n",
    "    \n",
    "    p = spec_preprocessing\n",
    "    #n = n_bands\n",
    "    tp = 'none'\n",
    "    \n",
    "    Y = HMtree[t][m][tp][p]\n",
    "    \n",
    "    y_test = Y['y_test']\n",
    "    y_pred = Y['y_testP']\n",
    "    L1y_pred = Y['L1y_testP']\n",
    "    L1y_test = Y['L1y_test']\n",
    "    \n",
    "    y_train = Y['y_train']\n",
    "    yhat_pred = Y['y_trainP']\n",
    "    \n",
    "    \n",
    "    if m == 'plsr':\n",
    "        y_pred = y_pred[:,0]\n",
    "        #L1y_pred = L1y_pred[:,0]\n",
    "\n",
    "    \n",
    "    #iqrp_test = Y['iqrp_test']\n",
    "    r2_test = Y['r2_test']\n",
    "    #rpd_test = Y['rpd_test']\n",
    "\n",
    "    #iqrp_train = find_iqrp(yhat_pred, y_train)\n",
    "    r2_train = Y['r2_train']\n",
    "    #rpd_train = find_rpd(yhat_pred, y_train)\n",
    "    \n",
    "    L1iqrp_test = Y['L1iqrp_test']\n",
    "    L1r2_test = Y['L1r2_test']\n",
    "    L1rpd_test = Y['L1rpd_test']\n",
    "    \n",
    "    y_tp = pd.DataFrame({'actual':y_test.values, 'predic': y_pred})\n",
    "    z = np.polyfit(y_test, y_pred, 1)\n",
    "\n",
    "    yhat_tp = pd.DataFrame({'actual':y_train.values, 'predic': yhat_pred})\n",
    "    zhat = np.polyfit(y_train, yhat_pred, 1)\n",
    "    \n",
    "    L1y_tp = pd.DataFrame({'actual':L1y_test.values, 'predic': L1y_pred})\n",
    "    L1z = np.polyfit(L1y_test, L1y_pred, 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(2,2, figsize=(18,16))\n",
    "    \n",
    "    #with plt.style.context(('ggplot')): ---- PLOT of test-prediction --------------------------------------\n",
    "    y_tp.plot.scatter(ax= axes[0][0], x=\"actual\", y=\"predic\", alpha=0.8, color = clr[i], edgecolors='k')\n",
    "    axes[0][0].plot(y_test, np.polyval(z, y_test),  c='blue', linewidth=1)\n",
    "    axes[0][0].plot(y_test, y_test, color='green', linewidth=1)\n",
    "    axes[0][0].tick_params(axis='both', labelsize=10)\n",
    "    axes[0][0].text(0.05, 0.95, target_names[i]+' (Test Score)', transform=axes[0][0].transAxes, fontsize = 20, color = clr[i])\n",
    "    #axes[0][0].text(0.05, 0.90, 'IQRP ={:.2f}'.format(iqrp_test), transform=axes[0][0].transAxes, fontsize = 16)\n",
    "    #axes[0][0].text(0.05, 0.85, 'RPD ={:.2f}'.format(rpd_test), transform=axes[0][0].transAxes, fontsize = 16)\n",
    "    axes[0][0].text(0.05, 0.80, 'R2 ={:.2f}'.format(np.round(r2_test,3)), transform=axes[0][0].transAxes, fontsize = 16)\n",
    "    axes[0][0].text(0.95, 0.15, 'Method: '+method, transform=axes[0][0].transAxes, \n",
    "                    horizontalalignment='right', fontsize = 20)\n",
    "    \n",
    "    L1y_tp.plot.scatter(ax= axes[0][1], x=\"actual\", y=\"predic\", alpha=0.8, color = clr[i], edgecolors='k')\n",
    "    axes[0][1].plot(L1y_test, np.polyval(L1z, L1y_test),  c='blue', linewidth=1)\n",
    "    axes[0][1].plot(L1y_test, L1y_test, color='green', linewidth=1)\n",
    "    axes[0][1].tick_params(axis='both', labelsize=10)\n",
    "    axes[0][1].text(0.05, 0.95, target_names[i]+' (L1-out Score)', transform=axes[0][1].transAxes, fontsize = 20, color = clr[i])\n",
    "    axes[0][1].text(0.05, 0.90, 'IQRP ={:.2f}'.format(L1iqrp_test), transform=axes[0][1].transAxes, fontsize = 16)\n",
    "    axes[0][1].text(0.05, 0.85, 'RPD ={:.2f}'.format(L1rpd_test), transform=axes[0][1].transAxes, fontsize = 16)\n",
    "    axes[0][1].text(0.05, 0.80, 'R2 ={:.2f}'.format(np.round(L1r2_test,3)), transform=axes[0][1].transAxes, fontsize = 16)\n",
    "    axes[0][1].text(0.95, 0.15, 'Method: '+method, transform=axes[0][1].transAxes, \n",
    "                    horizontalalignment='right', fontsize = 20)\n",
    "    \n",
    "    \n",
    "    #with plt.style.context(('ggplot')): ---- PLOT of test-prediction --------------------------------------\n",
    "    yhat_tp.plot.scatter(ax= axes[1][0], x=\"actual\", y=\"predic\", alpha=0.8, color = clr[i], edgecolors='k')\n",
    "    axes[1][0].plot(y_train, np.polyval(zhat, y_train),  c='blue', linewidth=1)\n",
    "    axes[1][0].plot(y_train, y_train, color='green', linewidth=1)\n",
    "    axes[1][0].tick_params(axis='both', labelsize=10)\n",
    "    axes[1][0].text(0.05, 0.95, target_names[i]+' (Train Score)', transform=axes[1][0].transAxes, fontsize = 20, color = clr[i])\n",
    "    #axes[1][0].text(0.05, 0.90, 'IQRP ={:.2f}'.format(iqrp_train), transform=axes[1][0].transAxes, fontsize = 16)\n",
    "    #axes[1][0].text(0.05, 0.85, 'RPD ={:.2f}'.format(rpd_train), transform=axes[1][0].transAxes, fontsize = 16)\n",
    "    axes[1][0].text(0.05, 0.80, 'R2 ={:.2f}'.format(np.round(r2_train,3)), transform=axes[1][0].transAxes, fontsize = 16)\n",
    "    axes[1][0].text(0.95, 0.15, 'Method: '+method, transform=axes[1][0].transAxes, \n",
    "                    horizontalalignment='right', fontsize = 20)\n",
    "    \n",
    "    #with plt.style.context(('ggplot')): ---- PLOT of test-prediction --------------------------------------\n",
    "    yhat_tp.plot.scatter(ax= axes[1][1], x=\"actual\", y=\"predic\", alpha=0.8, color = clr[i], edgecolors='k')\n",
    "    axes[1][1].plot(y_train, np.polyval(zhat, y_train),  c='blue', linewidth=1)\n",
    "    axes[1][1].plot(y_train, y_train, color='green', linewidth=1)\n",
    "    axes[1][1].tick_params(axis='both', labelsize=10)\n",
    "    axes[1][1].text(0.05, 0.95, target_names[i]+' (Train Score)', transform=axes[1][1].transAxes, fontsize = 20, color = clr[i])\n",
    "    #axes[1][0].text(0.05, 0.90, 'IQRP ={:.2f}'.format(iqrp_train), transform=axes[1][0].transAxes, fontsize = 16)\n",
    "    #axes[1][0].text(0.05, 0.85, 'RPD ={:.2f}'.format(rpd_train), transform=axes[1][0].transAxes, fontsize = 16)\n",
    "    axes[1][1].text(0.05, 0.80, 'R2 ={:.2f}'.format(np.round(r2_train,3)), transform=axes[1][1].transAxes, fontsize = 16)\n",
    "    axes[1][1].text(0.95, 0.15, 'Method: '+method, transform=axes[1][1].transAxes, \n",
    "                    horizontalalignment='right', fontsize = 20)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ml_methods = ['mult', 'ridge', 'plsr', 'svr', 'cubist', 'gbrt']\n",
    "\n",
    "#ml_methods = ['mult', 'plsr', 'svr', 'ridge', 'cubist','gbrt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score_for (HMtree, 'Sand', 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score_for (HMtree, 'CaCO3', 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score_for (HMtree, 'Silt', 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score_for (HMtree, 'CaCO3', 'L1r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score_for (HMtree, 'Clay', 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score_for (HMtree, 'Clay', 'L1r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score_for (HMtree, 'TOC', 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score_for (HMtree, 'TOC', 'L1r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score_for (HMtree, 'CaCO3', 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score_for (HMtree, 'CaCO3', 'L1r2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Model Accuracy (ipywidgets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipywidgets.interact( plot_model_acc_half, target = target_names, method = ml_methods, \\\n",
    "                    spec_preprocessing = prepare_spec,  \\\n",
    "                    target_preprocessing = prepare_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open ('HMtree.pickle', 'wb') as file:\n",
    "#     pickle.dump(HMtree, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MTable = {'Input': ['Hyperspectral', 'Sentinal', 'Venus'], \n",
    "#           'Target': ['Sand', 'Sand', 'Sand'], \n",
    "#           'plsr': ['R2:0.57  bands:13','R2:0.57 bands:13','R2:0.57  bands:13'],\n",
    "#           'cubist': ['R2:0.57  bands:13','R2:0.57 bands:13','R2:0.57  bands:13'],\n",
    "#           'gbrt': ['R2:0.57  bands:13','R2:0.57 bands:13','R2:0.57  bands:13'],\n",
    "#           'svr': ['R2:0.57  bands:13','R2:0.57 bands:13','R2:0.57  bands:13'],\n",
    "#           'kridge': ['R2:0.57  bands:13','R2:0.57 bands:13','R2:0.57  bands:13']}\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MTable = pd.DataFrame.from_dict(MTable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.colheader_justify', 'center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
