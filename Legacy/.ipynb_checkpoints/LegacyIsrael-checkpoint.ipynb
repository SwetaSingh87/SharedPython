{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c173cf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openpyxl\n",
    "# !pip install imbalanced-learn\n",
    "# !pip3 install ipympl\n",
    "# !pip install import-ipynb\n",
    "# !pip install shapely\n",
    "# !pip install SciencePlots \n",
    "# !pip install seaborn\n",
    "# !pip install tqdm\n",
    "# !pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ef6b01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scienceplots\n",
    "import os, sys\n",
    "from numpy import nan\n",
    "import re\n",
    "import ipympl\n",
    "# from IPython.core.display import display, HTML\n",
    "import ipywidgets\n",
    "import json\n",
    "from os import listdir\n",
    "import glob\n",
    "import math\n",
    "from IPython.display import Image, display, HTML\n",
    "from shapely.geometry import mapping\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, RepeatedKFold, cross_val_predict\n",
    "from sklearn.metrics import r2_score, mean_squared_error, precision_score, recall_score, mean_absolute_error, make_scorer\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from cubist import Cubist\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, LeaveOneOut, cross_validate\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy import stats\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "pd.options.display.max_columns = 100\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "%matplotlib inline\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22684781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "from SoilPrep import * "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237d1771",
   "metadata": {},
   "source": [
    "# Step 0: Setting up decision paramenters (Data Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee7c2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Available smoothing filter types: savgol1 and savgol2 ------------------------ (1)\n",
    "sg_filters = ['sg1', 'sg2']\n",
    "\n",
    "# 2. Available window lengths for the smoothing filter ---------------------------- (2)\n",
    "window_lengths = [0, 1, 11, 21, 31, 41, 51, 61, 71, 81, 91, 101]\n",
    "\n",
    "# 3. Available preprocessing for Spectral data ------------------------------------ (3)\n",
    "prepare_spec = ['none', 'fod', 'continuum', 'log']\n",
    "#prepare_spec = ['none', 'fod', 'continuum']\n",
    "\n",
    "# 4. Number of bands available for resampling spectra ----------------------------- (4) \n",
    "nbands_sampling = [0, 5, 10, 15,20, 25, 30, 35, 40, 45, 50, 60, 70, 80, 90,  100]\n",
    "\n",
    "# 5. Names of target variables in the dataframe ----------------------------------- (5)\n",
    "target_names = ['Sand', 'Silt', 'Clay', 'TOC', 'CaCO3']\n",
    "\n",
    "# 6. Available preprocessing for Target data -------------------------------------- (6)\n",
    "prepare_target = ['none', 'minmax']\n",
    "\n",
    "# 7. Available machine learning regression models --------------------------------- (7)\n",
    "ml_methods = ['mult', 'plsr', 'randomforest', 'cubist', 'svr', 'ridge', 'gbrt']\n",
    "\n",
    "# 8. Recorded predictions on test-train data for model accuracy  ------------------ (8)\n",
    "test_train_predict = ['test', 'testP', 'train', 'trainP']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b42ad8",
   "metadata": {},
   "source": [
    "# Step 1a: Obtaining Spectra (Noise and Outliers removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fbfeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colour scheme definition\n",
    "kado = '#8B7355'\n",
    "mati = '#A52A2A'\n",
    "balu = '#F4A460'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88f67d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "legacy_spec = pd.read_csv('spectra.csv')\n",
    "legacy_tar = pd.read_csv('targets.csv')\n",
    "\n",
    "#\n",
    "# legacy_spec.head(2)\n",
    "legacy_spec.rename(columns= {'sample':'id'}, inplace=True)\n",
    "legacy_tar.rename(columns = {'SOIL': 'id', 'CLAI':'Clay', 'SILT': 'Silt', 'SAND': 'Sand', 'OC': 'TOC', 'CACO3':'CaCO3'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd3452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "legacy_spec = legacy_spec.set_index('id', drop=True)\n",
    "legacy_tar = legacy_tar.set_index('id', drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cb9e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "legacy_tar.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ba63da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,10,1):\n",
    "    legacy_spec.iloc[i,1:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd41aebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "legacy_spectra = legacy_spec.iloc[:, 101::].copy()\n",
    "legacy_spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76185608",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,5,1):\n",
    "    legacy_spectra.iloc[i,:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b92cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "legacy_tar = legacy_tar[['Clay', 'Silt', 'Sand', 'TOC', 'CaCO3']]\n",
    "legacy_tar.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcefb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(legacy_spectra.shape)\n",
    "print(legacy_tar.shape)\n",
    "\n",
    "# Note that some id are missing in the data so we will do preprocessing to fix it ---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56de56c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing ID's are taken care by setting the index to ID and obtaining inner join.\n",
    "\n",
    "\n",
    "legacy_fr = pd.merge(legacy_tar, legacy_spectra, on = 'id', how = 'inner')\n",
    "\n",
    "legacy_fr.reset_index(inplace = True)\n",
    "legacy_fr .head(35)\n",
    "\n",
    "print('Missing:', legacy_fr.isnull().sum().sum())   # alternate to previous (inferred from next command)\n",
    "print(legacy_fr.isnull().sum()) # isnull applies to df but isnan applies only to ndarray\n",
    "\n",
    "legacy_fr.dropna(axis=0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7111ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra = legacy_fr.iloc[:, 6::]\n",
    "spectra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1acff7d",
   "metadata": {},
   "source": [
    "# Step 1b: Obtaining Targets (Outliers removal and Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ad22bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = legacy_fr\n",
    "# ------------- Target Isolation ----------------------\n",
    "\n",
    "clr = ['#F4A460', '#8B7355', '#A52A2A', 'green', 'blue']\n",
    "\n",
    "def isolate_targets(df, target_names):\n",
    "    T=[]\n",
    "    for i in range (0,len(target_names)):\n",
    "        T.append(df[target_names[i]])\n",
    "    return(T)\n",
    "    \n",
    "T = isolate_targets(df,target_names) \n",
    "\n",
    "def normalize_targets(T):          \n",
    "    NT =[]\n",
    "    for i in range(0, len(T)):\n",
    "        NT.append(min_max_normal(T[i].copy()))\n",
    "    return(NT)\n",
    "\n",
    "NT = normalize_targets(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd5b13f",
   "metadata": {},
   "source": [
    "# Step 1c: Spectra Preprocessing (Smooth, FOD/Contin, and Resample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aae8ec",
   "metadata": {},
   "source": [
    "## Savgol smoothing (order 1 and order 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99baabb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- Smoothed Spectra spec1 (savgol order 1) and spec2 (savgol order 2)  -----------\n",
    "\n",
    "spec1 = {}\n",
    "for i in window_lengths:\n",
    "    spec1[i] = filt_sg(spectra, i, 'sg1')                   \n",
    "\n",
    "spec2 = {}\n",
    "for i in window_lengths:\n",
    "    spec2[i] = filt_sg(spectra, i, 'sg2')\n",
    "\n",
    "smth_spec = sgsmooth (spectra, 3)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f253386c",
   "metadata": {},
   "source": [
    "## First Order Derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385ba98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fod_spec = fod(smth_spec)\n",
    "\n",
    "for i in range (0,5,1):\n",
    "    fod_spec.iloc[i,:].plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f55420f",
   "metadata": {},
   "source": [
    "## Continuum Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e800b1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_spec = continuum_removed(spec2[51])\n",
    "\n",
    "for i in range (0,5,1):\n",
    "    cr_spec.iloc[i,:].plot()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f470e6e5",
   "metadata": {},
   "source": [
    "## 1/logR Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a46141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_spec = ((1/spec2[51]).apply(np.log)).copy()\n",
    "log_spec.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88485b75",
   "metadata": {},
   "source": [
    "## Resampling (n_bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3293312",
   "metadata": {},
   "source": [
    "### 1. Sampled Original (sampled_spec: sampled clipped_spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f516492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_spec = {}\n",
    "for n in nbands_sampling:\n",
    "    sampled_spec[n] = resample_spectra (spec2[51], n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e039a42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range (0,5,1):\n",
    "#     sampled_spec[200].iloc[i,:].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b556f5a",
   "metadata": {},
   "source": [
    "### 2. Sampled Continuum Removed  (sampled_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab45619",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_cr = {}\n",
    "for n in nbands_sampling:\n",
    "    sampled_cr[n] = resample_spectra (cr_spec, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de689267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range (0,5,1):\n",
    "#     sampled_cr[200].iloc[i,:].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822eed90",
   "metadata": {},
   "source": [
    "### 3. Sampled FOD  (sampled_fod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd32e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_fod = {}\n",
    "for n in nbands_sampling:\n",
    "    sampled_fod[n] = resample_spectra (fod_spec, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaa74eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range (0,10,1):\n",
    "#     sampled_fod[200].iloc[i,:].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dcfe3c",
   "metadata": {},
   "source": [
    "## 4. Sampled Log (sampled_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaa0c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_log = {}\n",
    "for n in nbands_sampling:\n",
    "    sampled_log[n] = resample_spectra (log_spec, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6503b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range (0,10,1):\n",
    "#     sampled_fod[200].iloc[i,:].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad37e7ab",
   "metadata": {},
   "source": [
    "## Visualizing Processed Spectrum (variable samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc8344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spec (sample, process):\n",
    "    x1 = spec2[51].iloc[sample,:]\n",
    "    x1.plot()\n",
    "    if process == 'continuum':\n",
    "        x2 = cr_spec.iloc[sample,:]\n",
    "        x2.plot()\n",
    "    else: \n",
    "        x3 = fod_spec.iloc[sample,:]*100\n",
    "        \n",
    "        x3.plot()\n",
    "    plt.ylim([-0.6, 0.8])\n",
    "\n",
    "ipywidgets.interact(plot_spec, sample = (0, 80,1), process = ['fod', 'continuum'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12f62f4",
   "metadata": {},
   "source": [
    "## Correlation between wavelengths and Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd230431",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(['science','notebook','grid'])\n",
    "\n",
    "def plot_corr (target, spec_cr_fod, n_bands):\n",
    "    \n",
    "    i = target_names.index(target)    \n",
    "    \n",
    "    if  spec_cr_fod == 'spec':\n",
    "        r_val, p_val = find_rpval (resample_spectra(spec2[51], n_bands), T[i])\n",
    "        r_val.iloc[0,:].plot(color = clr[i])\n",
    "    elif  spec_cr_fod == 'cr':\n",
    "        r_cr, p_cr = find_rpval (resample_spectra(cr_spec, n_bands), T[i])\n",
    "        r_cr.iloc[0,:].plot(color = clr[i])\n",
    "    else:\n",
    "        r_fod, p_fod = find_rpval (resample_spectra(fod_spec, n_bands), T[i])\n",
    "        r_fod.iloc[0,:].plot(color = clr[i])\n",
    "    \n",
    "    plt.ylim([-0.9, 0.9])\n",
    "\n",
    "ipywidgets.interact(plot_corr, target = target_names, spec_cr_fod = ['spec', 'cr','fod'], n_bands = nbands_sampling)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00e07ff",
   "metadata": {},
   "source": [
    "# Step 2:  Parameters for Best Train-Test Split  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1300a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Mtree (Model Tree) ----------------------------------\n",
    "\n",
    "tst_siz = 0.20\n",
    "\n",
    "rand_t = [None] * (len(T))\n",
    "err_t = [None] * (len(T))\n",
    "\n",
    "print('Without Normalization:')\n",
    "for i in range (0,len(T)):\n",
    "    rand_t[i], err_t[i] = best_split(spectra.copy(), T[i], tst_siz) \n",
    "    print ('For '+ target_names[i]+ ' :test size =', tst_siz, '\\t min bin error=', err_t[i], '\\t at randome state =', rand_t[i])\n",
    "    \n",
    "rand_nt = [None] * (len(T))\n",
    "err_nt = [None] * (len(T))\n",
    "\n",
    "print('After Normalization:')\n",
    "for i in range (0,len(T)):\n",
    "    rand_nt[i], err_nt[i] = best_split(spectra.copy(), NT[i], tst_siz)     \n",
    "    print ('For '+ target_names[i]+ ' :test size =', tst_siz, '\\t min bin error=', err_nt[i], '\\t at randome state =', rand_nt[i])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e853a50",
   "metadata": {},
   "source": [
    "# Step 3: Parameters for Best Model Fit "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d531478b",
   "metadata": {},
   "source": [
    "## PLSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311d0c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "def best_param_PLSR (X_train, X_test, y_train, y_test, n_comp):\n",
    "        \n",
    "    iqrpL = []\n",
    "#     r2L = []\n",
    "#     rpdL = []\n",
    "    \n",
    "    for n in range(1,n_comp):\n",
    "        Model = PLSRegression(n_components=n, scale=True)\n",
    "        Model.fit(X_train, y_train)\n",
    "        y_pred = Model.predict(X_test, copy=True)\n",
    "        \n",
    "        iqrp_test = find_iqrp(y_pred, y_test)\n",
    "#         r2_test = find_r2(y_pred, y_test)         \n",
    "#         rpd_test = find_rpd(y_pred, y_test)\n",
    "               \n",
    "        iqrpL.append(iqrp_test)\n",
    "#         r2L.append(r2_test)\n",
    "#         rpdL.append(rpd_test)\n",
    "                \n",
    "    \n",
    "    IQRP = max(iqrpL)\n",
    "    n_iqrp = iqrpL.index(max(iqrpL))+1\n",
    "#     R2 = max(r2L)     \n",
    "#     n_r2 = r2L.index(R2)+1    \n",
    "#     RPD = max(rpdL)\n",
    "#     n_rpd = rpdL.index(RPD)+1\n",
    "    \n",
    "    #print('IQRP :', IQRP,  'R2 :', R2,  '>>> n_comp: ', n_iqrp)    \n",
    "    return (n_iqrp)\n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d908099c",
   "metadata": {},
   "source": [
    "# Step 4: Building Model Tree (Mtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07468618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('say \"your Meta Tree started building\"')\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a97c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Available machine learning regression models --------------------------------- (7)\n",
    "#ml_methods = ['mult', 'plsr', 'randomforest', 'svr', 'ridge', 'gbrt']\n",
    "#ml_methods = ['mult', 'plsr', 'cubist', 'randomforest', 'ridge' 'gbrt', 'svr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d247b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n_comp = 5\n",
    "\n",
    "def build_tree_for (method_name):\n",
    "    tree ={}\n",
    "    start = time.time()\n",
    "    m = method_name\n",
    "    #-- code to build tree----\n",
    "    for t in target_names:\n",
    "        print('tree for: '+ m +' ------> running on: ' + t)\n",
    "        tree[t] ={}\n",
    "        for tp in prepare_target:\n",
    "            tree[t][tp] ={}\n",
    "            for n in nbands_sampling:\n",
    "                tree[t][tp][n] ={}\n",
    "                for p in prepare_spec:\n",
    "                    tree[t][tp][n][p] ={}\n",
    "                    Y = tree[t][tp][n][p]\n",
    "                    \n",
    "                        \n",
    "                    #------ setting spec to appropriate (sampled) spectra----\n",
    "                    if p == 'none':\n",
    "                        if n == 0:\n",
    "                            if m == 'randomforest' or m == 'cubist' or m == 'gbrt':\n",
    "                                #---- reched here due to tree based methods e.g. randomforest--\n",
    "                                spec = sampled_spec[100]\n",
    "                            else:\n",
    "                                spec = spec2[51]\n",
    "                        else:\n",
    "                            #---- reached here with some n!=0----\n",
    "                            spec = sampled_spec[n]\n",
    "                        \n",
    "                    elif p == 'fod':\n",
    "                        if n == 0:\n",
    "                            if m == 'randomforest' or m == 'cubist' or m == 'gbrt':\n",
    "                                #---- reched here due to tree based methods e.g. randomforest--\n",
    "                                spec = sampled_fod[100]\n",
    "                            else:\n",
    "                                spec = fod_spec\n",
    "                        else:\n",
    "                            #---- reached here with some n!=0----\n",
    "                            spec = sampled_fod[n]\n",
    "                                \n",
    "                    elif p== 'continuum':  \n",
    "                        if n == 0:\n",
    "                            if m == 'randomforest' or m == 'cubist' or m == 'gbrt':\n",
    "                                #---- reched here due to tree based methods e.g. randomforest--\n",
    "                                spec = sampled_cr[100]\n",
    "                            else:\n",
    "                                spec = cr_spec\n",
    "                        else:\n",
    "                            #---- reached here with some n!=0----\n",
    "                            spec = sampled_cr[n]\n",
    "                        \n",
    "                    else: \n",
    "                        if n == 0:\n",
    "                            if m == 'randomforest' or m == 'cubist' or m == 'gbrt':\n",
    "                                #---- reched here due to tree based methods e.g. randomforest--\n",
    "                                spec = sampled_log[100]\n",
    "                            else:\n",
    "                                spec = log_spec\n",
    "                        else:\n",
    "                            #---- reached here with some n!=0----\n",
    "                            spec = sampled_log[n]\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    #---- target selection and normalization ---\n",
    "                    if tp == 'none':\n",
    "                        y = T[target_names.index(t)]\n",
    "                        rand_n = rand_t[target_names.index(t)]  #-- for future use in train-test split\n",
    "                    else:\n",
    "                        y = NT[target_names.index(t)]\n",
    "                        rand_n = rand_nt[target_names.index(t)] #-- for future use in train-test split\n",
    "                        #print('one more target set')\n",
    "                            \n",
    "                    #---- performing train-test split----------------------\n",
    "                    X_train, X_test, y_train, y_test = train_test_split(spec, y, test_size= tst_siz, random_state=rand_n)\n",
    "                        \n",
    "                        \n",
    "                    #------INITIATING the appropriate models-----------------------------------------------\n",
    "                    #----- PLSR: best parameters, fitting, and prediction\n",
    "                    if m == 'plsr':\n",
    "                        n_com = best_param_PLSR (X_train, X_test, y_train, y_test, max_n_comp)\n",
    "                        Y['n_comp'] = n_com\n",
    "                        Model = PLSRegression(n_components=n_com, scale=True)\n",
    "                    #----- MULTILINEAR:  fitting, and prediction---------- \n",
    "                    elif m == 'mult':\n",
    "                        Model = linear_model.LinearRegression()    \n",
    "                    #----- RANDOM_FOREST:   fitting, and prediction---------- \n",
    "                    elif m == 'randomforest': \n",
    "                        Model = RandomForestRegressor(random_state= 23)    \n",
    "                    #----- CUBIST REGRESSION:    fitting and prediction---------\n",
    "                    elif m == 'cubist':\n",
    "                        Model = Cubist(n_rules = 50, n_committees = 5, random_state = 42)    \n",
    "                    #------ SUPPORT VECTOR MACHINE FOR REGRESSION: fitting and prediction-----------      \n",
    "                    elif m == 'svr': \n",
    "                        Model = SVR()\n",
    "                    #------ RIDGE REGRESSION: fitting and prediction-----------      \n",
    "                    elif m == 'ridge': \n",
    "                        Model = KernelRidge()\n",
    "                    #------ GRADIENT BOOSTING REGRESSION: fitting and prediction-----------      \n",
    "                    else: \n",
    "                        Model = GradientBoostingRegressor()                         \n",
    "                        \n",
    "                    Model.fit(X_train, y_train)\n",
    "                    y_pred = Model.predict(X_test)\n",
    "                    yhat_pred = Model.predict(X_train)\n",
    "                                \n",
    "                    Y['test'] = y_test\n",
    "                    Y['testP'] = y_pred\n",
    "                    Y['train'] = y_train\n",
    "                    Y['trainP'] = yhat_pred\n",
    "                    Y['iqrp_test'] = find_iqrp(y_pred, y_test)\n",
    "                    Y['r2_test'] = find_r2(y_pred, y_test)\n",
    "                    Y['rpd_test'] = find_rpd(y_pred, y_test)\n",
    "                    Y['rmse_test'] = find_rmse(y_pred, y_test)\n",
    "                    \n",
    "                    Y['r2_train'] = find_r2(yhat_pred, y_train)\n",
    "                                                                \n",
    "                                                                         \n",
    "    end = time.time()                            \n",
    "    os.system('say \"your meta tree finished for one more method\"')                            \n",
    "\n",
    "    print('End time - Start time =', (end-start)) \n",
    "    \n",
    "    return (tree.copy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b71507",
   "metadata": {},
   "source": [
    "## Loading the saved Mtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bd545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open ('legacy.pickle', 'rb') as file:\n",
    "#     Mtree = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbe7179",
   "metadata": {},
   "source": [
    "## Mtree initialisation (do not run below code every time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc012ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mtree ={}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d3136d",
   "metadata": {},
   "source": [
    "## Creating different branches of Mtree (for separate methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e879891",
   "metadata": {},
   "source": [
    "### PLSR Branch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c34738",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mtree['plsr'] = build_tree_for ('plsr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e6ce3a",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02641a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mtree['mult'] = build_tree_for ('mult')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9d0acc",
   "metadata": {},
   "source": [
    "\n",
    "### Random Forest Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867391a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mtree['randomforest'] = build_tree_for ('randomforest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4358d9",
   "metadata": {},
   "source": [
    "### SVM Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfe29be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mtree['svr'] = build_tree_for ('svr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e189c3",
   "metadata": {},
   "source": [
    "### GBRT Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6139101",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mtree['gbrt'] = build_tree_for ('gbrt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ff0fb2",
   "metadata": {},
   "source": [
    "### Ridge Regression Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93db53ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mtree['ridge'] = build_tree_for ('ridge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee13435",
   "metadata": {},
   "source": [
    "### Cubist Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a9028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mtree['cubist'] = build_tree_for ('cubist')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e1faa5",
   "metadata": {},
   "source": [
    "## Best of all worlds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f85e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ml_methods = ['mult', 'plsr', 'randomforest','svr', 'ridge', 'gbrt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04241275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model_parameters (Mtree, target, method, scorer):\n",
    "    t=target\n",
    "    m= method\n",
    "    \n",
    "    best_score = -1\n",
    "    best_n_comp = 'NA'\n",
    "    \n",
    "    \n",
    "    for tp in prepare_target:\n",
    "        for n in nbands_sampling:\n",
    "            for p in prepare_spec:\n",
    "                Y = Mtree[m][t][tp][n][p]\n",
    "                r2_train = Y['r2_train']\n",
    "                r2_test = Y['r2_test']\n",
    "                    \n",
    "                if scorer == 'iqrp':\n",
    "                    cur_score = Y['iqrp_test']\n",
    "                elif scorer == 'rpd':\n",
    "                    cur_score = Y['rpd_test']\n",
    "                else:\n",
    "                    cur_score = Y['r2_test']  \n",
    "                    \n",
    "                if cur_score > best_score and r2_train >= r2_test:\n",
    "                    best_score = cur_score\n",
    "                    best_tp = tp\n",
    "                    best_n = n\n",
    "                    best_p = p\n",
    "                    if m == 'plsr':\n",
    "                        best_n_comp = Y['n_comp']\n",
    "                            \n",
    "    param_list = [scorer, np.round(best_score,2), 'Spec:', best_p, 'bands:', best_n, 'Tar:', best_tp]                                 \n",
    "    return (param_list)                                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8e5bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_score_for (Mtree, target, scorer):\n",
    "    \n",
    "    for method in ml_methods:\n",
    "        param_list= best_model_parameters (Mtree, target, method, scorer)\n",
    "        print('For:'+target+'->', param_list, ':'+method)\n",
    "     \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b948ff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score_for(Mtree, 'Sand', 'iqrp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41642a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score_for(Mtree, 'Sand', 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e14d8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score_for(Mtree, 'Silt', 'iqrp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a1a3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score_for(Mtree, 'Silt', 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfd1f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score_for(Mtree, 'Clay', 'iqrp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369bce9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score_for(Mtree, 'Clay', 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9829e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score_for(Mtree, 'TOC', 'iqrp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acbf868",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score_for(Mtree, 'TOC', 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574800e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score_for(Mtree, 'CaCO3', 'iqrp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15feb3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score_for(Mtree, 'CaCO3', 'r2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe74d829",
   "metadata": {},
   "source": [
    "## Plotting Model Accuracy (ipywidgets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd90a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_acc (target, target_preprocessing, spec_preprocessing, n_bands, method):\n",
    "    \n",
    "    m = method\n",
    "    t = target\n",
    "    \n",
    "    i = target_names.index(target)\n",
    "    \n",
    "    \n",
    "    p = spec_preprocessing\n",
    "    n = n_bands\n",
    "    tp = target_preprocessing\n",
    "    \n",
    "    Y = Mtree[m][t][tp][n][p]\n",
    "    \n",
    "    y_test = Y['test']\n",
    "    y_pred = Y['testP']\n",
    "    y_train = Y['train']\n",
    "    yhat_pred = Y['trainP']\n",
    "    \n",
    "    if m == 'plsr':\n",
    "        n_com = Y['n_comp']\n",
    "        y_pred = y_pred[:,0]\n",
    "        yhat_pred = yhat_pred[:,0]\n",
    "    \n",
    "    \n",
    "    iqrp_test = Y['iqrp_test']\n",
    "    r2_test = Y['r2_test']\n",
    "    rpd_test = Y['rpd_test']\n",
    "    \n",
    "    iqrp_train = find_iqrp(yhat_pred, y_train)\n",
    "    r2_train = find_r2(yhat_pred, y_train)\n",
    "    rpd_train = find_rpd(yhat_pred, y_train)\n",
    "    \n",
    "    y_tp = pd.DataFrame({'actual':y_test.values, 'predic': y_pred})\n",
    "    z = np.polyfit(y_test, y_pred, 1)\n",
    "    \n",
    "    yhat_tp = pd.DataFrame({'actual':y_train.values, 'predic': yhat_pred})\n",
    "    zhat = np.polyfit(y_train, yhat_pred, 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(1,2, figsize=(18,8))\n",
    "    \n",
    "    #with plt.style.context(('ggplot')): ---- PLOT of test-prediction --------------------------------------\n",
    "    y_tp.plot.scatter(ax= axes[0], x=\"actual\", y=\"predic\", alpha=0.8, color = clr[i], edgecolors='k')\n",
    "    axes[0].plot(y_test, np.polyval(z, y_test),  c='blue', linewidth=1)\n",
    "    axes[0].plot(y_test, y_test, color='green', linewidth=1)\n",
    "    axes[0].tick_params(axis='both', labelsize=10)\n",
    "    axes[0].text(0.05, 0.95, target_names[i]+' (Test Data)', transform=axes[0].transAxes, fontsize = 20, color = clr[i])\n",
    "    axes[0].text(0.05, 0.90, 'IQRP ={:.2f}'.format(iqrp_test), transform=axes[0].transAxes, fontsize = 16)\n",
    "    axes[0].text(0.05, 0.85, 'RPD ={:.2f}'.format(rpd_test), transform=axes[0].transAxes, fontsize = 16)\n",
    "    axes[0].text(0.05, 0.80, 'R2 ={:.2f}'.format(np.round(r2_test,3)), transform=axes[0].transAxes, fontsize = 16)\n",
    "    axes[0].text(0.95, 0.15, 'Method: '+method, transform=axes[0].transAxes, \n",
    "                    horizontalalignment='right', fontsize = 20)\n",
    "    \n",
    "    if method == 'plsr':\n",
    "        axes[0].text(0.95, 0.05, 'n_component={:.2f}'.format(n_com), transform=axes[0].transAxes, \n",
    "                    horizontalalignment='right', fontsize = 12)\n",
    "    \n",
    "    #---------------------------------- ---- PLOT of train-prediction --------------------------------------\n",
    "    yhat_tp.plot.scatter(ax= axes[1], x=\"actual\", y=\"predic\", alpha=0.8, color = clr[i], edgecolors='k')\n",
    "    axes[1].plot(y_train, np.polyval(zhat, y_train),  c='blue', linewidth=1)\n",
    "    axes[1].plot(y_train, y_train, color='green', linewidth=1)\n",
    "    axes[1].tick_params(axis='both', labelsize=10)\n",
    "    axes[1].text(0.05, 0.95,  target_names[i]+' (Training Data)', transform=axes[1].transAxes,fontsize = 20, color = clr[i])\n",
    "    axes[1].text(0.05, 0.90, 'IQRP ={:.2f}'.format(iqrp_train), transform=axes[1].transAxes, fontsize = 16)\n",
    "    axes[1].text(0.05, 0.85, 'RPD ={:.2f}'.format(rpd_train), transform=axes[1].transAxes, fontsize = 16)\n",
    "    axes[1].text(0.05, 0.80, 'R2 ={:.2f}'.format(np.round(r2_train,3)), transform=axes[1].transAxes, fontsize = 16)\n",
    "    axes[1].text(0.95, 0.15, 'Method: '+method, transform=axes[1].transAxes, \n",
    "                    horizontalalignment='right', fontsize = 20)\n",
    "    return    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b9db47",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipywidgets.interact(plot_model_acc, target = target_names,target_preprocessing = prepare_target, \\\n",
    "                    method = ml_methods, spec_preprocessing = prepare_spec, n_bands = nbands_sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8c3328",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('legacy.pickle', 'wb') as file:\n",
    "    pickle.dump(Mtree, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84323e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
