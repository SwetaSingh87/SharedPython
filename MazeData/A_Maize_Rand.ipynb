{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c173cf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from imbalanced-learn) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from imbalanced-learn) (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from imbalanced-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from imbalanced-learn) (1.10.1)\n",
      "Requirement already satisfied: ipympl in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (0.9.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from ipympl) (9.4.0)\n",
      "Requirement already satisfied: matplotlib<4,>=3.4.0 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from ipympl) (3.7.1)\n",
      "Requirement already satisfied: ipython<9 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from ipympl) (8.10.0)\n",
      "Requirement already satisfied: traitlets<6 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from ipympl) (5.7.1)\n",
      "Requirement already satisfied: ipywidgets<9,>=7.6.0 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from ipympl) (8.0.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from ipympl) (1.24.3)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from ipympl) (0.2.0)\n",
      "Requirement already satisfied: backcall in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from ipython<9->ipympl) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from ipython<9->ipympl) (0.18.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from ipython<9->ipympl) (0.4.6)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from ipython<9->ipympl) (0.7.5)\n",
      "Requirement already satisfied: stack-data in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from ipython<9->ipympl) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from ipython<9->ipympl) (5.1.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from ipython<9->ipympl) (0.1.6)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from ipython<9->ipympl) (2.11.2)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.30 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from ipython<9->ipympl) (3.0.36)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from ipywidgets<9,>=7.6.0->ipympl) (3.0.7)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from ipywidgets<9,>=7.6.0->ipympl) (6.19.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from ipywidgets<9,>=7.6.0->ipympl) (4.0.7)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from matplotlib<4,>=3.4.0->ipympl) (5.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from matplotlib<4,>=3.4.0->ipympl) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from matplotlib<4,>=3.4.0->ipympl) (1.0.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from matplotlib<4,>=3.4.0->ipympl) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from matplotlib<4,>=3.4.0->ipympl) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from matplotlib<4,>=3.4.0->ipympl) (4.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from matplotlib<4,>=3.4.0->ipympl) (23.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from matplotlib<4,>=3.4.0->ipympl) (1.4.4)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib<4,>=3.4.0->ipympl) (3.11.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (5.9.0)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (1.5.6)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (7.4.9)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (6.2)\n",
      "Requirement already satisfied: debugpy>=1.0 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (1.5.1)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (0.1.2)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (23.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from jedi>=0.16->ipython<9->ipympl) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.30->ipython<9->ipympl) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib<4,>=3.4.0->ipympl) (1.16.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from stack-data->ipython<9->ipympl) (0.2.2)\n",
      "Requirement already satisfied: asttokens in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from stack-data->ipython<9->ipympl) (2.0.5)\n",
      "Requirement already satisfied: executing in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from stack-data->ipython<9->ipympl) (0.8.3)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (5.2.0)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (0.4)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (305.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (2.5.2)\n",
      "Requirement already satisfied: shapely in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: numpy>=1.14 in c:\\users\\abhis\\anaconda3\\envs\\rp_env\\lib\\site-packages (from shapely) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl\n",
    "!pip install imbalanced-learn\n",
    "!pip3 install ipympl\n",
    "!pip install shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22684781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import os, sys\n",
    "from numpy import nan\n",
    "import re\n",
    "import ipympl\n",
    "# from IPython.core.display import display, HTML\n",
    "import json\n",
    "from os import listdir\n",
    "import glob\n",
    "import math\n",
    "from IPython.display import Image, display, HTML\n",
    "from shapely.geometry import mapping\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, RepeatedKFold, cross_val_predict\n",
    "from sklearn.metrics import r2_score, mean_squared_error, precision_score, recall_score, mean_absolute_error, make_scorer\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, LeaveOneOut, cross_validate\n",
    "from sklearn.impute import SimpleImputer\n",
    "#from tqdm.notebook import tqdm\n",
    "from sklearn.svm import SVC\n",
    "#from tqdm import tqdm\n",
    "import pickle\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy import stats\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "pd.options.display.max_columns = 100\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd5b13f",
   "metadata": {},
   "source": [
    "# Step 1: Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "492df528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>350</th>\n",
       "      <th>351</th>\n",
       "      <th>352</th>\n",
       "      <th>353</th>\n",
       "      <th>354</th>\n",
       "      <th>355</th>\n",
       "      <th>356</th>\n",
       "      <th>357</th>\n",
       "      <th>358</th>\n",
       "      <th>359</th>\n",
       "      <th>360</th>\n",
       "      <th>361</th>\n",
       "      <th>362</th>\n",
       "      <th>363</th>\n",
       "      <th>364</th>\n",
       "      <th>365</th>\n",
       "      <th>366</th>\n",
       "      <th>367</th>\n",
       "      <th>368</th>\n",
       "      <th>369</th>\n",
       "      <th>370</th>\n",
       "      <th>371</th>\n",
       "      <th>372</th>\n",
       "      <th>373</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "      <th>384</th>\n",
       "      <th>385</th>\n",
       "      <th>386</th>\n",
       "      <th>387</th>\n",
       "      <th>388</th>\n",
       "      <th>389</th>\n",
       "      <th>390</th>\n",
       "      <th>391</th>\n",
       "      <th>392</th>\n",
       "      <th>393</th>\n",
       "      <th>394</th>\n",
       "      <th>395</th>\n",
       "      <th>396</th>\n",
       "      <th>397</th>\n",
       "      <th>398</th>\n",
       "      <th>...</th>\n",
       "      <th>2451</th>\n",
       "      <th>2452</th>\n",
       "      <th>2453</th>\n",
       "      <th>2454</th>\n",
       "      <th>2455</th>\n",
       "      <th>2456</th>\n",
       "      <th>2457</th>\n",
       "      <th>2458</th>\n",
       "      <th>2459</th>\n",
       "      <th>2460</th>\n",
       "      <th>2461</th>\n",
       "      <th>2462</th>\n",
       "      <th>2463</th>\n",
       "      <th>2464</th>\n",
       "      <th>2465</th>\n",
       "      <th>2466</th>\n",
       "      <th>2467</th>\n",
       "      <th>2468</th>\n",
       "      <th>2469</th>\n",
       "      <th>2470</th>\n",
       "      <th>2471</th>\n",
       "      <th>2472</th>\n",
       "      <th>2473</th>\n",
       "      <th>2474</th>\n",
       "      <th>2475</th>\n",
       "      <th>2476</th>\n",
       "      <th>2477</th>\n",
       "      <th>2478</th>\n",
       "      <th>2479</th>\n",
       "      <th>2480</th>\n",
       "      <th>2481</th>\n",
       "      <th>2482</th>\n",
       "      <th>2483</th>\n",
       "      <th>2484</th>\n",
       "      <th>2485</th>\n",
       "      <th>2486</th>\n",
       "      <th>2487</th>\n",
       "      <th>2488</th>\n",
       "      <th>2489</th>\n",
       "      <th>2490</th>\n",
       "      <th>2491</th>\n",
       "      <th>2492</th>\n",
       "      <th>2493</th>\n",
       "      <th>2494</th>\n",
       "      <th>2495</th>\n",
       "      <th>2496</th>\n",
       "      <th>2497</th>\n",
       "      <th>2498</th>\n",
       "      <th>2499</th>\n",
       "      <th>2500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.106430</td>\n",
       "      <td>0.098860</td>\n",
       "      <td>0.088910</td>\n",
       "      <td>0.077947</td>\n",
       "      <td>0.072843</td>\n",
       "      <td>0.093862</td>\n",
       "      <td>0.090015</td>\n",
       "      <td>0.070006</td>\n",
       "      <td>0.090431</td>\n",
       "      <td>0.084056</td>\n",
       "      <td>0.073512</td>\n",
       "      <td>0.073086</td>\n",
       "      <td>0.067475</td>\n",
       "      <td>0.068706</td>\n",
       "      <td>0.068850</td>\n",
       "      <td>0.063061</td>\n",
       "      <td>0.064384</td>\n",
       "      <td>0.066461</td>\n",
       "      <td>0.070936</td>\n",
       "      <td>0.078129</td>\n",
       "      <td>0.069275</td>\n",
       "      <td>0.064903</td>\n",
       "      <td>0.067154</td>\n",
       "      <td>0.065122</td>\n",
       "      <td>0.060868</td>\n",
       "      <td>0.058503</td>\n",
       "      <td>0.059176</td>\n",
       "      <td>0.060199</td>\n",
       "      <td>0.059542</td>\n",
       "      <td>0.056787</td>\n",
       "      <td>0.053711</td>\n",
       "      <td>0.056561</td>\n",
       "      <td>0.059718</td>\n",
       "      <td>0.059836</td>\n",
       "      <td>0.056556</td>\n",
       "      <td>0.059190</td>\n",
       "      <td>0.057359</td>\n",
       "      <td>0.052478</td>\n",
       "      <td>0.053686</td>\n",
       "      <td>0.054506</td>\n",
       "      <td>0.055347</td>\n",
       "      <td>0.055851</td>\n",
       "      <td>0.053617</td>\n",
       "      <td>0.055252</td>\n",
       "      <td>0.058038</td>\n",
       "      <td>0.058547</td>\n",
       "      <td>0.057006</td>\n",
       "      <td>0.056262</td>\n",
       "      <td>0.055866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056319</td>\n",
       "      <td>0.055844</td>\n",
       "      <td>0.055375</td>\n",
       "      <td>0.055058</td>\n",
       "      <td>0.054726</td>\n",
       "      <td>0.054421</td>\n",
       "      <td>0.054162</td>\n",
       "      <td>0.053836</td>\n",
       "      <td>0.053488</td>\n",
       "      <td>0.053203</td>\n",
       "      <td>0.052905</td>\n",
       "      <td>0.052548</td>\n",
       "      <td>0.052264</td>\n",
       "      <td>0.051997</td>\n",
       "      <td>0.051595</td>\n",
       "      <td>0.051157</td>\n",
       "      <td>0.050832</td>\n",
       "      <td>0.050384</td>\n",
       "      <td>0.049892</td>\n",
       "      <td>0.049764</td>\n",
       "      <td>0.049538</td>\n",
       "      <td>0.049473</td>\n",
       "      <td>0.049243</td>\n",
       "      <td>0.048725</td>\n",
       "      <td>0.048397</td>\n",
       "      <td>0.048044</td>\n",
       "      <td>0.047772</td>\n",
       "      <td>0.047821</td>\n",
       "      <td>0.047637</td>\n",
       "      <td>0.047205</td>\n",
       "      <td>0.046992</td>\n",
       "      <td>0.046813</td>\n",
       "      <td>0.046602</td>\n",
       "      <td>0.046607</td>\n",
       "      <td>0.046481</td>\n",
       "      <td>0.046230</td>\n",
       "      <td>0.045912</td>\n",
       "      <td>0.045301</td>\n",
       "      <td>0.045138</td>\n",
       "      <td>0.045353</td>\n",
       "      <td>0.045184</td>\n",
       "      <td>0.045096</td>\n",
       "      <td>0.045050</td>\n",
       "      <td>0.044625</td>\n",
       "      <td>0.044355</td>\n",
       "      <td>0.044527</td>\n",
       "      <td>0.044399</td>\n",
       "      <td>0.043810</td>\n",
       "      <td>0.043605</td>\n",
       "      <td>0.043599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.097093</td>\n",
       "      <td>0.103140</td>\n",
       "      <td>0.083749</td>\n",
       "      <td>0.066028</td>\n",
       "      <td>0.072148</td>\n",
       "      <td>0.087739</td>\n",
       "      <td>0.098567</td>\n",
       "      <td>0.092104</td>\n",
       "      <td>0.062686</td>\n",
       "      <td>0.095519</td>\n",
       "      <td>0.107648</td>\n",
       "      <td>0.072792</td>\n",
       "      <td>0.071982</td>\n",
       "      <td>0.077794</td>\n",
       "      <td>0.071373</td>\n",
       "      <td>0.050405</td>\n",
       "      <td>0.051561</td>\n",
       "      <td>0.051083</td>\n",
       "      <td>0.053461</td>\n",
       "      <td>0.064439</td>\n",
       "      <td>0.047219</td>\n",
       "      <td>0.043872</td>\n",
       "      <td>0.056082</td>\n",
       "      <td>0.057424</td>\n",
       "      <td>0.058312</td>\n",
       "      <td>0.060843</td>\n",
       "      <td>0.060995</td>\n",
       "      <td>0.048972</td>\n",
       "      <td>0.051361</td>\n",
       "      <td>0.049914</td>\n",
       "      <td>0.036760</td>\n",
       "      <td>0.052602</td>\n",
       "      <td>0.054866</td>\n",
       "      <td>0.049009</td>\n",
       "      <td>0.052006</td>\n",
       "      <td>0.052774</td>\n",
       "      <td>0.050657</td>\n",
       "      <td>0.049641</td>\n",
       "      <td>0.054484</td>\n",
       "      <td>0.047719</td>\n",
       "      <td>0.044079</td>\n",
       "      <td>0.048591</td>\n",
       "      <td>0.048487</td>\n",
       "      <td>0.048350</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>0.047974</td>\n",
       "      <td>0.048457</td>\n",
       "      <td>0.048776</td>\n",
       "      <td>0.048339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047114</td>\n",
       "      <td>0.046864</td>\n",
       "      <td>0.046694</td>\n",
       "      <td>0.046366</td>\n",
       "      <td>0.045964</td>\n",
       "      <td>0.045663</td>\n",
       "      <td>0.045325</td>\n",
       "      <td>0.045112</td>\n",
       "      <td>0.044898</td>\n",
       "      <td>0.044548</td>\n",
       "      <td>0.044306</td>\n",
       "      <td>0.044098</td>\n",
       "      <td>0.043800</td>\n",
       "      <td>0.043470</td>\n",
       "      <td>0.043094</td>\n",
       "      <td>0.042753</td>\n",
       "      <td>0.042579</td>\n",
       "      <td>0.042447</td>\n",
       "      <td>0.042235</td>\n",
       "      <td>0.042065</td>\n",
       "      <td>0.041800</td>\n",
       "      <td>0.041422</td>\n",
       "      <td>0.041198</td>\n",
       "      <td>0.041026</td>\n",
       "      <td>0.040759</td>\n",
       "      <td>0.040543</td>\n",
       "      <td>0.040383</td>\n",
       "      <td>0.040137</td>\n",
       "      <td>0.039915</td>\n",
       "      <td>0.039878</td>\n",
       "      <td>0.039731</td>\n",
       "      <td>0.039409</td>\n",
       "      <td>0.039179</td>\n",
       "      <td>0.038988</td>\n",
       "      <td>0.038808</td>\n",
       "      <td>0.038687</td>\n",
       "      <td>0.038522</td>\n",
       "      <td>0.038289</td>\n",
       "      <td>0.038160</td>\n",
       "      <td>0.038160</td>\n",
       "      <td>0.038003</td>\n",
       "      <td>0.037762</td>\n",
       "      <td>0.037672</td>\n",
       "      <td>0.037440</td>\n",
       "      <td>0.037419</td>\n",
       "      <td>0.037894</td>\n",
       "      <td>0.037886</td>\n",
       "      <td>0.037521</td>\n",
       "      <td>0.037509</td>\n",
       "      <td>0.037503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.125163</td>\n",
       "      <td>0.124518</td>\n",
       "      <td>0.127662</td>\n",
       "      <td>0.127982</td>\n",
       "      <td>0.127173</td>\n",
       "      <td>0.115487</td>\n",
       "      <td>0.111536</td>\n",
       "      <td>0.112970</td>\n",
       "      <td>0.100015</td>\n",
       "      <td>0.079823</td>\n",
       "      <td>0.082658</td>\n",
       "      <td>0.102968</td>\n",
       "      <td>0.088516</td>\n",
       "      <td>0.094781</td>\n",
       "      <td>0.094515</td>\n",
       "      <td>0.070130</td>\n",
       "      <td>0.074827</td>\n",
       "      <td>0.079704</td>\n",
       "      <td>0.075530</td>\n",
       "      <td>0.064953</td>\n",
       "      <td>0.070498</td>\n",
       "      <td>0.072435</td>\n",
       "      <td>0.068536</td>\n",
       "      <td>0.068483</td>\n",
       "      <td>0.070248</td>\n",
       "      <td>0.065726</td>\n",
       "      <td>0.058498</td>\n",
       "      <td>0.066385</td>\n",
       "      <td>0.070785</td>\n",
       "      <td>0.069656</td>\n",
       "      <td>0.066325</td>\n",
       "      <td>0.068654</td>\n",
       "      <td>0.066584</td>\n",
       "      <td>0.063986</td>\n",
       "      <td>0.066945</td>\n",
       "      <td>0.068194</td>\n",
       "      <td>0.069426</td>\n",
       "      <td>0.069469</td>\n",
       "      <td>0.065436</td>\n",
       "      <td>0.058559</td>\n",
       "      <td>0.057705</td>\n",
       "      <td>0.061731</td>\n",
       "      <td>0.055525</td>\n",
       "      <td>0.059083</td>\n",
       "      <td>0.065252</td>\n",
       "      <td>0.065030</td>\n",
       "      <td>0.058985</td>\n",
       "      <td>0.062260</td>\n",
       "      <td>0.068849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055637</td>\n",
       "      <td>0.055295</td>\n",
       "      <td>0.055052</td>\n",
       "      <td>0.054888</td>\n",
       "      <td>0.054461</td>\n",
       "      <td>0.054179</td>\n",
       "      <td>0.054169</td>\n",
       "      <td>0.053794</td>\n",
       "      <td>0.053397</td>\n",
       "      <td>0.053165</td>\n",
       "      <td>0.052658</td>\n",
       "      <td>0.052337</td>\n",
       "      <td>0.052304</td>\n",
       "      <td>0.051942</td>\n",
       "      <td>0.051510</td>\n",
       "      <td>0.051305</td>\n",
       "      <td>0.051045</td>\n",
       "      <td>0.050822</td>\n",
       "      <td>0.050715</td>\n",
       "      <td>0.050409</td>\n",
       "      <td>0.050127</td>\n",
       "      <td>0.049959</td>\n",
       "      <td>0.049740</td>\n",
       "      <td>0.049392</td>\n",
       "      <td>0.049137</td>\n",
       "      <td>0.048937</td>\n",
       "      <td>0.048751</td>\n",
       "      <td>0.048657</td>\n",
       "      <td>0.048485</td>\n",
       "      <td>0.048162</td>\n",
       "      <td>0.048046</td>\n",
       "      <td>0.048203</td>\n",
       "      <td>0.048045</td>\n",
       "      <td>0.047810</td>\n",
       "      <td>0.047612</td>\n",
       "      <td>0.047058</td>\n",
       "      <td>0.046735</td>\n",
       "      <td>0.046689</td>\n",
       "      <td>0.046588</td>\n",
       "      <td>0.046480</td>\n",
       "      <td>0.046410</td>\n",
       "      <td>0.046467</td>\n",
       "      <td>0.046406</td>\n",
       "      <td>0.046281</td>\n",
       "      <td>0.046181</td>\n",
       "      <td>0.046085</td>\n",
       "      <td>0.045880</td>\n",
       "      <td>0.045441</td>\n",
       "      <td>0.045417</td>\n",
       "      <td>0.045704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.101250</td>\n",
       "      <td>0.094361</td>\n",
       "      <td>0.086309</td>\n",
       "      <td>0.090478</td>\n",
       "      <td>0.107267</td>\n",
       "      <td>0.088325</td>\n",
       "      <td>0.076786</td>\n",
       "      <td>0.083318</td>\n",
       "      <td>0.080874</td>\n",
       "      <td>0.084091</td>\n",
       "      <td>0.084152</td>\n",
       "      <td>0.079871</td>\n",
       "      <td>0.085310</td>\n",
       "      <td>0.087679</td>\n",
       "      <td>0.079508</td>\n",
       "      <td>0.062870</td>\n",
       "      <td>0.059119</td>\n",
       "      <td>0.068288</td>\n",
       "      <td>0.075749</td>\n",
       "      <td>0.069223</td>\n",
       "      <td>0.066564</td>\n",
       "      <td>0.066067</td>\n",
       "      <td>0.066501</td>\n",
       "      <td>0.067355</td>\n",
       "      <td>0.066727</td>\n",
       "      <td>0.062973</td>\n",
       "      <td>0.059307</td>\n",
       "      <td>0.064315</td>\n",
       "      <td>0.064843</td>\n",
       "      <td>0.063219</td>\n",
       "      <td>0.062928</td>\n",
       "      <td>0.062292</td>\n",
       "      <td>0.062633</td>\n",
       "      <td>0.062704</td>\n",
       "      <td>0.061520</td>\n",
       "      <td>0.063693</td>\n",
       "      <td>0.063807</td>\n",
       "      <td>0.061729</td>\n",
       "      <td>0.061046</td>\n",
       "      <td>0.060998</td>\n",
       "      <td>0.061302</td>\n",
       "      <td>0.061599</td>\n",
       "      <td>0.061438</td>\n",
       "      <td>0.063316</td>\n",
       "      <td>0.064415</td>\n",
       "      <td>0.062895</td>\n",
       "      <td>0.062514</td>\n",
       "      <td>0.061758</td>\n",
       "      <td>0.062089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063220</td>\n",
       "      <td>0.062894</td>\n",
       "      <td>0.062567</td>\n",
       "      <td>0.062176</td>\n",
       "      <td>0.061807</td>\n",
       "      <td>0.061366</td>\n",
       "      <td>0.060850</td>\n",
       "      <td>0.060529</td>\n",
       "      <td>0.060285</td>\n",
       "      <td>0.059850</td>\n",
       "      <td>0.059491</td>\n",
       "      <td>0.059236</td>\n",
       "      <td>0.058814</td>\n",
       "      <td>0.058425</td>\n",
       "      <td>0.058187</td>\n",
       "      <td>0.057785</td>\n",
       "      <td>0.057324</td>\n",
       "      <td>0.057021</td>\n",
       "      <td>0.056671</td>\n",
       "      <td>0.056601</td>\n",
       "      <td>0.056302</td>\n",
       "      <td>0.055740</td>\n",
       "      <td>0.055415</td>\n",
       "      <td>0.055086</td>\n",
       "      <td>0.054752</td>\n",
       "      <td>0.054657</td>\n",
       "      <td>0.054514</td>\n",
       "      <td>0.054307</td>\n",
       "      <td>0.054005</td>\n",
       "      <td>0.053654</td>\n",
       "      <td>0.053363</td>\n",
       "      <td>0.052884</td>\n",
       "      <td>0.052615</td>\n",
       "      <td>0.052670</td>\n",
       "      <td>0.052539</td>\n",
       "      <td>0.052351</td>\n",
       "      <td>0.052190</td>\n",
       "      <td>0.051985</td>\n",
       "      <td>0.051738</td>\n",
       "      <td>0.051436</td>\n",
       "      <td>0.051306</td>\n",
       "      <td>0.051264</td>\n",
       "      <td>0.051125</td>\n",
       "      <td>0.051135</td>\n",
       "      <td>0.050983</td>\n",
       "      <td>0.050531</td>\n",
       "      <td>0.050280</td>\n",
       "      <td>0.050144</td>\n",
       "      <td>0.049989</td>\n",
       "      <td>0.049945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.096988</td>\n",
       "      <td>0.106913</td>\n",
       "      <td>0.099666</td>\n",
       "      <td>0.085338</td>\n",
       "      <td>0.086283</td>\n",
       "      <td>0.086462</td>\n",
       "      <td>0.085748</td>\n",
       "      <td>0.084381</td>\n",
       "      <td>0.081730</td>\n",
       "      <td>0.073750</td>\n",
       "      <td>0.071237</td>\n",
       "      <td>0.074610</td>\n",
       "      <td>0.067910</td>\n",
       "      <td>0.071604</td>\n",
       "      <td>0.070636</td>\n",
       "      <td>0.056747</td>\n",
       "      <td>0.058965</td>\n",
       "      <td>0.066335</td>\n",
       "      <td>0.069005</td>\n",
       "      <td>0.063023</td>\n",
       "      <td>0.066893</td>\n",
       "      <td>0.068612</td>\n",
       "      <td>0.064870</td>\n",
       "      <td>0.059740</td>\n",
       "      <td>0.061785</td>\n",
       "      <td>0.060540</td>\n",
       "      <td>0.054180</td>\n",
       "      <td>0.053703</td>\n",
       "      <td>0.055616</td>\n",
       "      <td>0.058491</td>\n",
       "      <td>0.060636</td>\n",
       "      <td>0.058437</td>\n",
       "      <td>0.059741</td>\n",
       "      <td>0.059445</td>\n",
       "      <td>0.052222</td>\n",
       "      <td>0.053134</td>\n",
       "      <td>0.056167</td>\n",
       "      <td>0.057535</td>\n",
       "      <td>0.056435</td>\n",
       "      <td>0.057803</td>\n",
       "      <td>0.058252</td>\n",
       "      <td>0.056967</td>\n",
       "      <td>0.057813</td>\n",
       "      <td>0.055887</td>\n",
       "      <td>0.054408</td>\n",
       "      <td>0.055950</td>\n",
       "      <td>0.056722</td>\n",
       "      <td>0.056795</td>\n",
       "      <td>0.055932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052968</td>\n",
       "      <td>0.052582</td>\n",
       "      <td>0.052181</td>\n",
       "      <td>0.051812</td>\n",
       "      <td>0.051542</td>\n",
       "      <td>0.051262</td>\n",
       "      <td>0.050935</td>\n",
       "      <td>0.050440</td>\n",
       "      <td>0.049974</td>\n",
       "      <td>0.049768</td>\n",
       "      <td>0.049507</td>\n",
       "      <td>0.049181</td>\n",
       "      <td>0.048957</td>\n",
       "      <td>0.048599</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>0.048050</td>\n",
       "      <td>0.047667</td>\n",
       "      <td>0.047319</td>\n",
       "      <td>0.047089</td>\n",
       "      <td>0.046949</td>\n",
       "      <td>0.046656</td>\n",
       "      <td>0.046121</td>\n",
       "      <td>0.045817</td>\n",
       "      <td>0.045615</td>\n",
       "      <td>0.045346</td>\n",
       "      <td>0.045268</td>\n",
       "      <td>0.045105</td>\n",
       "      <td>0.044743</td>\n",
       "      <td>0.044431</td>\n",
       "      <td>0.044120</td>\n",
       "      <td>0.043897</td>\n",
       "      <td>0.043757</td>\n",
       "      <td>0.043535</td>\n",
       "      <td>0.043305</td>\n",
       "      <td>0.043162</td>\n",
       "      <td>0.043033</td>\n",
       "      <td>0.042843</td>\n",
       "      <td>0.042801</td>\n",
       "      <td>0.042619</td>\n",
       "      <td>0.042022</td>\n",
       "      <td>0.041867</td>\n",
       "      <td>0.042194</td>\n",
       "      <td>0.042013</td>\n",
       "      <td>0.041689</td>\n",
       "      <td>0.041549</td>\n",
       "      <td>0.040944</td>\n",
       "      <td>0.040854</td>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.041670</td>\n",
       "      <td>0.041102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2152 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       350       351       352       353       354       355       356  \\\n",
       "0   1  0.106430  0.098860  0.088910  0.077947  0.072843  0.093862  0.090015   \n",
       "1   2  0.097093  0.103140  0.083749  0.066028  0.072148  0.087739  0.098567   \n",
       "2   3  0.125163  0.124518  0.127662  0.127982  0.127173  0.115487  0.111536   \n",
       "3   4  0.101250  0.094361  0.086309  0.090478  0.107267  0.088325  0.076786   \n",
       "4   5  0.096988  0.106913  0.099666  0.085338  0.086283  0.086462  0.085748   \n",
       "\n",
       "        357       358       359       360       361       362       363  \\\n",
       "0  0.070006  0.090431  0.084056  0.073512  0.073086  0.067475  0.068706   \n",
       "1  0.092104  0.062686  0.095519  0.107648  0.072792  0.071982  0.077794   \n",
       "2  0.112970  0.100015  0.079823  0.082658  0.102968  0.088516  0.094781   \n",
       "3  0.083318  0.080874  0.084091  0.084152  0.079871  0.085310  0.087679   \n",
       "4  0.084381  0.081730  0.073750  0.071237  0.074610  0.067910  0.071604   \n",
       "\n",
       "        364       365       366       367       368       369       370  \\\n",
       "0  0.068850  0.063061  0.064384  0.066461  0.070936  0.078129  0.069275   \n",
       "1  0.071373  0.050405  0.051561  0.051083  0.053461  0.064439  0.047219   \n",
       "2  0.094515  0.070130  0.074827  0.079704  0.075530  0.064953  0.070498   \n",
       "3  0.079508  0.062870  0.059119  0.068288  0.075749  0.069223  0.066564   \n",
       "4  0.070636  0.056747  0.058965  0.066335  0.069005  0.063023  0.066893   \n",
       "\n",
       "        371       372       373       374       375       376       377  \\\n",
       "0  0.064903  0.067154  0.065122  0.060868  0.058503  0.059176  0.060199   \n",
       "1  0.043872  0.056082  0.057424  0.058312  0.060843  0.060995  0.048972   \n",
       "2  0.072435  0.068536  0.068483  0.070248  0.065726  0.058498  0.066385   \n",
       "3  0.066067  0.066501  0.067355  0.066727  0.062973  0.059307  0.064315   \n",
       "4  0.068612  0.064870  0.059740  0.061785  0.060540  0.054180  0.053703   \n",
       "\n",
       "        378       379       380       381       382       383       384  \\\n",
       "0  0.059542  0.056787  0.053711  0.056561  0.059718  0.059836  0.056556   \n",
       "1  0.051361  0.049914  0.036760  0.052602  0.054866  0.049009  0.052006   \n",
       "2  0.070785  0.069656  0.066325  0.068654  0.066584  0.063986  0.066945   \n",
       "3  0.064843  0.063219  0.062928  0.062292  0.062633  0.062704  0.061520   \n",
       "4  0.055616  0.058491  0.060636  0.058437  0.059741  0.059445  0.052222   \n",
       "\n",
       "        385       386       387       388       389       390       391  \\\n",
       "0  0.059190  0.057359  0.052478  0.053686  0.054506  0.055347  0.055851   \n",
       "1  0.052774  0.050657  0.049641  0.054484  0.047719  0.044079  0.048591   \n",
       "2  0.068194  0.069426  0.069469  0.065436  0.058559  0.057705  0.061731   \n",
       "3  0.063693  0.063807  0.061729  0.061046  0.060998  0.061302  0.061599   \n",
       "4  0.053134  0.056167  0.057535  0.056435  0.057803  0.058252  0.056967   \n",
       "\n",
       "        392       393       394       395       396       397       398  ...  \\\n",
       "0  0.053617  0.055252  0.058038  0.058547  0.057006  0.056262  0.055866  ...   \n",
       "1  0.048487  0.048350  0.048275  0.047974  0.048457  0.048776  0.048339  ...   \n",
       "2  0.055525  0.059083  0.065252  0.065030  0.058985  0.062260  0.068849  ...   \n",
       "3  0.061438  0.063316  0.064415  0.062895  0.062514  0.061758  0.062089  ...   \n",
       "4  0.057813  0.055887  0.054408  0.055950  0.056722  0.056795  0.055932  ...   \n",
       "\n",
       "       2451      2452      2453      2454      2455      2456      2457  \\\n",
       "0  0.056319  0.055844  0.055375  0.055058  0.054726  0.054421  0.054162   \n",
       "1  0.047114  0.046864  0.046694  0.046366  0.045964  0.045663  0.045325   \n",
       "2  0.055637  0.055295  0.055052  0.054888  0.054461  0.054179  0.054169   \n",
       "3  0.063220  0.062894  0.062567  0.062176  0.061807  0.061366  0.060850   \n",
       "4  0.052968  0.052582  0.052181  0.051812  0.051542  0.051262  0.050935   \n",
       "\n",
       "       2458      2459      2460      2461      2462      2463      2464  \\\n",
       "0  0.053836  0.053488  0.053203  0.052905  0.052548  0.052264  0.051997   \n",
       "1  0.045112  0.044898  0.044548  0.044306  0.044098  0.043800  0.043470   \n",
       "2  0.053794  0.053397  0.053165  0.052658  0.052337  0.052304  0.051942   \n",
       "3  0.060529  0.060285  0.059850  0.059491  0.059236  0.058814  0.058425   \n",
       "4  0.050440  0.049974  0.049768  0.049507  0.049181  0.048957  0.048599   \n",
       "\n",
       "       2465      2466      2467      2468      2469      2470      2471  \\\n",
       "0  0.051595  0.051157  0.050832  0.050384  0.049892  0.049764  0.049538   \n",
       "1  0.043094  0.042753  0.042579  0.042447  0.042235  0.042065  0.041800   \n",
       "2  0.051510  0.051305  0.051045  0.050822  0.050715  0.050409  0.050127   \n",
       "3  0.058187  0.057785  0.057324  0.057021  0.056671  0.056601  0.056302   \n",
       "4  0.048275  0.048050  0.047667  0.047319  0.047089  0.046949  0.046656   \n",
       "\n",
       "       2472      2473      2474      2475      2476      2477      2478  \\\n",
       "0  0.049473  0.049243  0.048725  0.048397  0.048044  0.047772  0.047821   \n",
       "1  0.041422  0.041198  0.041026  0.040759  0.040543  0.040383  0.040137   \n",
       "2  0.049959  0.049740  0.049392  0.049137  0.048937  0.048751  0.048657   \n",
       "3  0.055740  0.055415  0.055086  0.054752  0.054657  0.054514  0.054307   \n",
       "4  0.046121  0.045817  0.045615  0.045346  0.045268  0.045105  0.044743   \n",
       "\n",
       "       2479      2480      2481      2482      2483      2484      2485  \\\n",
       "0  0.047637  0.047205  0.046992  0.046813  0.046602  0.046607  0.046481   \n",
       "1  0.039915  0.039878  0.039731  0.039409  0.039179  0.038988  0.038808   \n",
       "2  0.048485  0.048162  0.048046  0.048203  0.048045  0.047810  0.047612   \n",
       "3  0.054005  0.053654  0.053363  0.052884  0.052615  0.052670  0.052539   \n",
       "4  0.044431  0.044120  0.043897  0.043757  0.043535  0.043305  0.043162   \n",
       "\n",
       "       2486      2487      2488      2489      2490      2491      2492  \\\n",
       "0  0.046230  0.045912  0.045301  0.045138  0.045353  0.045184  0.045096   \n",
       "1  0.038687  0.038522  0.038289  0.038160  0.038160  0.038003  0.037762   \n",
       "2  0.047058  0.046735  0.046689  0.046588  0.046480  0.046410  0.046467   \n",
       "3  0.052351  0.052190  0.051985  0.051738  0.051436  0.051306  0.051264   \n",
       "4  0.043033  0.042843  0.042801  0.042619  0.042022  0.041867  0.042194   \n",
       "\n",
       "       2493      2494      2495      2496      2497      2498      2499  \\\n",
       "0  0.045050  0.044625  0.044355  0.044527  0.044399  0.043810  0.043605   \n",
       "1  0.037672  0.037440  0.037419  0.037894  0.037886  0.037521  0.037509   \n",
       "2  0.046406  0.046281  0.046181  0.046085  0.045880  0.045441  0.045417   \n",
       "3  0.051125  0.051135  0.050983  0.050531  0.050280  0.050144  0.049989   \n",
       "4  0.042013  0.041689  0.041549  0.040944  0.040854  0.041708  0.041670   \n",
       "\n",
       "       2500  \n",
       "0  0.043599  \n",
       "1  0.037503  \n",
       "2  0.045704  \n",
       "3  0.049945  \n",
       "4  0.041102  \n",
       "\n",
       "[5 rows x 2152 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maize_data = pd.read_csv('maize_2018_2019_unl_spectra.csv')\n",
    "\n",
    "mdf = maize_data\n",
    "\n",
    "mdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "462782c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Nitrogen</th>\n",
       "      <th>Phosphorus</th>\n",
       "      <th>Potassium</th>\n",
       "      <th>Chlorophyll</th>\n",
       "      <th>Leaf_Dry_Weight</th>\n",
       "      <th>Leaf_Fresh_Weight</th>\n",
       "      <th>Leaf_Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.78</td>\n",
       "      <td>476.60</td>\n",
       "      <td>8.46</td>\n",
       "      <td>30.70</td>\n",
       "      <td>1420.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.48</td>\n",
       "      <td>2.74</td>\n",
       "      <td>492.17</td>\n",
       "      <td>6.69</td>\n",
       "      <td>27.55</td>\n",
       "      <td>1144.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Nitrogen  Phosphorus  Potassium  Chlorophyll  Leaf_Dry_Weight  \\\n",
       "0   1      2.96        0.22       1.78       476.60             8.46   \n",
       "1   2      3.11        0.48       2.74       492.17             6.69   \n",
       "\n",
       "   Leaf_Fresh_Weight  Leaf_Area  \n",
       "0              30.70    1420.57  \n",
       "1              27.55    1144.10  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdr = pd.read_csv('maize_2018_2019_unl_traits.csv')\n",
    "\n",
    "mdr.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccecfb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdrN = mdr[[\"Nitrogen\"]]\n",
    "mdrP = mdr[[\"Phosphorus\"]]\n",
    "mdrK = mdr[[\"Potassium\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaf79ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Nitrogen</th>\n",
       "      <th>Phosphorus</th>\n",
       "      <th>Potassium</th>\n",
       "      <th>Chlorophyll</th>\n",
       "      <th>Leaf_Dry_Weight</th>\n",
       "      <th>Leaf_Fresh_Weight</th>\n",
       "      <th>Leaf_Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.78</td>\n",
       "      <td>476.60</td>\n",
       "      <td>8.46</td>\n",
       "      <td>30.70</td>\n",
       "      <td>1420.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.48</td>\n",
       "      <td>2.74</td>\n",
       "      <td>492.17</td>\n",
       "      <td>6.69</td>\n",
       "      <td>27.55</td>\n",
       "      <td>1144.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Nitrogen  Phosphorus  Potassium  Chlorophyll  Leaf_Dry_Weight  \\\n",
       "0   1      2.96        0.22       1.78       476.60             8.46   \n",
       "1   2      3.11        0.48       2.74       492.17             6.69   \n",
       "\n",
       "   Leaf_Fresh_Weight  Leaf_Area  \n",
       "0              30.70    1420.57  \n",
       "1              27.55    1144.10  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdr.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d6f0b7",
   "metadata": {},
   "source": [
    "# Step 2: Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dce1d124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                   0\n",
       "Nitrogen             0\n",
       "Phosphorus           0\n",
       "Potassium            0\n",
       "Chlorophyll          0\n",
       "Leaf_Dry_Weight      0\n",
       "Leaf_Fresh_Weight    0\n",
       "Leaf_Area            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdf.isnull().sum()\n",
    "mdr.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdb2ad34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mdf\n",
    "\n",
    "# getting yN, yP, and yK in series form for the input of train-test split ahead   \n",
    "yN = mdrN\n",
    "yN = yN.iloc[: , 0]\n",
    "\n",
    "yP = mdrP\n",
    "yP = yP.iloc[: , 0]\n",
    "\n",
    "yK = mdrK\n",
    "yK = yK.iloc[: , 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00e07ff",
   "metadata": {},
   "source": [
    "# Step 3:  Train-Test Split  and its Goodness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c665ed35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KstestResult(statistic=0.08367768595041322, pvalue=0.12848395652787437, statistic_location=2.95, statistic_sign=-1)\n"
     ]
    }
   ],
   "source": [
    "rand_st = 14\n",
    "tst_siz = 0.2\n",
    "\n",
    "# Train test split for Nitrogen\n",
    "XN_train, XN_test,yN_train, yN_test = train_test_split(X, yN, test_size = tst_siz, random_state = rand_st)\n",
    "ks2_test = ks_2samp(yN_train, yN_test) \n",
    "print(ks2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d67f887",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\AppData\\Local\\Temp\\ipykernel_20252\\1843552486.py:2: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn-deep')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  Plotting the Distribution of Train and Test Output Data  -----------for  Nitrogen ----\n",
    "plt.style.use('seaborn-deep')\n",
    "min_y = np.min(yN)\n",
    "max_y = np.max(yN)\n",
    "bins = np.linspace(min_y, max_y, 8)\n",
    "plt.hist([yN_train, yN_test], bins , label=['Train', 'Test'], density=True, color = ['firebrick','gray'])\n",
    "plt.xlabel('y values (NITROGEN)')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3424f6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KstestResult(statistic=0.08677685950413223, pvalue=0.10456713994278695, statistic_location=0.29, statistic_sign=-1)\n"
     ]
    }
   ],
   "source": [
    "rand_st = 14\n",
    "tst_siz = 0.2\n",
    "\n",
    "# # Train test split for Phosphorous\n",
    "XP_train, XP_test, yP_train, yP_test = train_test_split(X, yP, test_size = tst_siz, random_state = rand_st)\n",
    "ks2_test = ks_2samp(yP_train, yP_test) \n",
    "print(ks2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd9a3cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\AppData\\Local\\Temp\\ipykernel_20252\\857364618.py:2: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn-deep')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the Goodness of Train-Test Split  -----------for  Phosphorus ----\n",
    "plt.style.use('seaborn-deep')\n",
    "min_y = np.min(yP)\n",
    "max_y = np.max(yP)\n",
    "bins = np.linspace(min_y, max_y, 8)\n",
    "plt.hist([yP_train, yP_test], bins , label=['Train', 'Test'], density=True, color = ['firebrick','gray'])\n",
    "plt.xlabel('y values (PHOSPHORUS)')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef827e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KstestResult(statistic=0.11776859504132231, pvalue=0.008812186388581732, statistic_location=2.26, statistic_sign=-1)\n"
     ]
    }
   ],
   "source": [
    "rand_st = 23\n",
    "tst_siz = 0.2\n",
    "\n",
    "#  Train test split for Potasium\n",
    "XK_train, XK_test, yK_train, yK_test = train_test_split(X, yK, test_size = tst_siz, random_state = rand_st)\n",
    "ks2_test = ks_2samp(yK_train, yK_test) \n",
    "print(ks2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06386c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\AppData\\Local\\Temp\\ipykernel_8464\\4101453007.py:2: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn-deep')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the Goodness of Train-Test Split   -----------for  Potasium ----\n",
    "plt.style.use('seaborn-deep')\n",
    "min_y = np.min(yK)\n",
    "max_y = np.max(yK)\n",
    "\n",
    "#fig, ax = plt.subplots(1,2, figsize=(10,4))\n",
    "bins = np.linspace(min_y, max_y, 8)\n",
    "\n",
    "plt.hist([yK_train, yK_test], bins , label=['Train', 'Test'], density=True, color = ['firebrick','gray'])\n",
    "# results in error when yN_train/ yN_test is data frame or ndarray\n",
    "#ax[0].legend(loc='upper right')\n",
    "plt.xlabel('y values (POTASIUM)')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32115dae",
   "metadata": {},
   "source": [
    "# Step 4: Training the Model\n",
    "\n",
    "        - Create a regr object\n",
    "        - Apply fit function (using regr object) on training data\n",
    "        - Check the weights/parameters generated by fit function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3fd4be83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [10, 13, 16, 19, 22, 25, 28, 31, 34, 37, 41, 44, 47, 50, 53, 56, 59, 62, 65, 68, 72, 75, 78, 81, 84, 87, 90, 93, 96, 100], 'max_depth': [3, 4], 'max_features': ['log2', 'sqrt'], 'min_samples_split': [3, 5, 8], 'bootstrap': [True, False]}\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=10,\n",
       "                   estimator=RandomForestRegressor(n_jobs=-1, random_state=10),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [3, 4],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;log2&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_split&#x27;: [3, 5, 8],\n",
       "                                        &#x27;n_estimators&#x27;: [10, 13, 16, 19, 22, 25,\n",
       "                                                         28, 31, 34, 37, 41, 44,\n",
       "                                                         47, 50, 53, 56, 59, 62,\n",
       "                                                         65, 68, 72, 75, 78, 81,\n",
       "                                                         84, 87, 90, 93, 96,\n",
       "                                                         100]},\n",
       "                   random_state=10, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=10,\n",
       "                   estimator=RandomForestRegressor(n_jobs=-1, random_state=10),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [3, 4],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;log2&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_split&#x27;: [3, 5, 8],\n",
       "                                        &#x27;n_estimators&#x27;: [10, 13, 16, 19, 22, 25,\n",
       "                                                         28, 31, 34, 37, 41, 44,\n",
       "                                                         47, 50, 53, 56, 59, 62,\n",
       "                                                         65, 68, 72, 75, 78, 81,\n",
       "                                                         84, 87, 90, 93, 96,\n",
       "                                                         100]},\n",
       "                   random_state=10, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1, random_state=10)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1, random_state=10)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=10,\n",
       "                   estimator=RandomForestRegressor(n_jobs=-1, random_state=10),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [3, 4],\n",
       "                                        'max_features': ['log2', 'sqrt'],\n",
       "                                        'min_samples_split': [3, 5, 8],\n",
       "                                        'n_estimators': [10, 13, 16, 19, 22, 25,\n",
       "                                                         28, 31, 34, 37, 41, 44,\n",
       "                                                         47, 50, 53, 56, 59, 62,\n",
       "                                                         65, 68, 72, 75, 78, 81,\n",
       "                                                         84, 87, 90, 93, 96,\n",
       "                                                         100]},\n",
       "                   random_state=10, verbose=2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_reg = RandomForestRegressor(n_jobs=-1, random_state=10)\n",
    "\n",
    "#to generate various random forests.\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 100, num = 30)]\n",
    "max_depth = [int(x) for x in np.linspace(3, 4, num = 2)]\n",
    "max_features = ['log2', 'sqrt']\n",
    "min_samples_split = [3, 5, 8]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators, 'max_depth': max_depth, 'max_features':max_features,\\\n",
    "              'min_samples_split':min_samples_split, 'bootstrap': [True, False]}\n",
    "\n",
    "print(random_grid)\n",
    "\n",
    "rf_modelN = RandomizedSearchCV(estimator=rf_reg, param_distributions = random_grid, cv = 10,\\\n",
    "                                verbose=2, random_state = 10, n_jobs = -1)\n",
    "\n",
    "rf_modelN.fit(XN_train, yN_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "049254c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [10, 13, 16, 19, 22, 25, 28, 31, 34, 37, 41, 44, 47, 50, 53, 56, 59, 62, 65, 68, 72, 75, 78, 81, 84, 87, 90, 93, 96, 100], 'max_depth': [3, 4], 'max_features': ['log2', 'sqrt'], 'min_samples_split': [3, 5, 8], 'bootstrap': [True, False]}\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=10,\n",
       "                   estimator=RandomForestRegressor(n_jobs=-1, random_state=10),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [3, 4],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;log2&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_split&#x27;: [3, 5, 8],\n",
       "                                        &#x27;n_estimators&#x27;: [10, 13, 16, 19, 22, 25,\n",
       "                                                         28, 31, 34, 37, 41, 44,\n",
       "                                                         47, 50, 53, 56, 59, 62,\n",
       "                                                         65, 68, 72, 75, 78, 81,\n",
       "                                                         84, 87, 90, 93, 96,\n",
       "                                                         100]},\n",
       "                   random_state=10, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=10,\n",
       "                   estimator=RandomForestRegressor(n_jobs=-1, random_state=10),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [3, 4],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;log2&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_split&#x27;: [3, 5, 8],\n",
       "                                        &#x27;n_estimators&#x27;: [10, 13, 16, 19, 22, 25,\n",
       "                                                         28, 31, 34, 37, 41, 44,\n",
       "                                                         47, 50, 53, 56, 59, 62,\n",
       "                                                         65, 68, 72, 75, 78, 81,\n",
       "                                                         84, 87, 90, 93, 96,\n",
       "                                                         100]},\n",
       "                   random_state=10, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1, random_state=10)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1, random_state=10)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=10,\n",
       "                   estimator=RandomForestRegressor(n_jobs=-1, random_state=10),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [3, 4],\n",
       "                                        'max_features': ['log2', 'sqrt'],\n",
       "                                        'min_samples_split': [3, 5, 8],\n",
       "                                        'n_estimators': [10, 13, 16, 19, 22, 25,\n",
       "                                                         28, 31, 34, 37, 41, 44,\n",
       "                                                         47, 50, 53, 56, 59, 62,\n",
       "                                                         65, 68, 72, 75, 78, 81,\n",
       "                                                         84, 87, 90, 93, 96,\n",
       "                                                         100]},\n",
       "                   random_state=10, verbose=2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ##  Create random forest regressor object for phosphorus\n",
    "\n",
    "rf_reg = RandomForestRegressor(n_jobs=-1, random_state=10)\n",
    "\n",
    "#to generate various random forests.\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 100, num = 30)]\n",
    "max_depth = [int(x) for x in np.linspace(3, 4, num = 2)]\n",
    "max_features = ['log2', 'sqrt']\n",
    "min_samples_split = [3, 5, 8]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators, 'max_depth': max_depth, 'max_features':max_features,\\\n",
    "              'min_samples_split':min_samples_split, 'bootstrap': [True, False]}\n",
    "\n",
    "print(random_grid)\n",
    "\n",
    "rf_modelP = RandomizedSearchCV(estimator=rf_reg, param_distributions = random_grid, cv = 10,\\\n",
    "                                verbose=2, random_state = 10, n_jobs = -1)\n",
    "\n",
    "rf_modelP.fit(XP_train, yP_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8353e83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [10, 13, 16, 19, 22, 25, 28, 31, 34, 37, 41, 44, 47, 50, 53, 56, 59, 62, 65, 68, 72, 75, 78, 81, 84, 87, 90, 93, 96, 100], 'max_depth': [3, 4], 'max_features': ['log2', 'sqrt'], 'min_samples_split': [3, 5, 8], 'bootstrap': [True, False]}\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=10,\n",
       "                   estimator=RandomForestRegressor(n_jobs=-1, random_state=10),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [3, 4],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;log2&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_split&#x27;: [3, 5, 8],\n",
       "                                        &#x27;n_estimators&#x27;: [10, 13, 16, 19, 22, 25,\n",
       "                                                         28, 31, 34, 37, 41, 44,\n",
       "                                                         47, 50, 53, 56, 59, 62,\n",
       "                                                         65, 68, 72, 75, 78, 81,\n",
       "                                                         84, 87, 90, 93, 96,\n",
       "                                                         100]},\n",
       "                   random_state=10, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=10,\n",
       "                   estimator=RandomForestRegressor(n_jobs=-1, random_state=10),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [3, 4],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;log2&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_split&#x27;: [3, 5, 8],\n",
       "                                        &#x27;n_estimators&#x27;: [10, 13, 16, 19, 22, 25,\n",
       "                                                         28, 31, 34, 37, 41, 44,\n",
       "                                                         47, 50, 53, 56, 59, 62,\n",
       "                                                         65, 68, 72, 75, 78, 81,\n",
       "                                                         84, 87, 90, 93, 96,\n",
       "                                                         100]},\n",
       "                   random_state=10, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1, random_state=10)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1, random_state=10)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=10,\n",
       "                   estimator=RandomForestRegressor(n_jobs=-1, random_state=10),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [3, 4],\n",
       "                                        'max_features': ['log2', 'sqrt'],\n",
       "                                        'min_samples_split': [3, 5, 8],\n",
       "                                        'n_estimators': [10, 13, 16, 19, 22, 25,\n",
       "                                                         28, 31, 34, 37, 41, 44,\n",
       "                                                         47, 50, 53, 56, 59, 62,\n",
       "                                                         65, 68, 72, 75, 78, 81,\n",
       "                                                         84, 87, 90, 93, 96,\n",
       "                                                         100]},\n",
       "                   random_state=10, verbose=2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Create random forest regressor object for Potassium\n",
    "\n",
    "\n",
    "rf_reg = RandomForestRegressor(n_jobs=-1, random_state=10)\n",
    "\n",
    "#to generate various random forests.\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 100, num = 30)]\n",
    "max_depth = [int(x) for x in np.linspace(3, 4, num = 2)]\n",
    "max_features = ['log2', 'sqrt']\n",
    "min_samples_split = [3, 5, 8]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators, 'max_depth': max_depth, 'max_features':max_features,\\\n",
    "              'min_samples_split':min_samples_split, 'bootstrap': [True, False]}\n",
    "\n",
    "print(random_grid)\n",
    "\n",
    "rf_modelK = RandomizedSearchCV(estimator=rf_reg, param_distributions = random_grid, cv = 10,\\\n",
    "                                verbose=2, random_state = 10, n_jobs = -1)\n",
    "\n",
    "rf_modelK.fit(XK_train, yK_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d8567e",
   "metadata": {},
   "source": [
    "# Step 5: Prediction on Test Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e59b259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(bootstrap=False, max_depth=4, max_features='sqrt',\n",
      "                      min_samples_split=5, n_estimators=81, n_jobs=-1,\n",
      "                      random_state=10)\n"
     ]
    }
   ],
   "source": [
    "print(rf_modelN.best_estimator_)\n",
    "yN_pred = rf_modelN.predict(XN_test)\n",
    "yN_pred = np.round(yN_pred, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b173039f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(bootstrap=False, max_depth=4, max_features='log2',\n",
      "                      min_samples_split=5, n_estimators=41, n_jobs=-1,\n",
      "                      random_state=10)\n"
     ]
    }
   ],
   "source": [
    "print(rf_modelP.best_estimator_)\n",
    "yP_pred = rf_modelP.predict(XP_test)\n",
    "yP_pred = np.round(yP_pred, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b4eea64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(max_depth=4, max_features='log2', min_samples_split=5,\n",
      "                      n_estimators=50, n_jobs=-1, random_state=10)\n"
     ]
    }
   ],
   "source": [
    "print(rf_modelK.best_estimator_)\n",
    "yK_pred = rf_modelK.predict(XK_test)\n",
    "yK_pred = np.round(yK_pred, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ae984f",
   "metadata": {},
   "source": [
    "# Step 6: Model Accuracy and Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f6a9cf3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nitogen Model Accuracy\n",
      "Nitrogen Root Mean Square Error (Training): 0.327\n",
      "Nitrogen Root Mean Square Error (Testing): 0.384\n",
      "Nitrogen Mean Absolute Error (For Training): 0.258\n",
      "Nitrogen Mean Absolute Error (For Testing): 0.305\n",
      "Test Nitrogen R2 Score 0.627\n",
      "Mean Percentage Error: 13.298946760555843\n"
     ]
    }
   ],
   "source": [
    "#  Mean percentage error for nitrogen\n",
    "errorsN = np.mean(abs((yN_pred - yN_test)/yN_test))\n",
    "\n",
    "#  Calculate the rmse for training data Nitrogen\n",
    "yhatN_pred = rf_modelN.predict(XN_train)\n",
    "mseNTrain = mean_squared_error(yN_train, yhatN_pred)\n",
    "rmseNTrain = np.sqrt(mseNTrain)\n",
    "\n",
    "#  Calculate the rmse for testing data Nitrogen\n",
    "mseNTest = mean_squared_error(yN_test, yN_pred)\n",
    "rmseNTest = np.sqrt(mseNTest)\n",
    "\n",
    "# Calculate the absolute errors for training data Nitrogen\n",
    "errorsNTrain = abs(yN_train - yhatN_pred)\n",
    "\n",
    "# Print out the mean absolute error (mae) for training data Nitrogen\n",
    "\n",
    "# Calculate the absolute errors for testing data Nitrogen\n",
    "errorsNTest = abs(yN_pred - yN_test)\n",
    "\n",
    "# Print out the mean absolute error (mae) for testing data Nitrogen\n",
    "\n",
    "print('Nitogen Model Accuracy')    \n",
    "print('Nitrogen Root Mean Square Error (Training): %.3f' % rmseNTrain)\n",
    "print('Nitrogen Root Mean Square Error (Testing): %.3f' % rmseNTest)\n",
    "print('Nitrogen Mean Absolute Error (For Training):', round(np.mean(errorsNTrain), 3))\n",
    "print('Nitrogen Mean Absolute Error (For Testing):', round(np.mean(errorsNTest), 3))\n",
    "print (\"Test Nitrogen R2 Score\", np.round(r2_score(yN_test, yN_pred), 3))\n",
    "print('Mean Percentage Error:', errorsN*100)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d305cbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phosphorus Model Accuracy\n",
      "phosphorus Root Mean Square Error (Training): 0.072\n",
      "phosphorusRoot Mean Square Error (Testing): 0.067\n",
      "phosphorus Mean Absolute Error (For Training): 0.054\n",
      "phosphorus Mean Absolute Error (For Testing): 0.052\n",
      "Test phosphorus R2 Score 0.144\n",
      "Mean Percentage Error: 18.223714428868966\n"
     ]
    }
   ],
   "source": [
    "#  Mean percentage error for phosphorus\n",
    "errorsP = np.mean(abs((yP_pred - yP_test)/yP_test))\n",
    "\n",
    "#  Calculate the rmse for training data phosphorus\n",
    "yhatP_pred = rf_modelP.predict(XP_train)\n",
    "msePTrain = mean_squared_error(yP_train, yhatP_pred)\n",
    "rmsePTrain = np.sqrt(msePTrain)\n",
    "\n",
    "#  Calculate the rmse for testing data phosphorus\n",
    "msePTest = mean_squared_error(yP_test, yP_pred)\n",
    "rmsePTest = np.sqrt(msePTest)\n",
    "\n",
    "# Calculate the absolute errors for training data phosphorus\n",
    "errorsPTrain = abs(yP_train - yhatP_pred)\n",
    "\n",
    "# Print out the mean absolute error (mae) for training data phosphorus\n",
    "\n",
    "# Calculate the absolute errors for testing data phosphorus\n",
    "errorsPTest = abs(yP_pred - yP_test)\n",
    "\n",
    "# Print out the mean absolute error (mae) for testing data phosphorus\n",
    "\n",
    "print('phosphorus Model Accuracy')    \n",
    "print('phosphorus Root Mean Square Error (Training): %.3f' % rmsePTrain)\n",
    "print('phosphorusRoot Mean Square Error (Testing): %.3f' % rmsePTest)\n",
    "print('phosphorus Mean Absolute Error (For Training):', round(np.mean(errorsPTrain), 3))\n",
    "print('phosphorus Mean Absolute Error (For Testing):', round(np.mean(errorsPTest), 3))\n",
    "print (\"Test phosphorus R2 Score\", np.round(r2_score(yP_test, yP_pred), 3))\n",
    "print('Mean Percentage Error:', errorsP*100)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bbe54297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "potassium Model Accuracy\n",
      "potassium Root Mean Square Error (Training): 0.347\n",
      "potassium Root Mean Square Error (Testing): 0.418\n",
      "potassium Mean Absolute Error (For Training): 0.269\n",
      "potassium Mean Absolute Error (For Testing): 0.319\n",
      "Test potassium R2 Score 0.132\n",
      "Mean Percentage Error: 14.898577690658787\n"
     ]
    }
   ],
   "source": [
    "#  Mean percentage error for potassium\n",
    "errorsK = np.mean(abs((yK_pred - yK_test)/yK_test))\n",
    "\n",
    "#  Calculate the rmse for training data potassium\n",
    "yhatK_pred = rf_modelK.predict(XK_train)\n",
    "mseKTrain = mean_squared_error(yK_train, yhatK_pred)\n",
    "rmseKTrain = np.sqrt(mseKTrain)\n",
    "\n",
    "#  Calculate the rmse for testing data potassium\n",
    "mseKTest = mean_squared_error(yK_test, yK_pred)\n",
    "rmseKTest = np.sqrt(mseKTest)\n",
    "\n",
    "# Calculate the absolute errors for training data potassium\n",
    "errorsKTrain = abs(yK_train - yhatK_pred)\n",
    "\n",
    "# Print out the mean absolute error (mae) for training data potassium\n",
    "\n",
    "# Calculate the absolute errors for testing data potassium\n",
    "errorsKTest = abs(yK_pred - yK_test)\n",
    "\n",
    "# Print out the mean absolute error (mae) for testing data potassium\n",
    "\n",
    "print('potassium Model Accuracy')    \n",
    "print('potassium Root Mean Square Error (Training): %.3f' % rmseKTrain)\n",
    "print('potassium Root Mean Square Error (Testing): %.3f' % rmseKTest)\n",
    "print('potassium Mean Absolute Error (For Training):', round(np.mean(errorsKTrain), 3))\n",
    "print('potassium Mean Absolute Error (For Testing):', round(np.mean(errorsKTest), 3))\n",
    "print (\"Test potassium R2 Score\", np.round(r2_score(yK_test, yK_pred), 3))\n",
    "print('Mean Percentage Error:', errorsK*100)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
