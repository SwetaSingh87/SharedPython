{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c173cf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openpyxl\n",
    "# !pip install imbalanced-learn\n",
    "# !pip3 install ipympl\n",
    "# !pip install import-ipynb\n",
    "# !pip install shapely\n",
    "# !pip install SciencePlots \n",
    "# !pip install seaborn\n",
    "# !pip install tqdm\n",
    "# !pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ef6b01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scienceplots\n",
    "import os, sys\n",
    "from numpy import nan\n",
    "import re\n",
    "import ipympl\n",
    "# from IPython.core.display import display, HTML\n",
    "import ipywidgets\n",
    "import json\n",
    "from os import listdir\n",
    "import glob\n",
    "import math\n",
    "from IPython.display import Image, display, HTML\n",
    "from shapely.geometry import mapping\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, RepeatedKFold, cross_val_predict\n",
    "from sklearn.metrics import r2_score, mean_squared_error, precision_score, recall_score, mean_absolute_error, make_scorer\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, LeaveOneOut, cross_validate\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy import stats\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "pd.options.display.max_columns = 100\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22684781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from SoilPrep.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from SoilPrep import * "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd5b13f",
   "metadata": {},
   "source": [
    "# Step 1: Data Preprocessing (Normalisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "492df528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colour scheme definition\n",
    "kado = '#8B7355'\n",
    "mati = '#A52A2A'\n",
    "balu = '#F4A460'\n",
    "\n",
    "udf = pd.read_csv('uae.csv')\n",
    "# print(udf.shape)\n",
    "# print(udf[\"FID\"].min(), udf[\"FID\"].max())\n",
    "# Note that some ids are missing in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b0b13b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "udf['sand'] = lognormal (udf['sand'].copy())\n",
    "udf['silt'] = lognormal (udf['silt'].copy())\n",
    "udf['clay'] = lognormal (udf['clay'].copy())\n",
    "udf['TOC'] = lognormal (udf['TOC'].copy())\n",
    "\n",
    "# plt.hist(udf['clay'], bins=98)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12f62f4",
   "metadata": {},
   "source": [
    "## Correlation between wavelengths and Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90484fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbed7770325245d79ffa5fc3d184d224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='target', options=('sand', 'silt', 'clay', 'TOC', 'All'), value='sa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_corr(target)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.style.use(['science','notebook','grid'])\n",
    "# Pearson corelation between different wavelengths and Targets/Outputs (i.e, sand, clay, silt, and TOC) \n",
    "\n",
    "# First and second row of sand_rp will store r values and p values for different wavelengths\n",
    "# Similar is the case for silt_rp, clay_rp, and toc_rp\n",
    "sand_rp = udf.loc[0:1,:].copy()\n",
    "silt_rp = udf.loc[0:1,:].copy()\n",
    "clay_rp = udf.loc[0:1,:].copy()\n",
    "toc_rp = udf.loc[0:1,:].copy()\n",
    "\n",
    "# Calculating r value and p value for different wavelengths when calculated against different Targets \n",
    "for i in range(7,2158):\n",
    "    sand_rp.iloc[0, i], sand_rp.iloc[1, i] = stats.pearsonr(udf.loc[:,'sand'], udf.iloc[:, i])\n",
    "    silt_rp.iloc[0, i], silt_rp.iloc[1, i] = stats.pearsonr(udf.loc[:,'silt'], udf.iloc[:, i])\n",
    "    clay_rp.iloc[0, i], clay_rp.iloc[1, i] = stats.pearsonr(udf.loc[:,'clay'], udf.iloc[:, i])\n",
    "    toc_rp.iloc[0, i], toc_rp.iloc[1, i] = stats.pearsonr(udf.loc[:,'TOC'], udf.iloc[:, i])\n",
    "    \n",
    "# Ploting the pearson correlation coefficient for different wavelengths against different Targets\n",
    "\n",
    "def plot_corr (target):\n",
    "    if target == 'sand':\n",
    "        sand_rp.iloc[0,7:].plot(color = balu)\n",
    "    elif target == 'silt':\n",
    "        silt_rp.iloc[0,7:].plot(color = kado) \n",
    "    elif target == 'TOC':\n",
    "        toc_rp.iloc[0,7:].plot(color = 'green')\n",
    "    elif target == 'clay':\n",
    "        clay_rp.iloc[0,7:].plot(color = mati)   \n",
    "    else:\n",
    "        clay_rp.iloc[0,7:].plot(color = mati)\n",
    "        sand_rp.iloc[0,7:].plot(color = balu)\n",
    "        silt_rp.iloc[0,7:].plot(color = kado) \n",
    "        toc_rp.iloc[0,7:].plot(color = 'green') \n",
    "    plt.ylim([-0.6, 0.6])\n",
    "\n",
    "ipywidgets.interact(plot_corr, target= ['sand', 'silt', 'clay', 'TOC', 'All'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9a2470",
   "metadata": {},
   "source": [
    "## Visualizing Spectrum by Increasing Target Contents (Interactive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33f44da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting spectra by Sand content\n",
    "\n",
    "smt =25\n",
    "\n",
    "bySand = udf.sort_values(by =['sand'])\n",
    "bySand = bySand.reset_index(drop=True)\n",
    "bySandS = bySand.iloc[:,:].copy()\n",
    "bySandS.iloc[:, 7:2158] = sgsmooth (bySand.iloc[:, 7:2158],smt)\n",
    "\n",
    "# Sorting spectra by Silt content\n",
    "bySilt = udf.sort_values(by =['silt'])\n",
    "bySilt = bySilt.reset_index(drop=True)\n",
    "bySiltS = bySilt.iloc[:,:].copy()\n",
    "bySiltS.iloc[:, 7:2158] = sgsmooth (bySilt.iloc[:, 7:2158],smt)\n",
    "#bySiltS = sgsmooth (bySilt,25)\n",
    "\n",
    "# Sorting spectra by Clay content\n",
    "byClay = udf.sort_values(by =['clay'])\n",
    "byClay = byClay.reset_index(drop=True)\n",
    "byClayS = byClay.iloc[:,:].copy()\n",
    "byClayS.iloc[:, 7:2158] = sgsmooth (byClay.iloc[:, 7:2158],smt)\n",
    "#byClayS = sgsmooth (byClay,25)\n",
    "\n",
    "# Sorting spectra by Total Organic Content(TOC)\n",
    "byTOC = udf.sort_values(by =['TOC'])\n",
    "byTOC = byTOC.reset_index(drop=True)\n",
    "byTOCS = byTOC.iloc[:,:].copy()\n",
    "byTOCS.iloc[:, 7:2158] = sgsmooth (byTOC.iloc[:, 7:2158],smt)\n",
    "#byTOCS = sgsmooth(byTOC, 25)\n",
    "# Using ipywidgets to draw interactive plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d053c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20060e42177d4d3e85173c319f3ada68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='sort_by', options=('sand', 'clay', 'silt', 'TOC'), value='sand'), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_spec(sort_by, sample, smooth)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_spec (sort_by, sample, smooth):\n",
    "    if sort_by == 'sand':\n",
    "        x= bySand.iloc[sample, 7:2158]\n",
    "        if smooth == 'on':\n",
    "            x = bySandS.iloc[sample, 7:2158] \n",
    "    elif sort_by == 'silt':\n",
    "        x= bySilt.iloc[sample, 7:2158]\n",
    "        if smooth == 'on':\n",
    "            x= bySiltS.iloc[sample, 7:2158]\n",
    "    elif sort_by == 'TOC':\n",
    "        x= byTOC.iloc[sample, 7:2158]\n",
    "        if smooth == 'on':\n",
    "            x= byTOCS.iloc[sample, 7:2158]\n",
    "    else:\n",
    "        x= byClay.iloc[sample, 7:2158]\n",
    "        if smooth == 'on':\n",
    "            x = byClayS.iloc[sample, 7:2158]\n",
    "    x.plot()\n",
    "    plt.ylim([-0.6, 0.8])\n",
    "\n",
    "ipywidgets.interact(plot_spec, sort_by= ['sand', 'clay', 'silt', 'TOC'], sample = (0, 293,1), smooth = ['on', 'off'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00e07ff",
   "metadata": {},
   "source": [
    "# Step 3:  Train-Test Split  and its Goodness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e195a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_silt = udf.loc[:, 'silt']\n",
    "y_sand = udf.loc[:, 'sand']\n",
    "y_clay = udf.loc[:, 'clay']\n",
    "y_toc = udf.loc[:, 'TOC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9694200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_siz = 0.2\n",
    "X = udf.iloc[:, 7:2158].copy()\n",
    "\n",
    "rand_sand, min_err = best_split(X, y_sand, tst_siz)\n",
    "print ('Sand: ')\n",
    "print ('For test size =', tst_siz, '\\t min bin error:', min_err, '\\t found at randome state =', rand_sand)\n",
    "\n",
    "rand_silt, min_err = best_split(X, y_silt, tst_siz)\n",
    "print ('Silt: ')\n",
    "print ('For test size =', tst_siz, '\\t min bin error:', min_err, '\\t found at randome state =', rand_silt)\n",
    "\n",
    "rand_clay, min_err = best_split(X, y_clay, tst_siz)\n",
    "print ('Clay: ')\n",
    "print ('For test size =', tst_siz, '\\t min bin error:', min_err, '\\t found at randome state =', rand_clay)\n",
    "\n",
    "rand_toc, min_err = best_split(X, y_toc, tst_siz)\n",
    "print ('TOC: ')\n",
    "print ('For test size =', tst_siz, '\\t min bin error:', min_err, '\\t found at randome state =', rand_toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e031f1d3",
   "metadata": {},
   "source": [
    "##  Optimal Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9030ec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the sample into train-test samples using obtained optimal parameters\n",
    "XSand_train, XSand_test, ySand_train, ySand_test = train_test_split(X, y_sand, test_size= tst_siz, random_state=rand_sand)\n",
    "\n",
    "XSilt_train, XSilt_test, ySilt_train, ySilt_test = train_test_split(X, y_silt, test_size= tst_siz, random_state=rand_silt)\n",
    "\n",
    "XClay_train, XClay_test, yClay_train, yClay_test = train_test_split(X, y_clay, test_size= tst_siz, random_state=rand_clay)\n",
    "\n",
    "XTOC_train, XTOC_test, yTOC_train, yTOC_test = train_test_split(X, y_toc, test_size= tst_siz, random_state=rand_toc)\n",
    "print ('\\n \\n Optimal Train-Test Split Done for y_sand y_silt y_clay y_toc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af33a5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Plotting the Distribution of Train and Test Output Data \n",
    "plt.style.use(['science','notebook','grid'])\n",
    "\n",
    "fig, ax = plt.subplots(2,2, figsize=(18,14))\n",
    "\n",
    "minSand = np.min(y_sand)\n",
    "maxSand = np.max(y_sand)\n",
    "\n",
    "binsSand = np.linspace(minSand, maxSand, 8)\n",
    "# density =True : used to normalise bin heights to make the integral of  histogram 1.\n",
    "ax[0][0].hist([ySand_train, ySand_test], binsSand , label=['Train', 'Test'], density=True, color = ['blue','red'])\n",
    "# results in error when yN_train/ yN_test is data frame or ndarray\n",
    "ax[0][0].legend(loc='upper left', fontsize =12)\n",
    "ax[0][0].set_xlabel('Sand content',fontsize =16)\n",
    "ax[0][0].set_ylabel('Normalised frequency',fontsize =12)\n",
    "ax[0][0].tick_params(axis='both', labelsize=8)\n",
    "\n",
    "minSilt = np.min(y_silt)\n",
    "maxSilt = np.max(y_silt)\n",
    "\n",
    "binsSilt = np.linspace(minSilt, maxSilt, 8)\n",
    "# density =True : used to normalise bin heights to make the integral of  histogram 1.\n",
    "ax[0][1].hist([ySilt_train, ySilt_test], binsSilt , label=['Train', 'Test'], density=True, color = ['blue','red'])\n",
    "# results in error when yN_train/ yN_test is data frame or ndarray\n",
    "ax[0][1].legend(loc='upper right', fontsize =12)\n",
    "ax[0][1].set_xlabel('Silt content',fontsize =16)\n",
    "ax[0][1].set_ylabel('Normalised frequency',fontsize =12)\n",
    "ax[0][1].tick_params(axis='both', labelsize=8)\n",
    "\n",
    "minClay = np.min(y_clay)\n",
    "maxClay = np.max(y_clay)\n",
    "\n",
    "binsClay = np.linspace(minClay, maxClay, 8)\n",
    "# density =True : used to normalise bin heights to make the integral of  histogram 1.\n",
    "ax[1][1].hist([yClay_train, yClay_test], binsClay , label=['Train', 'Test'], density=True, color = ['blue','red'])\n",
    "# results in error when yN_train/ yN_test is data frame or ndarray\n",
    "ax[1][1].legend(loc='upper right', fontsize =12)\n",
    "ax[1][1].set_xlabel('Clay content',fontsize =16)\n",
    "ax[1][1].set_ylabel('Normalised frequency',fontsize =12)\n",
    "ax[1][1].tick_params(axis='both', labelsize=8)\n",
    "\n",
    "minTOC = np.min(y_toc)\n",
    "maxTOC = np.max(y_toc)\n",
    "\n",
    "binsTOC = np.linspace(minTOC, maxTOC, 8)\n",
    "# density =True : used to normalise bin heights to make the integral of  histogram 1.\n",
    "ax[1][0].hist([yTOC_train, yTOC_test], binsTOC , label=['Train', 'Test'], density=True, color = ['blue','red'])\n",
    "# results in error when yN_train/ yN_test is data frame or ndarray\n",
    "ax[1][0].legend(loc='upper right', fontsize =12)\n",
    "ax[1][0].set_xlabel('Total Organic Content',fontsize =16)\n",
    "ax[1][0].set_ylabel('Normalised frequency',fontsize =12)\n",
    "ax[1][0].tick_params(axis='both', labelsize=8)\n",
    "\n",
    "fig.suptitle('Train Test Distribution of Data', x = 0.5 ,y = .95, fontsize = 20)\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448d5aed",
   "metadata": {},
   "source": [
    "# Finding best Model Parameters (window, n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3ab1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z= y_silt.sort_values().reset_index(drop=True)\n",
    "# #z= z.reset_index(drop=True)\n",
    "# len(z)\n",
    "# z[280]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c02c95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "def best_param_PLSR (spectra, target, rand_st, tst_siz, window, n_comp):\n",
    "    X= spectra.copy()\n",
    "    y= target.copy()\n",
    "     \n",
    "    iqrpM = np.zeros(shape=(window, n_comp))\n",
    "    # test train split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = tst_siz, random_state=rand_st)\n",
    "    for w in range (0,window):\n",
    "        X_train_smth = sgsmooth (X_train, w)\n",
    "        X_test_smth = sgsmooth (X_test, w)\n",
    "        for n in range(1,n_comp):\n",
    "            Model = PLSRegression(n_components=n, scale=True)\n",
    "            \n",
    "            Model.fit(X_train_smth, y_train)\n",
    "            y_pred = Model.predict(X_test, copy=True)\n",
    "            yhat_pred = Model.predict(X_train, copy=True)            \n",
    "            \n",
    "            iqrp_test = iqrp(y_pred, y_test)\n",
    "            iqrp_train = iqrp(yhat_pred, y_train)\n",
    "            \n",
    "            iqrpM[w,n] = iqrp_test\n",
    "            \n",
    "            if iqrp_test == iqrpM.max():\n",
    "                bestw = w\n",
    "                bestn = n\n",
    "                maxIQRP = iqrp_test\n",
    "                print('Found new best at w=', w, 'n=', n,  '>>   IQRP_test =', iqrp_test, '>>   IQRP_train =', iqrp_train)\n",
    "                \n",
    "    return (bestw, bestn, maxIQRP)\n",
    "\n",
    "\n",
    "# spectra = udf.iloc[:, 7:2158].copy()\n",
    "# w1, n1, IQRP1 = best_param_PLSR (spectra, y_sand, rand_sand, 0.2, 3,20) \n",
    "\n",
    "# spectra = udf.iloc[:, 7:2158].copy()\n",
    "# w2, n2, IQRP2 = best_param_PLSR (spectra, y_silt, rand_silt, 0.2, 3,20)  \n",
    "\n",
    "# spectra = udf.iloc[:, 7:2158].copy()\n",
    "# w3, n3, IQRP3 = best_param_PLSR (spectra, y_clay, rand_clay, 0.2, 3,20)\n",
    "\n",
    "# spectra = udf.iloc[:, 7:2158].copy()\n",
    "# w4, n4, IQRP4 = best_param_PLSR (spectra, y_toc, rand_toc, 0.2, 3, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6dc69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Sand:', w1, n1, IQRP1, 'Silt:', w2, n2, IQRP2, 'Clay:', w3, n3, IQRP3, 'TOC', w4, n4, IQRP4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1520cab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra = udf.iloc[:, 7:2158].copy()\n",
    "w1, n1, IQRP1 = best_param_PLSR (spectra, y_sand, rand_sand, 0.2, 3,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03575d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra = udf.iloc[:, 7:2158].copy()\n",
    "w2, n2, IQRP2 = best_param_PLSR (spectra, y_silt, rand_silt, 0.2, 3,20)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322350b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra = udf.iloc[:, 7:2158].copy()\n",
    "w3, n3, IQRP3 = best_param_PLSR (spectra, y_clay, rand_clay, 0.2, 3,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc7e1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra = udf.iloc[:, 7:2158].copy()\n",
    "w4, n4, IQRP4 = best_param_PLSR (spectra, y_toc, rand_toc, 0.2, 3, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32115dae",
   "metadata": {},
   "source": [
    "# Step 4: Training the Model\n",
    "\n",
    "        - Create a linear regr object\n",
    "        - Apply fit function (using regr object) on training data\n",
    "        - Check the weights/parameters generated by fit function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4438342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectra = udf.iloc[:,7:2158].copy()\n",
    "# smth_spec = sgsmooth (spectra,50)\n",
    "\n",
    "# smth_spec.iloc[1,:].plot()\n",
    "# plt.show()\n",
    "# spectra.iloc[1,:].plot()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1bef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "regSand = PLSRegression(n_components=n1, scale=True)\n",
    "regSilt = PLSRegression(n_components=n2, scale=True)\n",
    "regClay = PLSRegression(n_components=n3, scale=True)\n",
    "regTOC = PLSRegression(n_components=n4, scale=True)\n",
    "\n",
    "\n",
    "# train the model using X_train_smth and y_train (identified in previous step)\n",
    "\n",
    "XSand_train_smth = sgsmooth (XSand_train, w1)       \n",
    "regSand.fit(XSand_train_smth, ySand_train)\n",
    "\n",
    "XSilt_train_smth = sgsmooth (XSilt_train, w2)\n",
    "regSilt.fit(XSilt_train_smth, ySilt_train)\n",
    "\n",
    "XClay_train_smth = sgsmooth (XClay_train, w3)\n",
    "regClay.fit(XClay_train_smth, yClay_train)\n",
    "\n",
    "XTOC_train_smth = sgsmooth (XTOC_train, w4)\n",
    "regTOC.fit(XTOC_train_smth, yTOC_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871c5cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2d8567e",
   "metadata": {},
   "source": [
    "# Step 5: Prediction on Test Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eea64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predition using the trained-Model on the \"Test Data\"\n",
    "\n",
    "ySand_pred = regSand.predict(XSand_test,copy=True)\n",
    "ySand_pred = np.round(ySand_pred, 2)\n",
    "\n",
    "ySilt_pred = regSilt.predict(XSilt_test,copy=True)\n",
    "ySilt_pred = np.round(ySilt_pred, 2)\n",
    "\n",
    "yClay_pred = regClay.predict(XClay_test,copy=True)\n",
    "yClay_pred = np.round(yClay_pred, 2)\n",
    "\n",
    "yTOC_pred = regTOC.predict(XTOC_test,copy=True)\n",
    "yTOC_pred = np.round(yTOC_pred, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ae984f",
   "metadata": {},
   "source": [
    "# Step 6: Model Accuracy and Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53548c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging actual and predicted (Test data) in one data frame for plots\n",
    "ySand_tp = pd.DataFrame({'actual':ySand_test.values, 'predic': ySand_pred[:,0]})\n",
    "# ySand_sortedA = ySand_tp.sort_values(by =['actual'])\n",
    "# ySand_srtA = ySand_sortedA.reset_index(drop=True)\n",
    "\n",
    "ySilt_tp = pd.DataFrame({'actual':ySilt_test.values, 'predic': ySilt_pred[:,0]})\n",
    "# ySilt_sortedA = ySilt_tp.sort_values(by =['actual'])\n",
    "# ySilt_srtA = ySilt_sortedA.reset_index(drop=True)\n",
    "\n",
    "yClay_tp = pd.DataFrame({'actual':yClay_test.values, 'predic': yClay_pred[:,0]})\n",
    "# yClay_sortedA = yClay_tp.sort_values(by =['actual'])\n",
    "# yClay_srtA = yClay_sortedA.reset_index(drop=True)\n",
    "\n",
    "yTOC_tp = pd.DataFrame({'actual':yTOC_test.values, 'predic': yTOC_pred[:,0]})\n",
    "# yTOC_sortedA = yTOC_tp.sort_values(by =['actual'])\n",
    "# yTOC_srtA = yTOC_sortedA.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa86d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plots for Visualising the Model Accuracy\n",
    "#plt.style.use(['science','notebook','grid'])\n",
    "\n",
    "def plot_pred_acc (target):\n",
    "\n",
    "    fig, axes = plt.subplots(1,1, figsize=(8,7))\n",
    "\n",
    "    if target == 'sand':\n",
    "        z = np.polyfit(ySand_test, ySand_pred, 1)\n",
    "        score_cv = r2_score(ySand_test, ySand_pred)\n",
    "        with plt.style.context(('ggplot')):\n",
    "            ySand_tp.plot.scatter(ax= axes, x=\"actual\", y=\"predic\", alpha=0.8, color = balu, edgecolors='k')\n",
    "            axes.plot(np.polyval(z, ySand_test), ySand_test, c='blue', linewidth=1)\n",
    "            axes.plot(ySand_test, ySand_test, color='green', linewidth=1)\n",
    "            axes.tick_params(axis='both', labelsize=10)\n",
    "            plt.text(1, 11, 'SAND', fontsize = 20, color = balu)\n",
    "            plt.text(1, 10.2, 'IQRP ={:.2f}'.format(IQRP1), fontsize = 16)\n",
    "            plt.text(1, 9.4, 'R2 ={:.2f}'.format(np.round(score_cv,3)), fontsize = 16)\n",
    "\n",
    "    elif target == 'clay':\n",
    "        z = np.polyfit(yClay_test, yClay_pred, 1)\n",
    "        score_cv = r2_score(yClay_test, yClay_pred)\n",
    "        with plt.style.context(('ggplot')):\n",
    "            yClay_tp.plot.scatter(ax= axes, x=\"actual\", y=\"predic\", alpha=0.8, color = mati, edgecolors='k')\n",
    "            axes.plot(np.polyval(z, yClay_test), yClay_test, c='blue', linewidth=1)\n",
    "            axes.plot(yClay_test, yClay_test, color='green', linewidth=1)\n",
    "            axes.tick_params(axis='both', labelsize=10)\n",
    "            plt.text(1, 11, 'CLAY', fontsize = 20, color = mati)\n",
    "            plt.text(1, 10.2, 'IQRP ={:.2f}'.format(IQRP3), fontsize = 16)\n",
    "            plt.text(1, 9.4, 'R2 ={:.2f}'.format(np.round(score_cv,3)), fontsize = 16)\n",
    "\n",
    "        \n",
    "    elif target == 'silt':\n",
    "        z = np.polyfit(ySilt_test, ySilt_pred, 1)\n",
    "        score_cv = r2_score(ySilt_test, ySilt_pred)\n",
    "        with plt.style.context(('ggplot')):\n",
    "            ySilt_tp.plot.scatter(ax= axes, x=\"actual\", y=\"predic\", alpha=0.8, color = kado, edgecolors='k')\n",
    "            axes.plot(np.polyval(z, ySilt_test), ySilt_test, c='blue', linewidth=1)\n",
    "            axes.plot(ySilt_test, ySilt_test, color='green', linewidth=1)\n",
    "            axes.tick_params(axis='both', labelsize=10)\n",
    "            plt.text(1, 11, 'SILT', fontsize = 20, color = kado)\n",
    "            plt.text(1, 10.2, 'IQRP ={:.2f}'.format(IQRP2), fontsize = 16)\n",
    "            plt.text(1, 9.4, 'R2 ={:.2f}'.format(np.round(score_cv,3)), fontsize = 16)\n",
    "\n",
    "\n",
    "    elif target == 'TOC':\n",
    "        z = np.polyfit(yTOC_test, yTOC_pred, 1)\n",
    "        score_cv = r2_score(yTOC_test, yTOC_pred)\n",
    "        with plt.style.context(('ggplot')):\n",
    "            yTOC_tp.plot.scatter(ax= axes, x=\"actual\", y=\"predic\", alpha=0.8, color = 'green', edgecolors='k' )\n",
    "            axes.plot(np.polyval(z, yTOC_test), yTOC_test, c='blue', linewidth=1)\n",
    "            axes.plot(yTOC_test, yTOC_test, color='green', linewidth=1)\n",
    "            axes.tick_params(axis='both', labelsize=10)\n",
    "            plt.text(1, 11, 'TOC', fontsize = 20, color = 'green')\n",
    "            plt.text(1, 10.2, 'IQRP ={:.2f}'.format(IQRP4), fontsize = 16)\n",
    "            plt.text(1, 9.4, 'R2 ={:.2f}'.format(np.round(score_cv,3)), fontsize = 16)\n",
    "\n",
    "        \n",
    "    else:  \n",
    "        ySand_srtA.plot.scatter(ax= axes, x=\"actual\", y=\"predic\", alpha=0.8, color = balu)\n",
    "        axes.tick_params(axis='both', labelsize=10)\n",
    "        plt.text(3, 11, 'SAND', fontsize = 20, color = balu)\n",
    "        yClay_srtA.plot.scatter(ax= axes, x=\"actual\", y=\"predic\", alpha=0.8, color = mati)\n",
    "        axes.tick_params(axis='both', labelsize=10)\n",
    "        plt.text(3, 10, 'CLAY', fontsize = 20, color = mati)\n",
    "        ySilt_srtA.plot.scatter(ax= axes, x=\"actual\", y=\"predic\", alpha=0.8, color = kado)\n",
    "        axes.tick_params(axis='both', labelsize=10)\n",
    "        plt.text(1, 11, 'SILT', fontsize = 20, color = kado)\n",
    "        yTOC_srtA.plot.scatter(ax= axes, x=\"actual\", y=\"predic\", alpha=0.8, color = 'green')\n",
    "        axes.tick_params(axis='both', labelsize=10)\n",
    "        plt.text(1, 10, 'TOC', fontsize = 20, color = 'green')\n",
    "     \n",
    "\n",
    "    fig.suptitle('Predictions on \"Test\" Data', x = 0.5 ,y = .95, fontsize=20)\n",
    "    plt.xlim([0, 12])\n",
    "    plt.ylim([0, 12])\n",
    "    plt.show()\n",
    "\n",
    "ipywidgets.interact(plot_pred_acc, target = ['sand', 'clay', 'silt', 'TOC', 'All'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf4c57d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d828c633",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
