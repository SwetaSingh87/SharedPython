{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c173cf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openpyxl\n",
    "# !pip install imbalanced-learn\n",
    "# !pip3 install ipympl\n",
    "# !pip install import-ipynb\n",
    "# !pip install shapely\n",
    "# !pip install SciencePlots \n",
    "# !pip install seaborn\n",
    "# !pip install tqdm\n",
    "# !pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ef6b01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scienceplots\n",
    "import os, sys\n",
    "from numpy import nan\n",
    "import re\n",
    "import ipympl\n",
    "# from IPython.core.display import display, HTML\n",
    "import ipywidgets\n",
    "import json\n",
    "from os import listdir\n",
    "import glob\n",
    "import math\n",
    "from IPython.display import Image, display, HTML\n",
    "from shapely.geometry import mapping\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, RepeatedKFold, cross_val_predict\n",
    "from sklearn.metrics import r2_score, mean_squared_error, precision_score, recall_score, mean_absolute_error, make_scorer\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from cubist import Cubist\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, LeaveOneOut, cross_validate\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy import stats\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "pd.options.display.max_columns = 100\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "%matplotlib inline\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22684781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from SoilPrep.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from SoilPrep import * "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237d1771",
   "metadata": {},
   "source": [
    "# Step 0: Setting up decision paramenters (Data Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aee7c2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Available smoothing filter types: savgol1 and savgol2 ------------------------ (1)\n",
    "sg_filters = ['sg1', 'sg2']\n",
    "\n",
    "# 2. Available window lengths for the smoothing filter ---------------------------- (2)\n",
    "window_lengths = [0, 1, 11, 21, 31, 41, 51, 61, 71, 81, 91, 101]\n",
    "\n",
    "# 3. Available preprocessing for Spectral data ------------------------------------ (3)\n",
    "prepare_spec = ['none', 'fod', 'continuum']\n",
    "#prepare_spec = ['none', 'fod', 'continuum']\n",
    "\n",
    "# 4. Number of bands available for resampling spectra ----------------------------- (4) \n",
    "nbands_sampling = [0, 5, 10, 20, 30, 40, 50, 100, 200, 500]\n",
    "\n",
    "# 5. Names of target variables in the dataframe ----------------------------------- (5)\n",
    "target_names = ['sand', 'silt', 'clay', 'TOC']\n",
    "\n",
    "# 6. Available preprocessing for Target data -------------------------------------- (6)\n",
    "prepare_target = ['none', 'minmax']\n",
    "\n",
    "# 7. Available machine learning regression models --------------------------------- (7)\n",
    "ml_methods = ['mult', 'plsr', 'randomforest', 'cubist', 'svr', 'ridge', 'gbrt']\n",
    "\n",
    "# 8. Recorded predictions on test-train data for model accuracy  ------------------ (8)\n",
    "test_train_predict = ['test', 'testP', 'train', 'trainP']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b42ad8",
   "metadata": {},
   "source": [
    "# Step 1a: Obtaining Spectra (Noise and Outliers removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24fbfeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colour scheme definition\n",
    "kado = '#8B7355'\n",
    "mati = '#A52A2A'\n",
    "balu = '#F4A460'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b8fda5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>FID</th>\n",
       "      <th>500</th>\n",
       "      <th>501</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "      <th>512</th>\n",
       "      <th>513</th>\n",
       "      <th>514</th>\n",
       "      <th>515</th>\n",
       "      <th>516</th>\n",
       "      <th>517</th>\n",
       "      <th>518</th>\n",
       "      <th>519</th>\n",
       "      <th>520</th>\n",
       "      <th>521</th>\n",
       "      <th>522</th>\n",
       "      <th>523</th>\n",
       "      <th>524</th>\n",
       "      <th>525</th>\n",
       "      <th>526</th>\n",
       "      <th>527</th>\n",
       "      <th>528</th>\n",
       "      <th>529</th>\n",
       "      <th>530</th>\n",
       "      <th>531</th>\n",
       "      <th>532</th>\n",
       "      <th>533</th>\n",
       "      <th>534</th>\n",
       "      <th>535</th>\n",
       "      <th>536</th>\n",
       "      <th>537</th>\n",
       "      <th>538</th>\n",
       "      <th>539</th>\n",
       "      <th>540</th>\n",
       "      <th>541</th>\n",
       "      <th>542</th>\n",
       "      <th>543</th>\n",
       "      <th>544</th>\n",
       "      <th>545</th>\n",
       "      <th>546</th>\n",
       "      <th>547</th>\n",
       "      <th>548</th>\n",
       "      <th>549</th>\n",
       "      <th>...</th>\n",
       "      <th>2351</th>\n",
       "      <th>2352</th>\n",
       "      <th>2353</th>\n",
       "      <th>2354</th>\n",
       "      <th>2355</th>\n",
       "      <th>2356</th>\n",
       "      <th>2357</th>\n",
       "      <th>2358</th>\n",
       "      <th>2359</th>\n",
       "      <th>2360</th>\n",
       "      <th>2361</th>\n",
       "      <th>2362</th>\n",
       "      <th>2363</th>\n",
       "      <th>2364</th>\n",
       "      <th>2365</th>\n",
       "      <th>2366</th>\n",
       "      <th>2367</th>\n",
       "      <th>2368</th>\n",
       "      <th>2369</th>\n",
       "      <th>2370</th>\n",
       "      <th>2371</th>\n",
       "      <th>2372</th>\n",
       "      <th>2373</th>\n",
       "      <th>2374</th>\n",
       "      <th>2375</th>\n",
       "      <th>2376</th>\n",
       "      <th>2377</th>\n",
       "      <th>2378</th>\n",
       "      <th>2379</th>\n",
       "      <th>2380</th>\n",
       "      <th>2381</th>\n",
       "      <th>2382</th>\n",
       "      <th>2383</th>\n",
       "      <th>2384</th>\n",
       "      <th>2385</th>\n",
       "      <th>2386</th>\n",
       "      <th>2387</th>\n",
       "      <th>2388</th>\n",
       "      <th>2389</th>\n",
       "      <th>2390</th>\n",
       "      <th>2391</th>\n",
       "      <th>2392</th>\n",
       "      <th>2393</th>\n",
       "      <th>2394</th>\n",
       "      <th>2395</th>\n",
       "      <th>2396</th>\n",
       "      <th>2397</th>\n",
       "      <th>2398</th>\n",
       "      <th>2399</th>\n",
       "      <th>2400</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.227443</td>\n",
       "      <td>0.228545</td>\n",
       "      <td>0.229799</td>\n",
       "      <td>0.230523</td>\n",
       "      <td>0.231666</td>\n",
       "      <td>0.232931</td>\n",
       "      <td>0.233588</td>\n",
       "      <td>0.234605</td>\n",
       "      <td>0.235804</td>\n",
       "      <td>0.236921</td>\n",
       "      <td>0.238062</td>\n",
       "      <td>0.239106</td>\n",
       "      <td>0.240131</td>\n",
       "      <td>0.241234</td>\n",
       "      <td>0.242302</td>\n",
       "      <td>0.243401</td>\n",
       "      <td>0.244637</td>\n",
       "      <td>0.245741</td>\n",
       "      <td>0.246833</td>\n",
       "      <td>0.248083</td>\n",
       "      <td>0.249263</td>\n",
       "      <td>0.250429</td>\n",
       "      <td>0.251586</td>\n",
       "      <td>0.252721</td>\n",
       "      <td>0.254057</td>\n",
       "      <td>0.255508</td>\n",
       "      <td>0.256609</td>\n",
       "      <td>0.257853</td>\n",
       "      <td>0.259207</td>\n",
       "      <td>0.260403</td>\n",
       "      <td>0.261741</td>\n",
       "      <td>0.263133</td>\n",
       "      <td>0.264479</td>\n",
       "      <td>0.265983</td>\n",
       "      <td>0.267513</td>\n",
       "      <td>0.268972</td>\n",
       "      <td>0.270338</td>\n",
       "      <td>0.271744</td>\n",
       "      <td>0.273284</td>\n",
       "      <td>0.274936</td>\n",
       "      <td>0.276606</td>\n",
       "      <td>0.278276</td>\n",
       "      <td>0.279917</td>\n",
       "      <td>0.281612</td>\n",
       "      <td>0.283351</td>\n",
       "      <td>0.285097</td>\n",
       "      <td>0.286908</td>\n",
       "      <td>0.288725</td>\n",
       "      <td>0.290557</td>\n",
       "      <td>0.292472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.476467</td>\n",
       "      <td>0.476533</td>\n",
       "      <td>0.476503</td>\n",
       "      <td>0.476393</td>\n",
       "      <td>0.476283</td>\n",
       "      <td>0.476071</td>\n",
       "      <td>0.475939</td>\n",
       "      <td>0.475937</td>\n",
       "      <td>0.475733</td>\n",
       "      <td>0.475538</td>\n",
       "      <td>0.475322</td>\n",
       "      <td>0.474851</td>\n",
       "      <td>0.47433</td>\n",
       "      <td>0.473809</td>\n",
       "      <td>0.473287</td>\n",
       "      <td>0.472794</td>\n",
       "      <td>0.472152</td>\n",
       "      <td>0.471353</td>\n",
       "      <td>0.470456</td>\n",
       "      <td>0.469334</td>\n",
       "      <td>0.468234</td>\n",
       "      <td>0.467202</td>\n",
       "      <td>0.466068</td>\n",
       "      <td>0.464876</td>\n",
       "      <td>0.463645</td>\n",
       "      <td>0.462346</td>\n",
       "      <td>0.46098</td>\n",
       "      <td>0.459513</td>\n",
       "      <td>0.45823</td>\n",
       "      <td>0.456887</td>\n",
       "      <td>0.455493</td>\n",
       "      <td>0.454223</td>\n",
       "      <td>0.452812</td>\n",
       "      <td>0.451282</td>\n",
       "      <td>0.449921</td>\n",
       "      <td>0.448584</td>\n",
       "      <td>0.447024</td>\n",
       "      <td>0.445668</td>\n",
       "      <td>0.444354</td>\n",
       "      <td>0.442849</td>\n",
       "      <td>0.441628</td>\n",
       "      <td>0.440351</td>\n",
       "      <td>0.438906</td>\n",
       "      <td>0.437587</td>\n",
       "      <td>0.43613</td>\n",
       "      <td>0.434633</td>\n",
       "      <td>0.433239</td>\n",
       "      <td>0.431792</td>\n",
       "      <td>0.43044</td>\n",
       "      <td>0.429227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.203604</td>\n",
       "      <td>0.204856</td>\n",
       "      <td>0.206159</td>\n",
       "      <td>0.206983</td>\n",
       "      <td>0.208219</td>\n",
       "      <td>0.209534</td>\n",
       "      <td>0.210224</td>\n",
       "      <td>0.211487</td>\n",
       "      <td>0.212801</td>\n",
       "      <td>0.213752</td>\n",
       "      <td>0.214944</td>\n",
       "      <td>0.216192</td>\n",
       "      <td>0.217439</td>\n",
       "      <td>0.218535</td>\n",
       "      <td>0.219669</td>\n",
       "      <td>0.22093</td>\n",
       "      <td>0.222325</td>\n",
       "      <td>0.223525</td>\n",
       "      <td>0.224657</td>\n",
       "      <td>0.225927</td>\n",
       "      <td>0.227172</td>\n",
       "      <td>0.228481</td>\n",
       "      <td>0.229843</td>\n",
       "      <td>0.231135</td>\n",
       "      <td>0.232456</td>\n",
       "      <td>0.233807</td>\n",
       "      <td>0.235056</td>\n",
       "      <td>0.236406</td>\n",
       "      <td>0.237846</td>\n",
       "      <td>0.239231</td>\n",
       "      <td>0.240492</td>\n",
       "      <td>0.241811</td>\n",
       "      <td>0.243322</td>\n",
       "      <td>0.244692</td>\n",
       "      <td>0.2461</td>\n",
       "      <td>0.247614</td>\n",
       "      <td>0.249008</td>\n",
       "      <td>0.25052</td>\n",
       "      <td>0.252155</td>\n",
       "      <td>0.253631</td>\n",
       "      <td>0.255084</td>\n",
       "      <td>0.256573</td>\n",
       "      <td>0.258099</td>\n",
       "      <td>0.259726</td>\n",
       "      <td>0.261394</td>\n",
       "      <td>0.263017</td>\n",
       "      <td>0.264633</td>\n",
       "      <td>0.266251</td>\n",
       "      <td>0.267908</td>\n",
       "      <td>0.269633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.482508</td>\n",
       "      <td>0.483913</td>\n",
       "      <td>0.485242</td>\n",
       "      <td>0.486661</td>\n",
       "      <td>0.487982</td>\n",
       "      <td>0.489231</td>\n",
       "      <td>0.490476</td>\n",
       "      <td>0.491738</td>\n",
       "      <td>0.492878</td>\n",
       "      <td>0.494015</td>\n",
       "      <td>0.495149</td>\n",
       "      <td>0.496152</td>\n",
       "      <td>0.496954</td>\n",
       "      <td>0.497712</td>\n",
       "      <td>0.498373</td>\n",
       "      <td>0.498868</td>\n",
       "      <td>0.499313</td>\n",
       "      <td>0.499557</td>\n",
       "      <td>0.499725</td>\n",
       "      <td>0.499792</td>\n",
       "      <td>0.499774</td>\n",
       "      <td>0.499757</td>\n",
       "      <td>0.499616</td>\n",
       "      <td>0.499347</td>\n",
       "      <td>0.499035</td>\n",
       "      <td>0.498576</td>\n",
       "      <td>0.498159</td>\n",
       "      <td>0.49775</td>\n",
       "      <td>0.497424</td>\n",
       "      <td>0.497171</td>\n",
       "      <td>0.496828</td>\n",
       "      <td>0.496308</td>\n",
       "      <td>0.495675</td>\n",
       "      <td>0.494923</td>\n",
       "      <td>0.494119</td>\n",
       "      <td>0.493464</td>\n",
       "      <td>0.492781</td>\n",
       "      <td>0.492077</td>\n",
       "      <td>0.491473</td>\n",
       "      <td>0.490739</td>\n",
       "      <td>0.489955</td>\n",
       "      <td>0.489149</td>\n",
       "      <td>0.488276</td>\n",
       "      <td>0.487503</td>\n",
       "      <td>0.486767</td>\n",
       "      <td>0.485955</td>\n",
       "      <td>0.48522</td>\n",
       "      <td>0.484676</td>\n",
       "      <td>0.483985</td>\n",
       "      <td>0.483238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.209251</td>\n",
       "      <td>0.210377</td>\n",
       "      <td>0.211554</td>\n",
       "      <td>0.212393</td>\n",
       "      <td>0.213557</td>\n",
       "      <td>0.214754</td>\n",
       "      <td>0.215375</td>\n",
       "      <td>0.216572</td>\n",
       "      <td>0.217807</td>\n",
       "      <td>0.218665</td>\n",
       "      <td>0.219798</td>\n",
       "      <td>0.220923</td>\n",
       "      <td>0.221993</td>\n",
       "      <td>0.223018</td>\n",
       "      <td>0.224137</td>\n",
       "      <td>0.225378</td>\n",
       "      <td>0.226666</td>\n",
       "      <td>0.227759</td>\n",
       "      <td>0.228793</td>\n",
       "      <td>0.229962</td>\n",
       "      <td>0.231101</td>\n",
       "      <td>0.232282</td>\n",
       "      <td>0.233505</td>\n",
       "      <td>0.234744</td>\n",
       "      <td>0.235949</td>\n",
       "      <td>0.237133</td>\n",
       "      <td>0.238362</td>\n",
       "      <td>0.239553</td>\n",
       "      <td>0.240757</td>\n",
       "      <td>0.242024</td>\n",
       "      <td>0.243184</td>\n",
       "      <td>0.244386</td>\n",
       "      <td>0.245763</td>\n",
       "      <td>0.247058</td>\n",
       "      <td>0.248349</td>\n",
       "      <td>0.249667</td>\n",
       "      <td>0.250902</td>\n",
       "      <td>0.252245</td>\n",
       "      <td>0.253699</td>\n",
       "      <td>0.255016</td>\n",
       "      <td>0.256362</td>\n",
       "      <td>0.257747</td>\n",
       "      <td>0.2591</td>\n",
       "      <td>0.260566</td>\n",
       "      <td>0.262086</td>\n",
       "      <td>0.263565</td>\n",
       "      <td>0.265021</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>0.267988</td>\n",
       "      <td>0.269544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483675</td>\n",
       "      <td>0.484249</td>\n",
       "      <td>0.484805</td>\n",
       "      <td>0.485367</td>\n",
       "      <td>0.485871</td>\n",
       "      <td>0.486412</td>\n",
       "      <td>0.486851</td>\n",
       "      <td>0.487221</td>\n",
       "      <td>0.487486</td>\n",
       "      <td>0.487695</td>\n",
       "      <td>0.487954</td>\n",
       "      <td>0.488093</td>\n",
       "      <td>0.488067</td>\n",
       "      <td>0.488036</td>\n",
       "      <td>0.487923</td>\n",
       "      <td>0.487622</td>\n",
       "      <td>0.487368</td>\n",
       "      <td>0.487083</td>\n",
       "      <td>0.486593</td>\n",
       "      <td>0.485971</td>\n",
       "      <td>0.485289</td>\n",
       "      <td>0.484495</td>\n",
       "      <td>0.483655</td>\n",
       "      <td>0.482771</td>\n",
       "      <td>0.481886</td>\n",
       "      <td>0.480893</td>\n",
       "      <td>0.479931</td>\n",
       "      <td>0.479062</td>\n",
       "      <td>0.478223</td>\n",
       "      <td>0.477247</td>\n",
       "      <td>0.476334</td>\n",
       "      <td>0.4753</td>\n",
       "      <td>0.474102</td>\n",
       "      <td>0.472959</td>\n",
       "      <td>0.471745</td>\n",
       "      <td>0.47046</td>\n",
       "      <td>0.469232</td>\n",
       "      <td>0.468119</td>\n",
       "      <td>0.467104</td>\n",
       "      <td>0.466125</td>\n",
       "      <td>0.465152</td>\n",
       "      <td>0.464041</td>\n",
       "      <td>0.462798</td>\n",
       "      <td>0.461652</td>\n",
       "      <td>0.460399</td>\n",
       "      <td>0.45911</td>\n",
       "      <td>0.458042</td>\n",
       "      <td>0.456933</td>\n",
       "      <td>0.455851</td>\n",
       "      <td>0.454714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.216322</td>\n",
       "      <td>0.217478</td>\n",
       "      <td>0.21864</td>\n",
       "      <td>0.219436</td>\n",
       "      <td>0.220639</td>\n",
       "      <td>0.221928</td>\n",
       "      <td>0.222598</td>\n",
       "      <td>0.223641</td>\n",
       "      <td>0.224765</td>\n",
       "      <td>0.22569</td>\n",
       "      <td>0.226785</td>\n",
       "      <td>0.22794</td>\n",
       "      <td>0.229131</td>\n",
       "      <td>0.230184</td>\n",
       "      <td>0.231237</td>\n",
       "      <td>0.232377</td>\n",
       "      <td>0.233627</td>\n",
       "      <td>0.234747</td>\n",
       "      <td>0.235837</td>\n",
       "      <td>0.237043</td>\n",
       "      <td>0.238154</td>\n",
       "      <td>0.239294</td>\n",
       "      <td>0.240504</td>\n",
       "      <td>0.241765</td>\n",
       "      <td>0.242967</td>\n",
       "      <td>0.244115</td>\n",
       "      <td>0.245326</td>\n",
       "      <td>0.246563</td>\n",
       "      <td>0.247823</td>\n",
       "      <td>0.249061</td>\n",
       "      <td>0.250196</td>\n",
       "      <td>0.25137</td>\n",
       "      <td>0.252695</td>\n",
       "      <td>0.253953</td>\n",
       "      <td>0.255276</td>\n",
       "      <td>0.256688</td>\n",
       "      <td>0.25794</td>\n",
       "      <td>0.259289</td>\n",
       "      <td>0.260749</td>\n",
       "      <td>0.262037</td>\n",
       "      <td>0.263395</td>\n",
       "      <td>0.264803</td>\n",
       "      <td>0.26613</td>\n",
       "      <td>0.267561</td>\n",
       "      <td>0.269081</td>\n",
       "      <td>0.270609</td>\n",
       "      <td>0.272042</td>\n",
       "      <td>0.273491</td>\n",
       "      <td>0.275033</td>\n",
       "      <td>0.276628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.478092</td>\n",
       "      <td>0.47914</td>\n",
       "      <td>0.480126</td>\n",
       "      <td>0.48119</td>\n",
       "      <td>0.48212</td>\n",
       "      <td>0.482956</td>\n",
       "      <td>0.483802</td>\n",
       "      <td>0.484573</td>\n",
       "      <td>0.485334</td>\n",
       "      <td>0.486192</td>\n",
       "      <td>0.487009</td>\n",
       "      <td>0.487787</td>\n",
       "      <td>0.488263</td>\n",
       "      <td>0.488576</td>\n",
       "      <td>0.48886</td>\n",
       "      <td>0.48891</td>\n",
       "      <td>0.489013</td>\n",
       "      <td>0.489068</td>\n",
       "      <td>0.488979</td>\n",
       "      <td>0.488837</td>\n",
       "      <td>0.488529</td>\n",
       "      <td>0.488083</td>\n",
       "      <td>0.487602</td>\n",
       "      <td>0.487013</td>\n",
       "      <td>0.486377</td>\n",
       "      <td>0.48564</td>\n",
       "      <td>0.484934</td>\n",
       "      <td>0.484256</td>\n",
       "      <td>0.48363</td>\n",
       "      <td>0.482786</td>\n",
       "      <td>0.481929</td>\n",
       "      <td>0.480859</td>\n",
       "      <td>0.479632</td>\n",
       "      <td>0.478573</td>\n",
       "      <td>0.477594</td>\n",
       "      <td>0.476614</td>\n",
       "      <td>0.475586</td>\n",
       "      <td>0.474622</td>\n",
       "      <td>0.473571</td>\n",
       "      <td>0.472483</td>\n",
       "      <td>0.471433</td>\n",
       "      <td>0.470226</td>\n",
       "      <td>0.469052</td>\n",
       "      <td>0.467808</td>\n",
       "      <td>0.466539</td>\n",
       "      <td>0.465331</td>\n",
       "      <td>0.464089</td>\n",
       "      <td>0.462908</td>\n",
       "      <td>0.461745</td>\n",
       "      <td>0.460631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.221962</td>\n",
       "      <td>0.22318</td>\n",
       "      <td>0.224464</td>\n",
       "      <td>0.225349</td>\n",
       "      <td>0.226569</td>\n",
       "      <td>0.227868</td>\n",
       "      <td>0.228621</td>\n",
       "      <td>0.229779</td>\n",
       "      <td>0.231036</td>\n",
       "      <td>0.2321</td>\n",
       "      <td>0.233327</td>\n",
       "      <td>0.234549</td>\n",
       "      <td>0.235747</td>\n",
       "      <td>0.236822</td>\n",
       "      <td>0.238009</td>\n",
       "      <td>0.239325</td>\n",
       "      <td>0.24064</td>\n",
       "      <td>0.241825</td>\n",
       "      <td>0.242969</td>\n",
       "      <td>0.244208</td>\n",
       "      <td>0.245463</td>\n",
       "      <td>0.246771</td>\n",
       "      <td>0.248095</td>\n",
       "      <td>0.249358</td>\n",
       "      <td>0.250671</td>\n",
       "      <td>0.252032</td>\n",
       "      <td>0.253306</td>\n",
       "      <td>0.254605</td>\n",
       "      <td>0.255964</td>\n",
       "      <td>0.257333</td>\n",
       "      <td>0.25862</td>\n",
       "      <td>0.259946</td>\n",
       "      <td>0.261408</td>\n",
       "      <td>0.262775</td>\n",
       "      <td>0.264182</td>\n",
       "      <td>0.265676</td>\n",
       "      <td>0.267076</td>\n",
       "      <td>0.268571</td>\n",
       "      <td>0.270173</td>\n",
       "      <td>0.271641</td>\n",
       "      <td>0.273167</td>\n",
       "      <td>0.274711</td>\n",
       "      <td>0.276138</td>\n",
       "      <td>0.277751</td>\n",
       "      <td>0.279426</td>\n",
       "      <td>0.281006</td>\n",
       "      <td>0.282593</td>\n",
       "      <td>0.284213</td>\n",
       "      <td>0.285899</td>\n",
       "      <td>0.287643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494904</td>\n",
       "      <td>0.49588</td>\n",
       "      <td>0.496906</td>\n",
       "      <td>0.497995</td>\n",
       "      <td>0.4991</td>\n",
       "      <td>0.500296</td>\n",
       "      <td>0.501406</td>\n",
       "      <td>0.502597</td>\n",
       "      <td>0.50358</td>\n",
       "      <td>0.504499</td>\n",
       "      <td>0.505395</td>\n",
       "      <td>0.506048</td>\n",
       "      <td>0.506611</td>\n",
       "      <td>0.507098</td>\n",
       "      <td>0.507606</td>\n",
       "      <td>0.508134</td>\n",
       "      <td>0.508526</td>\n",
       "      <td>0.508862</td>\n",
       "      <td>0.508914</td>\n",
       "      <td>0.508622</td>\n",
       "      <td>0.50836</td>\n",
       "      <td>0.508001</td>\n",
       "      <td>0.507594</td>\n",
       "      <td>0.507176</td>\n",
       "      <td>0.506723</td>\n",
       "      <td>0.506177</td>\n",
       "      <td>0.505601</td>\n",
       "      <td>0.505026</td>\n",
       "      <td>0.504565</td>\n",
       "      <td>0.503928</td>\n",
       "      <td>0.50327</td>\n",
       "      <td>0.502512</td>\n",
       "      <td>0.501574</td>\n",
       "      <td>0.500697</td>\n",
       "      <td>0.499738</td>\n",
       "      <td>0.498658</td>\n",
       "      <td>0.497558</td>\n",
       "      <td>0.496502</td>\n",
       "      <td>0.495486</td>\n",
       "      <td>0.494491</td>\n",
       "      <td>0.493547</td>\n",
       "      <td>0.492568</td>\n",
       "      <td>0.491505</td>\n",
       "      <td>0.490468</td>\n",
       "      <td>0.489556</td>\n",
       "      <td>0.488629</td>\n",
       "      <td>0.487597</td>\n",
       "      <td>0.486627</td>\n",
       "      <td>0.485722</td>\n",
       "      <td>0.48464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.170577</td>\n",
       "      <td>0.171679</td>\n",
       "      <td>0.173045</td>\n",
       "      <td>0.17374</td>\n",
       "      <td>0.174551</td>\n",
       "      <td>0.175587</td>\n",
       "      <td>0.176568</td>\n",
       "      <td>0.177402</td>\n",
       "      <td>0.178378</td>\n",
       "      <td>0.179585</td>\n",
       "      <td>0.180657</td>\n",
       "      <td>0.181663</td>\n",
       "      <td>0.182706</td>\n",
       "      <td>0.183749</td>\n",
       "      <td>0.184706</td>\n",
       "      <td>0.185715</td>\n",
       "      <td>0.186987</td>\n",
       "      <td>0.188055</td>\n",
       "      <td>0.189014</td>\n",
       "      <td>0.190068</td>\n",
       "      <td>0.191136</td>\n",
       "      <td>0.192283</td>\n",
       "      <td>0.193461</td>\n",
       "      <td>0.194434</td>\n",
       "      <td>0.195595</td>\n",
       "      <td>0.196926</td>\n",
       "      <td>0.197932</td>\n",
       "      <td>0.199092</td>\n",
       "      <td>0.200385</td>\n",
       "      <td>0.201566</td>\n",
       "      <td>0.202745</td>\n",
       "      <td>0.203939</td>\n",
       "      <td>0.205154</td>\n",
       "      <td>0.206375</td>\n",
       "      <td>0.207644</td>\n",
       "      <td>0.20897</td>\n",
       "      <td>0.210336</td>\n",
       "      <td>0.211585</td>\n",
       "      <td>0.212801</td>\n",
       "      <td>0.214223</td>\n",
       "      <td>0.215605</td>\n",
       "      <td>0.216953</td>\n",
       "      <td>0.218317</td>\n",
       "      <td>0.219731</td>\n",
       "      <td>0.221198</td>\n",
       "      <td>0.22268</td>\n",
       "      <td>0.224102</td>\n",
       "      <td>0.22555</td>\n",
       "      <td>0.227072</td>\n",
       "      <td>0.22859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.491711</td>\n",
       "      <td>0.492527</td>\n",
       "      <td>0.493346</td>\n",
       "      <td>0.494217</td>\n",
       "      <td>0.495053</td>\n",
       "      <td>0.495868</td>\n",
       "      <td>0.496697</td>\n",
       "      <td>0.497632</td>\n",
       "      <td>0.498352</td>\n",
       "      <td>0.499055</td>\n",
       "      <td>0.499727</td>\n",
       "      <td>0.500113</td>\n",
       "      <td>0.500458</td>\n",
       "      <td>0.500845</td>\n",
       "      <td>0.501127</td>\n",
       "      <td>0.501279</td>\n",
       "      <td>0.501456</td>\n",
       "      <td>0.501524</td>\n",
       "      <td>0.501456</td>\n",
       "      <td>0.501346</td>\n",
       "      <td>0.501112</td>\n",
       "      <td>0.500683</td>\n",
       "      <td>0.500341</td>\n",
       "      <td>0.500042</td>\n",
       "      <td>0.499682</td>\n",
       "      <td>0.499373</td>\n",
       "      <td>0.498923</td>\n",
       "      <td>0.498402</td>\n",
       "      <td>0.497873</td>\n",
       "      <td>0.497166</td>\n",
       "      <td>0.496639</td>\n",
       "      <td>0.496061</td>\n",
       "      <td>0.495349</td>\n",
       "      <td>0.494927</td>\n",
       "      <td>0.494526</td>\n",
       "      <td>0.494045</td>\n",
       "      <td>0.493589</td>\n",
       "      <td>0.492865</td>\n",
       "      <td>0.492026</td>\n",
       "      <td>0.491156</td>\n",
       "      <td>0.490235</td>\n",
       "      <td>0.489439</td>\n",
       "      <td>0.488697</td>\n",
       "      <td>0.487981</td>\n",
       "      <td>0.487384</td>\n",
       "      <td>0.486723</td>\n",
       "      <td>0.485806</td>\n",
       "      <td>0.484941</td>\n",
       "      <td>0.484272</td>\n",
       "      <td>0.48352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.192066</td>\n",
       "      <td>0.193132</td>\n",
       "      <td>0.194557</td>\n",
       "      <td>0.195241</td>\n",
       "      <td>0.196112</td>\n",
       "      <td>0.197217</td>\n",
       "      <td>0.19817</td>\n",
       "      <td>0.199078</td>\n",
       "      <td>0.200146</td>\n",
       "      <td>0.201375</td>\n",
       "      <td>0.202375</td>\n",
       "      <td>0.203323</td>\n",
       "      <td>0.204373</td>\n",
       "      <td>0.205457</td>\n",
       "      <td>0.206446</td>\n",
       "      <td>0.207477</td>\n",
       "      <td>0.208784</td>\n",
       "      <td>0.209859</td>\n",
       "      <td>0.21082</td>\n",
       "      <td>0.211902</td>\n",
       "      <td>0.21299</td>\n",
       "      <td>0.214157</td>\n",
       "      <td>0.215362</td>\n",
       "      <td>0.216384</td>\n",
       "      <td>0.217566</td>\n",
       "      <td>0.218876</td>\n",
       "      <td>0.219851</td>\n",
       "      <td>0.221032</td>\n",
       "      <td>0.222358</td>\n",
       "      <td>0.223493</td>\n",
       "      <td>0.224669</td>\n",
       "      <td>0.225891</td>\n",
       "      <td>0.227129</td>\n",
       "      <td>0.228357</td>\n",
       "      <td>0.229583</td>\n",
       "      <td>0.230838</td>\n",
       "      <td>0.232255</td>\n",
       "      <td>0.233535</td>\n",
       "      <td>0.234744</td>\n",
       "      <td>0.236202</td>\n",
       "      <td>0.23759</td>\n",
       "      <td>0.238919</td>\n",
       "      <td>0.240272</td>\n",
       "      <td>0.241679</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>0.244604</td>\n",
       "      <td>0.246052</td>\n",
       "      <td>0.247497</td>\n",
       "      <td>0.248963</td>\n",
       "      <td>0.250414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.481373</td>\n",
       "      <td>0.482305</td>\n",
       "      <td>0.483073</td>\n",
       "      <td>0.483825</td>\n",
       "      <td>0.484581</td>\n",
       "      <td>0.485212</td>\n",
       "      <td>0.485914</td>\n",
       "      <td>0.486766</td>\n",
       "      <td>0.487459</td>\n",
       "      <td>0.488145</td>\n",
       "      <td>0.488827</td>\n",
       "      <td>0.489371</td>\n",
       "      <td>0.48976</td>\n",
       "      <td>0.490164</td>\n",
       "      <td>0.490393</td>\n",
       "      <td>0.490409</td>\n",
       "      <td>0.490443</td>\n",
       "      <td>0.49023</td>\n",
       "      <td>0.490005</td>\n",
       "      <td>0.489826</td>\n",
       "      <td>0.489487</td>\n",
       "      <td>0.489006</td>\n",
       "      <td>0.488584</td>\n",
       "      <td>0.4881</td>\n",
       "      <td>0.487656</td>\n",
       "      <td>0.487429</td>\n",
       "      <td>0.486938</td>\n",
       "      <td>0.486369</td>\n",
       "      <td>0.485716</td>\n",
       "      <td>0.484946</td>\n",
       "      <td>0.484136</td>\n",
       "      <td>0.483392</td>\n",
       "      <td>0.482595</td>\n",
       "      <td>0.481799</td>\n",
       "      <td>0.481045</td>\n",
       "      <td>0.480176</td>\n",
       "      <td>0.479286</td>\n",
       "      <td>0.478507</td>\n",
       "      <td>0.477633</td>\n",
       "      <td>0.476784</td>\n",
       "      <td>0.47606</td>\n",
       "      <td>0.475143</td>\n",
       "      <td>0.47408</td>\n",
       "      <td>0.47316</td>\n",
       "      <td>0.472377</td>\n",
       "      <td>0.471585</td>\n",
       "      <td>0.470846</td>\n",
       "      <td>0.470043</td>\n",
       "      <td>0.468979</td>\n",
       "      <td>0.467946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.157823</td>\n",
       "      <td>0.158827</td>\n",
       "      <td>0.160118</td>\n",
       "      <td>0.160768</td>\n",
       "      <td>0.161511</td>\n",
       "      <td>0.162481</td>\n",
       "      <td>0.163457</td>\n",
       "      <td>0.164381</td>\n",
       "      <td>0.165405</td>\n",
       "      <td>0.16654</td>\n",
       "      <td>0.167501</td>\n",
       "      <td>0.168376</td>\n",
       "      <td>0.169307</td>\n",
       "      <td>0.170369</td>\n",
       "      <td>0.171281</td>\n",
       "      <td>0.172214</td>\n",
       "      <td>0.173515</td>\n",
       "      <td>0.174535</td>\n",
       "      <td>0.175423</td>\n",
       "      <td>0.176463</td>\n",
       "      <td>0.177442</td>\n",
       "      <td>0.178528</td>\n",
       "      <td>0.17972</td>\n",
       "      <td>0.180646</td>\n",
       "      <td>0.181755</td>\n",
       "      <td>0.183035</td>\n",
       "      <td>0.183961</td>\n",
       "      <td>0.185041</td>\n",
       "      <td>0.186263</td>\n",
       "      <td>0.187385</td>\n",
       "      <td>0.188531</td>\n",
       "      <td>0.189705</td>\n",
       "      <td>0.190889</td>\n",
       "      <td>0.192051</td>\n",
       "      <td>0.193234</td>\n",
       "      <td>0.194456</td>\n",
       "      <td>0.195701</td>\n",
       "      <td>0.19689</td>\n",
       "      <td>0.198099</td>\n",
       "      <td>0.199485</td>\n",
       "      <td>0.200843</td>\n",
       "      <td>0.202152</td>\n",
       "      <td>0.203428</td>\n",
       "      <td>0.204747</td>\n",
       "      <td>0.20613</td>\n",
       "      <td>0.207551</td>\n",
       "      <td>0.208935</td>\n",
       "      <td>0.210344</td>\n",
       "      <td>0.211809</td>\n",
       "      <td>0.213238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.484249</td>\n",
       "      <td>0.485663</td>\n",
       "      <td>0.487003</td>\n",
       "      <td>0.488484</td>\n",
       "      <td>0.489824</td>\n",
       "      <td>0.490984</td>\n",
       "      <td>0.492266</td>\n",
       "      <td>0.493633</td>\n",
       "      <td>0.494883</td>\n",
       "      <td>0.49628</td>\n",
       "      <td>0.497529</td>\n",
       "      <td>0.498487</td>\n",
       "      <td>0.499395</td>\n",
       "      <td>0.500234</td>\n",
       "      <td>0.501065</td>\n",
       "      <td>0.501934</td>\n",
       "      <td>0.502662</td>\n",
       "      <td>0.503236</td>\n",
       "      <td>0.503609</td>\n",
       "      <td>0.503767</td>\n",
       "      <td>0.503855</td>\n",
       "      <td>0.503706</td>\n",
       "      <td>0.503709</td>\n",
       "      <td>0.503821</td>\n",
       "      <td>0.503817</td>\n",
       "      <td>0.503827</td>\n",
       "      <td>0.503806</td>\n",
       "      <td>0.503717</td>\n",
       "      <td>0.503693</td>\n",
       "      <td>0.503704</td>\n",
       "      <td>0.503545</td>\n",
       "      <td>0.503258</td>\n",
       "      <td>0.502882</td>\n",
       "      <td>0.502623</td>\n",
       "      <td>0.502539</td>\n",
       "      <td>0.502408</td>\n",
       "      <td>0.502252</td>\n",
       "      <td>0.502011</td>\n",
       "      <td>0.501601</td>\n",
       "      <td>0.501176</td>\n",
       "      <td>0.500801</td>\n",
       "      <td>0.500384</td>\n",
       "      <td>0.499999</td>\n",
       "      <td>0.499698</td>\n",
       "      <td>0.499409</td>\n",
       "      <td>0.499075</td>\n",
       "      <td>0.498732</td>\n",
       "      <td>0.498446</td>\n",
       "      <td>0.498169</td>\n",
       "      <td>0.49771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.187465</td>\n",
       "      <td>0.188537</td>\n",
       "      <td>0.189853</td>\n",
       "      <td>0.190496</td>\n",
       "      <td>0.191295</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>0.193159</td>\n",
       "      <td>0.19402</td>\n",
       "      <td>0.195035</td>\n",
       "      <td>0.19618</td>\n",
       "      <td>0.197145</td>\n",
       "      <td>0.198041</td>\n",
       "      <td>0.199013</td>\n",
       "      <td>0.200096</td>\n",
       "      <td>0.20101</td>\n",
       "      <td>0.201946</td>\n",
       "      <td>0.203282</td>\n",
       "      <td>0.204319</td>\n",
       "      <td>0.205217</td>\n",
       "      <td>0.206285</td>\n",
       "      <td>0.207336</td>\n",
       "      <td>0.208443</td>\n",
       "      <td>0.209569</td>\n",
       "      <td>0.210492</td>\n",
       "      <td>0.211639</td>\n",
       "      <td>0.212968</td>\n",
       "      <td>0.213902</td>\n",
       "      <td>0.214992</td>\n",
       "      <td>0.216233</td>\n",
       "      <td>0.217368</td>\n",
       "      <td>0.218502</td>\n",
       "      <td>0.219674</td>\n",
       "      <td>0.220907</td>\n",
       "      <td>0.222155</td>\n",
       "      <td>0.223399</td>\n",
       "      <td>0.224644</td>\n",
       "      <td>0.225971</td>\n",
       "      <td>0.227202</td>\n",
       "      <td>0.228415</td>\n",
       "      <td>0.229848</td>\n",
       "      <td>0.231259</td>\n",
       "      <td>0.232625</td>\n",
       "      <td>0.233961</td>\n",
       "      <td>0.23536</td>\n",
       "      <td>0.236809</td>\n",
       "      <td>0.238263</td>\n",
       "      <td>0.239764</td>\n",
       "      <td>0.24125</td>\n",
       "      <td>0.242732</td>\n",
       "      <td>0.244288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.48507</td>\n",
       "      <td>0.485914</td>\n",
       "      <td>0.486651</td>\n",
       "      <td>0.487325</td>\n",
       "      <td>0.488039</td>\n",
       "      <td>0.488756</td>\n",
       "      <td>0.489426</td>\n",
       "      <td>0.490195</td>\n",
       "      <td>0.490745</td>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.49167</td>\n",
       "      <td>0.491929</td>\n",
       "      <td>0.492133</td>\n",
       "      <td>0.4924</td>\n",
       "      <td>0.492557</td>\n",
       "      <td>0.492638</td>\n",
       "      <td>0.492652</td>\n",
       "      <td>0.49246</td>\n",
       "      <td>0.492195</td>\n",
       "      <td>0.491877</td>\n",
       "      <td>0.491424</td>\n",
       "      <td>0.490775</td>\n",
       "      <td>0.490266</td>\n",
       "      <td>0.489776</td>\n",
       "      <td>0.489249</td>\n",
       "      <td>0.488941</td>\n",
       "      <td>0.488393</td>\n",
       "      <td>0.487626</td>\n",
       "      <td>0.486989</td>\n",
       "      <td>0.486376</td>\n",
       "      <td>0.485518</td>\n",
       "      <td>0.484665</td>\n",
       "      <td>0.48383</td>\n",
       "      <td>0.483002</td>\n",
       "      <td>0.482233</td>\n",
       "      <td>0.481532</td>\n",
       "      <td>0.48076</td>\n",
       "      <td>0.479756</td>\n",
       "      <td>0.478716</td>\n",
       "      <td>0.477626</td>\n",
       "      <td>0.476569</td>\n",
       "      <td>0.475617</td>\n",
       "      <td>0.474646</td>\n",
       "      <td>0.47384</td>\n",
       "      <td>0.473031</td>\n",
       "      <td>0.472133</td>\n",
       "      <td>0.471248</td>\n",
       "      <td>0.470238</td>\n",
       "      <td>0.469262</td>\n",
       "      <td>0.468359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.153616</td>\n",
       "      <td>0.154612</td>\n",
       "      <td>0.15598</td>\n",
       "      <td>0.156683</td>\n",
       "      <td>0.157475</td>\n",
       "      <td>0.15843</td>\n",
       "      <td>0.159281</td>\n",
       "      <td>0.160116</td>\n",
       "      <td>0.161115</td>\n",
       "      <td>0.162278</td>\n",
       "      <td>0.163285</td>\n",
       "      <td>0.164149</td>\n",
       "      <td>0.16502</td>\n",
       "      <td>0.166089</td>\n",
       "      <td>0.166993</td>\n",
       "      <td>0.167876</td>\n",
       "      <td>0.169086</td>\n",
       "      <td>0.170035</td>\n",
       "      <td>0.170899</td>\n",
       "      <td>0.171964</td>\n",
       "      <td>0.172977</td>\n",
       "      <td>0.174016</td>\n",
       "      <td>0.175076</td>\n",
       "      <td>0.175999</td>\n",
       "      <td>0.177067</td>\n",
       "      <td>0.178263</td>\n",
       "      <td>0.179229</td>\n",
       "      <td>0.180265</td>\n",
       "      <td>0.181397</td>\n",
       "      <td>0.182515</td>\n",
       "      <td>0.183609</td>\n",
       "      <td>0.184706</td>\n",
       "      <td>0.185832</td>\n",
       "      <td>0.18693</td>\n",
       "      <td>0.188088</td>\n",
       "      <td>0.189333</td>\n",
       "      <td>0.190591</td>\n",
       "      <td>0.191709</td>\n",
       "      <td>0.19279</td>\n",
       "      <td>0.194114</td>\n",
       "      <td>0.19539</td>\n",
       "      <td>0.196628</td>\n",
       "      <td>0.197897</td>\n",
       "      <td>0.199133</td>\n",
       "      <td>0.200429</td>\n",
       "      <td>0.201823</td>\n",
       "      <td>0.203155</td>\n",
       "      <td>0.204478</td>\n",
       "      <td>0.205841</td>\n",
       "      <td>0.207224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500999</td>\n",
       "      <td>0.502385</td>\n",
       "      <td>0.503779</td>\n",
       "      <td>0.505297</td>\n",
       "      <td>0.506784</td>\n",
       "      <td>0.508241</td>\n",
       "      <td>0.509722</td>\n",
       "      <td>0.511359</td>\n",
       "      <td>0.512763</td>\n",
       "      <td>0.514067</td>\n",
       "      <td>0.515484</td>\n",
       "      <td>0.51676</td>\n",
       "      <td>0.517899</td>\n",
       "      <td>0.519208</td>\n",
       "      <td>0.520224</td>\n",
       "      <td>0.520887</td>\n",
       "      <td>0.521678</td>\n",
       "      <td>0.52227</td>\n",
       "      <td>0.52282</td>\n",
       "      <td>0.523524</td>\n",
       "      <td>0.523939</td>\n",
       "      <td>0.524105</td>\n",
       "      <td>0.524312</td>\n",
       "      <td>0.524363</td>\n",
       "      <td>0.524455</td>\n",
       "      <td>0.524659</td>\n",
       "      <td>0.524732</td>\n",
       "      <td>0.524749</td>\n",
       "      <td>0.524861</td>\n",
       "      <td>0.52477</td>\n",
       "      <td>0.524667</td>\n",
       "      <td>0.524601</td>\n",
       "      <td>0.524456</td>\n",
       "      <td>0.524417</td>\n",
       "      <td>0.524356</td>\n",
       "      <td>0.524018</td>\n",
       "      <td>0.523661</td>\n",
       "      <td>0.5234</td>\n",
       "      <td>0.523105</td>\n",
       "      <td>0.522731</td>\n",
       "      <td>0.522212</td>\n",
       "      <td>0.521695</td>\n",
       "      <td>0.521132</td>\n",
       "      <td>0.520675</td>\n",
       "      <td>0.5205</td>\n",
       "      <td>0.520111</td>\n",
       "      <td>0.519579</td>\n",
       "      <td>0.519268</td>\n",
       "      <td>0.518902</td>\n",
       "      <td>0.518571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 1901 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "FID       500       501       502       503       504       505       506  \\\n",
       "0    0.227443  0.228545  0.229799  0.230523  0.231666  0.232931  0.233588   \n",
       "1    0.203604  0.204856  0.206159  0.206983  0.208219  0.209534  0.210224   \n",
       "2    0.209251  0.210377  0.211554  0.212393  0.213557  0.214754  0.215375   \n",
       "3    0.216322  0.217478   0.21864  0.219436  0.220639  0.221928  0.222598   \n",
       "4    0.221962   0.22318  0.224464  0.225349  0.226569  0.227868  0.228621   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "76   0.170577  0.171679  0.173045   0.17374  0.174551  0.175587  0.176568   \n",
       "77   0.192066  0.193132  0.194557  0.195241  0.196112  0.197217   0.19817   \n",
       "78   0.157823  0.158827  0.160118  0.160768  0.161511  0.162481  0.163457   \n",
       "79   0.187465  0.188537  0.189853  0.190496  0.191295    0.1923  0.193159   \n",
       "80   0.153616  0.154612   0.15598  0.156683  0.157475   0.15843  0.159281   \n",
       "\n",
       "FID       507       508       509       510       511       512       513  \\\n",
       "0    0.234605  0.235804  0.236921  0.238062  0.239106  0.240131  0.241234   \n",
       "1    0.211487  0.212801  0.213752  0.214944  0.216192  0.217439  0.218535   \n",
       "2    0.216572  0.217807  0.218665  0.219798  0.220923  0.221993  0.223018   \n",
       "3    0.223641  0.224765   0.22569  0.226785   0.22794  0.229131  0.230184   \n",
       "4    0.229779  0.231036    0.2321  0.233327  0.234549  0.235747  0.236822   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "76   0.177402  0.178378  0.179585  0.180657  0.181663  0.182706  0.183749   \n",
       "77   0.199078  0.200146  0.201375  0.202375  0.203323  0.204373  0.205457   \n",
       "78   0.164381  0.165405   0.16654  0.167501  0.168376  0.169307  0.170369   \n",
       "79    0.19402  0.195035   0.19618  0.197145  0.198041  0.199013  0.200096   \n",
       "80   0.160116  0.161115  0.162278  0.163285  0.164149   0.16502  0.166089   \n",
       "\n",
       "FID       514       515       516       517       518       519       520  \\\n",
       "0    0.242302  0.243401  0.244637  0.245741  0.246833  0.248083  0.249263   \n",
       "1    0.219669   0.22093  0.222325  0.223525  0.224657  0.225927  0.227172   \n",
       "2    0.224137  0.225378  0.226666  0.227759  0.228793  0.229962  0.231101   \n",
       "3    0.231237  0.232377  0.233627  0.234747  0.235837  0.237043  0.238154   \n",
       "4    0.238009  0.239325   0.24064  0.241825  0.242969  0.244208  0.245463   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "76   0.184706  0.185715  0.186987  0.188055  0.189014  0.190068  0.191136   \n",
       "77   0.206446  0.207477  0.208784  0.209859   0.21082  0.211902   0.21299   \n",
       "78   0.171281  0.172214  0.173515  0.174535  0.175423  0.176463  0.177442   \n",
       "79    0.20101  0.201946  0.203282  0.204319  0.205217  0.206285  0.207336   \n",
       "80   0.166993  0.167876  0.169086  0.170035  0.170899  0.171964  0.172977   \n",
       "\n",
       "FID       521       522       523       524       525       526       527  \\\n",
       "0    0.250429  0.251586  0.252721  0.254057  0.255508  0.256609  0.257853   \n",
       "1    0.228481  0.229843  0.231135  0.232456  0.233807  0.235056  0.236406   \n",
       "2    0.232282  0.233505  0.234744  0.235949  0.237133  0.238362  0.239553   \n",
       "3    0.239294  0.240504  0.241765  0.242967  0.244115  0.245326  0.246563   \n",
       "4    0.246771  0.248095  0.249358  0.250671  0.252032  0.253306  0.254605   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "76   0.192283  0.193461  0.194434  0.195595  0.196926  0.197932  0.199092   \n",
       "77   0.214157  0.215362  0.216384  0.217566  0.218876  0.219851  0.221032   \n",
       "78   0.178528   0.17972  0.180646  0.181755  0.183035  0.183961  0.185041   \n",
       "79   0.208443  0.209569  0.210492  0.211639  0.212968  0.213902  0.214992   \n",
       "80   0.174016  0.175076  0.175999  0.177067  0.178263  0.179229  0.180265   \n",
       "\n",
       "FID       528       529       530       531       532       533       534  \\\n",
       "0    0.259207  0.260403  0.261741  0.263133  0.264479  0.265983  0.267513   \n",
       "1    0.237846  0.239231  0.240492  0.241811  0.243322  0.244692    0.2461   \n",
       "2    0.240757  0.242024  0.243184  0.244386  0.245763  0.247058  0.248349   \n",
       "3    0.247823  0.249061  0.250196   0.25137  0.252695  0.253953  0.255276   \n",
       "4    0.255964  0.257333   0.25862  0.259946  0.261408  0.262775  0.264182   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "76   0.200385  0.201566  0.202745  0.203939  0.205154  0.206375  0.207644   \n",
       "77   0.222358  0.223493  0.224669  0.225891  0.227129  0.228357  0.229583   \n",
       "78   0.186263  0.187385  0.188531  0.189705  0.190889  0.192051  0.193234   \n",
       "79   0.216233  0.217368  0.218502  0.219674  0.220907  0.222155  0.223399   \n",
       "80   0.181397  0.182515  0.183609  0.184706  0.185832   0.18693  0.188088   \n",
       "\n",
       "FID       535       536       537       538       539       540       541  \\\n",
       "0    0.268972  0.270338  0.271744  0.273284  0.274936  0.276606  0.278276   \n",
       "1    0.247614  0.249008   0.25052  0.252155  0.253631  0.255084  0.256573   \n",
       "2    0.249667  0.250902  0.252245  0.253699  0.255016  0.256362  0.257747   \n",
       "3    0.256688   0.25794  0.259289  0.260749  0.262037  0.263395  0.264803   \n",
       "4    0.265676  0.267076  0.268571  0.270173  0.271641  0.273167  0.274711   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "76    0.20897  0.210336  0.211585  0.212801  0.214223  0.215605  0.216953   \n",
       "77   0.230838  0.232255  0.233535  0.234744  0.236202   0.23759  0.238919   \n",
       "78   0.194456  0.195701   0.19689  0.198099  0.199485  0.200843  0.202152   \n",
       "79   0.224644  0.225971  0.227202  0.228415  0.229848  0.231259  0.232625   \n",
       "80   0.189333  0.190591  0.191709   0.19279  0.194114   0.19539  0.196628   \n",
       "\n",
       "FID       542       543       544       545       546       547       548  \\\n",
       "0    0.279917  0.281612  0.283351  0.285097  0.286908  0.288725  0.290557   \n",
       "1    0.258099  0.259726  0.261394  0.263017  0.264633  0.266251  0.267908   \n",
       "2      0.2591  0.260566  0.262086  0.263565  0.265021  0.266482  0.267988   \n",
       "3     0.26613  0.267561  0.269081  0.270609  0.272042  0.273491  0.275033   \n",
       "4    0.276138  0.277751  0.279426  0.281006  0.282593  0.284213  0.285899   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "76   0.218317  0.219731  0.221198   0.22268  0.224102   0.22555  0.227072   \n",
       "77   0.240272  0.241679  0.243137  0.244604  0.246052  0.247497  0.248963   \n",
       "78   0.203428  0.204747   0.20613  0.207551  0.208935  0.210344  0.211809   \n",
       "79   0.233961   0.23536  0.236809  0.238263  0.239764   0.24125  0.242732   \n",
       "80   0.197897  0.199133  0.200429  0.201823  0.203155  0.204478  0.205841   \n",
       "\n",
       "FID       549  ...      2351      2352      2353      2354      2355  \\\n",
       "0    0.292472  ...  0.476467  0.476533  0.476503  0.476393  0.476283   \n",
       "1    0.269633  ...  0.482508  0.483913  0.485242  0.486661  0.487982   \n",
       "2    0.269544  ...  0.483675  0.484249  0.484805  0.485367  0.485871   \n",
       "3    0.276628  ...  0.478092   0.47914  0.480126   0.48119   0.48212   \n",
       "4    0.287643  ...  0.494904   0.49588  0.496906  0.497995    0.4991   \n",
       "..        ...  ...       ...       ...       ...       ...       ...   \n",
       "76    0.22859  ...  0.491711  0.492527  0.493346  0.494217  0.495053   \n",
       "77   0.250414  ...  0.481373  0.482305  0.483073  0.483825  0.484581   \n",
       "78   0.213238  ...  0.484249  0.485663  0.487003  0.488484  0.489824   \n",
       "79   0.244288  ...   0.48507  0.485914  0.486651  0.487325  0.488039   \n",
       "80   0.207224  ...  0.500999  0.502385  0.503779  0.505297  0.506784   \n",
       "\n",
       "FID      2356      2357      2358      2359      2360      2361      2362  \\\n",
       "0    0.476071  0.475939  0.475937  0.475733  0.475538  0.475322  0.474851   \n",
       "1    0.489231  0.490476  0.491738  0.492878  0.494015  0.495149  0.496152   \n",
       "2    0.486412  0.486851  0.487221  0.487486  0.487695  0.487954  0.488093   \n",
       "3    0.482956  0.483802  0.484573  0.485334  0.486192  0.487009  0.487787   \n",
       "4    0.500296  0.501406  0.502597   0.50358  0.504499  0.505395  0.506048   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "76   0.495868  0.496697  0.497632  0.498352  0.499055  0.499727  0.500113   \n",
       "77   0.485212  0.485914  0.486766  0.487459  0.488145  0.488827  0.489371   \n",
       "78   0.490984  0.492266  0.493633  0.494883   0.49628  0.497529  0.498487   \n",
       "79   0.488756  0.489426  0.490195  0.490745  0.491187   0.49167  0.491929   \n",
       "80   0.508241  0.509722  0.511359  0.512763  0.514067  0.515484   0.51676   \n",
       "\n",
       "FID      2363      2364      2365      2366      2367      2368      2369  \\\n",
       "0     0.47433  0.473809  0.473287  0.472794  0.472152  0.471353  0.470456   \n",
       "1    0.496954  0.497712  0.498373  0.498868  0.499313  0.499557  0.499725   \n",
       "2    0.488067  0.488036  0.487923  0.487622  0.487368  0.487083  0.486593   \n",
       "3    0.488263  0.488576   0.48886   0.48891  0.489013  0.489068  0.488979   \n",
       "4    0.506611  0.507098  0.507606  0.508134  0.508526  0.508862  0.508914   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "76   0.500458  0.500845  0.501127  0.501279  0.501456  0.501524  0.501456   \n",
       "77    0.48976  0.490164  0.490393  0.490409  0.490443   0.49023  0.490005   \n",
       "78   0.499395  0.500234  0.501065  0.501934  0.502662  0.503236  0.503609   \n",
       "79   0.492133    0.4924  0.492557  0.492638  0.492652   0.49246  0.492195   \n",
       "80   0.517899  0.519208  0.520224  0.520887  0.521678   0.52227   0.52282   \n",
       "\n",
       "FID      2370      2371      2372      2373      2374      2375      2376  \\\n",
       "0    0.469334  0.468234  0.467202  0.466068  0.464876  0.463645  0.462346   \n",
       "1    0.499792  0.499774  0.499757  0.499616  0.499347  0.499035  0.498576   \n",
       "2    0.485971  0.485289  0.484495  0.483655  0.482771  0.481886  0.480893   \n",
       "3    0.488837  0.488529  0.488083  0.487602  0.487013  0.486377   0.48564   \n",
       "4    0.508622   0.50836  0.508001  0.507594  0.507176  0.506723  0.506177   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "76   0.501346  0.501112  0.500683  0.500341  0.500042  0.499682  0.499373   \n",
       "77   0.489826  0.489487  0.489006  0.488584    0.4881  0.487656  0.487429   \n",
       "78   0.503767  0.503855  0.503706  0.503709  0.503821  0.503817  0.503827   \n",
       "79   0.491877  0.491424  0.490775  0.490266  0.489776  0.489249  0.488941   \n",
       "80   0.523524  0.523939  0.524105  0.524312  0.524363  0.524455  0.524659   \n",
       "\n",
       "FID      2377      2378      2379      2380      2381      2382      2383  \\\n",
       "0     0.46098  0.459513   0.45823  0.456887  0.455493  0.454223  0.452812   \n",
       "1    0.498159   0.49775  0.497424  0.497171  0.496828  0.496308  0.495675   \n",
       "2    0.479931  0.479062  0.478223  0.477247  0.476334    0.4753  0.474102   \n",
       "3    0.484934  0.484256   0.48363  0.482786  0.481929  0.480859  0.479632   \n",
       "4    0.505601  0.505026  0.504565  0.503928   0.50327  0.502512  0.501574   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "76   0.498923  0.498402  0.497873  0.497166  0.496639  0.496061  0.495349   \n",
       "77   0.486938  0.486369  0.485716  0.484946  0.484136  0.483392  0.482595   \n",
       "78   0.503806  0.503717  0.503693  0.503704  0.503545  0.503258  0.502882   \n",
       "79   0.488393  0.487626  0.486989  0.486376  0.485518  0.484665   0.48383   \n",
       "80   0.524732  0.524749  0.524861   0.52477  0.524667  0.524601  0.524456   \n",
       "\n",
       "FID      2384      2385      2386      2387      2388      2389      2390  \\\n",
       "0    0.451282  0.449921  0.448584  0.447024  0.445668  0.444354  0.442849   \n",
       "1    0.494923  0.494119  0.493464  0.492781  0.492077  0.491473  0.490739   \n",
       "2    0.472959  0.471745   0.47046  0.469232  0.468119  0.467104  0.466125   \n",
       "3    0.478573  0.477594  0.476614  0.475586  0.474622  0.473571  0.472483   \n",
       "4    0.500697  0.499738  0.498658  0.497558  0.496502  0.495486  0.494491   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "76   0.494927  0.494526  0.494045  0.493589  0.492865  0.492026  0.491156   \n",
       "77   0.481799  0.481045  0.480176  0.479286  0.478507  0.477633  0.476784   \n",
       "78   0.502623  0.502539  0.502408  0.502252  0.502011  0.501601  0.501176   \n",
       "79   0.483002  0.482233  0.481532   0.48076  0.479756  0.478716  0.477626   \n",
       "80   0.524417  0.524356  0.524018  0.523661    0.5234  0.523105  0.522731   \n",
       "\n",
       "FID      2391      2392      2393      2394      2395      2396      2397  \\\n",
       "0    0.441628  0.440351  0.438906  0.437587   0.43613  0.434633  0.433239   \n",
       "1    0.489955  0.489149  0.488276  0.487503  0.486767  0.485955   0.48522   \n",
       "2    0.465152  0.464041  0.462798  0.461652  0.460399   0.45911  0.458042   \n",
       "3    0.471433  0.470226  0.469052  0.467808  0.466539  0.465331  0.464089   \n",
       "4    0.493547  0.492568  0.491505  0.490468  0.489556  0.488629  0.487597   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "76   0.490235  0.489439  0.488697  0.487981  0.487384  0.486723  0.485806   \n",
       "77    0.47606  0.475143   0.47408   0.47316  0.472377  0.471585  0.470846   \n",
       "78   0.500801  0.500384  0.499999  0.499698  0.499409  0.499075  0.498732   \n",
       "79   0.476569  0.475617  0.474646   0.47384  0.473031  0.472133  0.471248   \n",
       "80   0.522212  0.521695  0.521132  0.520675    0.5205  0.520111  0.519579   \n",
       "\n",
       "FID      2398      2399      2400  \n",
       "0    0.431792   0.43044  0.429227  \n",
       "1    0.484676  0.483985  0.483238  \n",
       "2    0.456933  0.455851  0.454714  \n",
       "3    0.462908  0.461745  0.460631  \n",
       "4    0.486627  0.485722   0.48464  \n",
       "..        ...       ...       ...  \n",
       "76   0.484941  0.484272   0.48352  \n",
       "77   0.470043  0.468979  0.467946  \n",
       "78   0.498446  0.498169   0.49771  \n",
       "79   0.470238  0.469262  0.468359  \n",
       "80   0.519268  0.518902  0.518571  \n",
       "\n",
       "[81 rows x 1901 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_faulty = pd.read_csv('oil.csv')\n",
    "df_faulty = df_faulty.T\n",
    "df_faulty.columns = df_faulty.iloc[0,:].copy()\n",
    "df_faulty = df_faulty.reset_index(drop=True)\n",
    "df_faulty = df_faulty.iloc[1:, :].copy()\n",
    "df_faulty.head(5)\n",
    "\n",
    "#df = pd.read_csv('uae.csv')\n",
    "spectra = df_faulty.iloc[:, 6:2158].copy()\n",
    "temp_spec = spectra.copy()\n",
    "spectra = temp_spec.iloc[:,150:2051].copy()\n",
    "spectra.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e47df423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 1898, 1899, 1900])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr_spec = spectra.copy()    \n",
    "row, col = spectra.shape\n",
    "x1 = np.arange (0, col, 1)\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76185608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range (0,5,1):\n",
    "#     spectra.iloc[i,:].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1acff7d",
   "metadata": {},
   "source": [
    "# Step 1b: Obtaining Targets (Outliers removal and Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58ad22bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_faulty\n",
    "# ------------- Target Isolation ----------------------\n",
    "\n",
    "clr = ['#F4A460', '#8B7355', '#A52A2A', 'green']\n",
    "\n",
    "def isolate_targets(df, target_names):\n",
    "    T=[]\n",
    "    for i in range (0,len(target_names)):\n",
    "        T.append(df[target_names[i]])\n",
    "    return(T)\n",
    "    \n",
    "T = isolate_targets(df,target_names) \n",
    "\n",
    "\n",
    "def normalize_targets(T):          \n",
    "    NT =[]\n",
    "    for i in range(0, len(T)):\n",
    "        NT.append(min_max_normal(T[i].copy()))\n",
    "    return(NT)\n",
    "\n",
    "NT = normalize_targets(T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd5b13f",
   "metadata": {},
   "source": [
    "# Step 1c: Spectra Preprocessing (Smooth, FOD/Contin, and Resample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aae8ec",
   "metadata": {},
   "source": [
    "## Savgol smoothing (order 1 and order 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99baabb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- Smoothed Spectra spec1 (savgol order 1) and spec2 (savgol order 2)  -----------\n",
    "\n",
    "spec1 = {}\n",
    "for i in window_lengths:\n",
    "    spec1[i] = filt_sg(spectra, i, 'sg1')                   \n",
    "\n",
    "spec2 = {}\n",
    "for i in window_lengths:\n",
    "    spec2[i] = filt_sg(spectra, i, 'sg2')\n",
    "\n",
    "smth_spec = sgsmooth (spectra, 3)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f253386c",
   "metadata": {},
   "source": [
    "## First Order Derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "385ba98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fod_spec = fod(smth_spec)\n",
    "\n",
    "for i in range (0,5,1):\n",
    "    fod_spec.iloc[i,:].plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f55420f",
   "metadata": {},
   "source": [
    "## Continuum Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e800b1b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "object arrays are not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cr_spec \u001b[38;5;241m=\u001b[39m \u001b[43mcontinuum_removed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m51\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:30\u001b[0m, in \u001b[0;36mcontinuum_removed\u001b[0;34m(spectra)\u001b[0m\n",
      "File \u001b[0;32m<string>:7\u001b[0m, in \u001b[0;36mcontinuum_removal\u001b[0;34m(points, show)\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scipy/interpolate/_polyint.py:79\u001b[0m, in \u001b[0;36m_Interpolator1D.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    Evaluate the interpolant\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m \n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     x, x_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_x\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate(x)\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finish_y(y, x_shape)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scipy/interpolate/_polyint.py:91\u001b[0m, in \u001b[0;36m_Interpolator1D._prepare_x\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prepare_x\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;124;03m\"\"\"Reshape input x array to 1-D\"\"\"\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_validated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_inexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m     x_shape \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mravel(), x_shape\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scipy/_lib/_util.py:255\u001b[0m, in \u001b[0;36m_asarray_validated\u001b[0;34m(a, check_finite, sparse_ok, objects_ok, mask_ok, as_inexact)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m objects_ok:\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 255\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject arrays are not supported\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m as_inexact:\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(a\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minexact):\n",
      "\u001b[0;31mValueError\u001b[0m: object arrays are not supported"
     ]
    }
   ],
   "source": [
    "cr_spec = continuum_removed(spec2[51])\n",
    "\n",
    "# for i in range (0,5,1):\n",
    "#     cr_spec.iloc[i,:].plot()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88485b75",
   "metadata": {},
   "source": [
    "## Resampling (n_bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3293312",
   "metadata": {},
   "source": [
    "### 1. Sampled Original (sampled_spec: sampled clipped_spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f516492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_spec = {}\n",
    "for n in nbands_sampling:\n",
    "    sampled_spec[n] = resample_spectra (spec2[51], n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e039a42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range (0,5,1):\n",
    "#     sampled_spec[200].iloc[i,:].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b556f5a",
   "metadata": {},
   "source": [
    "### 2. Sampled Continuum Removed  (sampled_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fab45619",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cr_spec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m sampled_cr \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m nbands_sampling:\n\u001b[0;32m----> 3\u001b[0m     sampled_cr[n] \u001b[38;5;241m=\u001b[39m resample_spectra (\u001b[43mcr_spec\u001b[49m, n)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cr_spec' is not defined"
     ]
    }
   ],
   "source": [
    "sampled_cr = {}\n",
    "for n in nbands_sampling:\n",
    "    sampled_cr[n] = resample_spectra (cr_spec, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de689267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range (0,5,1):\n",
    "#     sampled_cr[200].iloc[i,:].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822eed90",
   "metadata": {},
   "source": [
    "### 3. Sampled FOD  (sampled_fod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd32e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_fod = {}\n",
    "for n in nbands_sampling:\n",
    "    sampled_fod[n] = resample_spectra (fod_spec, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaa74eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,10,1):\n",
    "    sampled_fod[200].iloc[i,:].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad37e7ab",
   "metadata": {},
   "source": [
    "## Visualizing Processed Spectrum (variable samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc8344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spec (sample, process):\n",
    "    x1 = spec2[51].iloc[sample,:]\n",
    "    x1.plot()\n",
    "    if process == 'continuum':\n",
    "        x2 = cr_spec.iloc[sample,:]\n",
    "        x2.plot()\n",
    "    else: \n",
    "        x3 = fod_spec.iloc[sample,:]*100\n",
    "        \n",
    "        x3.plot()\n",
    "    plt.ylim([-0.6, 0.8])\n",
    "\n",
    "ipywidgets.interact(plot_spec, sample = (0, 293,1), process = ['fod', 'continuum'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12f62f4",
   "metadata": {},
   "source": [
    "## Correlation between wavelengths and Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd230431",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(['science','notebook','grid'])\n",
    "\n",
    "def plot_corr (target, spec_cr_fod, n_bands):\n",
    "    \n",
    "    i = target_names.index(target)    \n",
    "    \n",
    "    if  spec_cr_fod == 'spec':\n",
    "        r_val, p_val = find_rpval (resample_spectra(spec2[51], n_bands), T[i])\n",
    "        r_val.iloc[0,:].plot(color = clr[i])\n",
    "    elif  spec_cr_fod == 'cr':\n",
    "        r_cr, p_cr = find_rpval (resample_spectra(cr_spec, n_bands), T[i])\n",
    "        r_cr.iloc[0,:].plot(color = clr[i])\n",
    "    else:\n",
    "        r_fod, p_fod = find_rpval (resample_spectra(fod_spec, n_bands), T[i])\n",
    "        r_fod.iloc[0,:].plot(color = clr[i])\n",
    "    \n",
    "    plt.ylim([-0.7, 0.7])\n",
    "\n",
    "ipywidgets.interact(plot_corr, target = target_names, spec_cr_fod = ['spec', 'cr','fod'], n_bands = nbands_sampling)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00e07ff",
   "metadata": {},
   "source": [
    "# Step 2:  Parameters for Best Train-Test Split  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1300a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Mtree (Model Tree) ----------------------------------\n",
    "\n",
    "tst_siz = 0.20\n",
    "\n",
    "rand_t = [None] * (len(T))\n",
    "err_t = [None] * (len(T))\n",
    "\n",
    "print('Without Normalization:')\n",
    "for i in range (0,len(T)):\n",
    "    rand_t[i], err_t[i] = best_split(spectra.copy(), T[i], tst_siz) \n",
    "    print ('For '+ target_names[i]+ ' :test size =', tst_siz, '\\t min bin error=', err_t[i], '\\t at randome state =', rand_t[i])\n",
    "    \n",
    "rand_nt = [None] * (len(T))\n",
    "err_nt = [None] * (len(T))\n",
    "\n",
    "print('After Normalization:')\n",
    "for i in range (0,len(T)):\n",
    "    rand_nt[i], err_nt[i] = best_split(spectra.copy(), NT[i], tst_siz)     \n",
    "    print ('For '+ target_names[i]+ ' :test size =', tst_siz, '\\t min bin error=', err_nt[i], '\\t at randome state =', rand_nt[i])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e853a50",
   "metadata": {},
   "source": [
    "# Step 3: Parameters for Best Model Fit "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d531478b",
   "metadata": {},
   "source": [
    "## PLSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311d0c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "def best_param_PLSR (X_train, X_test, y_train, y_test, n_comp):\n",
    "        \n",
    "    iqrpL = []\n",
    "#     r2L = []\n",
    "#     rpdL = []\n",
    "    \n",
    "    for n in range(1,n_comp):\n",
    "        Model = PLSRegression(n_components=n, scale=True)\n",
    "        Model.fit(X_train, y_train)\n",
    "        y_pred = Model.predict(X_test, copy=True)\n",
    "        \n",
    "        iqrp_test = find_iqrp(y_pred, y_test)\n",
    "#         r2_test = find_r2(y_pred, y_test)         \n",
    "#         rpd_test = find_rpd(y_pred, y_test)\n",
    "               \n",
    "        iqrpL.append(iqrp_test)\n",
    "#         r2L.append(r2_test)\n",
    "#         rpdL.append(rpd_test)\n",
    "                \n",
    "    \n",
    "    IQRP = max(iqrpL)\n",
    "    n_iqrp = iqrpL.index(max(iqrpL))+1\n",
    "#     R2 = max(r2L)     \n",
    "#     n_r2 = r2L.index(R2)+1    \n",
    "#     RPD = max(rpdL)\n",
    "#     n_rpd = rpdL.index(RPD)+1\n",
    "    \n",
    "    #print('IQRP :', IQRP,  'R2 :', R2,  '>>> n_comp: ', n_iqrp)    \n",
    "    return (n_iqrp)\n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d908099c",
   "metadata": {},
   "source": [
    "# Step 4: Building Model Tree (Mtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07468618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('say \"your program has finished\"')\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a97c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Available machine learning regression models --------------------------------- (7)\n",
    "ml_methods = ['mult', 'plsr', 'randomforest', 'cubist', 'svr', 'ridge', 'gbrt']\n",
    "#ml_methods = ['mult', 'plsr', 'cubist', 'randomforest', 'ridge' 'gbrt', 'svr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d247b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n_comp = 5\n",
    "\n",
    "def build_tree_for (method_name):\n",
    "    tree ={}\n",
    "    start = time.time()\n",
    "    m = method_name\n",
    "    #-- code to build tree----\n",
    "    for t in target_names:\n",
    "        print('tree for: '+ m +' ------> running on: ' + t)\n",
    "        tree[t] ={}\n",
    "        for tp in prepare_target:\n",
    "            tree[t][tp] ={}\n",
    "            for n in nbands_sampling:\n",
    "                tree[t][tp][n] ={}\n",
    "                for p in prepare_spec:\n",
    "                    tree[t][tp][n][p] ={}\n",
    "                    Y = tree[t][tp][n][p]\n",
    "                    \n",
    "                        \n",
    "                    #------ setting spec to appropriate (sampled) spectra----\n",
    "                    if p == 'none':\n",
    "                        if n == 0:\n",
    "                            if m == 'randomforest' or m == 'cubist' or m == 'gbrt':\n",
    "                                #---- reched here due to tree based methods e.g. randomforest--\n",
    "                                spec = sampled_spec[100]\n",
    "                            else:\n",
    "                                spec = spec2[51]\n",
    "                        else:\n",
    "                            #---- reached here with some n!=0----\n",
    "                            spec = sampled_spec[n]\n",
    "                        \n",
    "                    elif p == 'fod':\n",
    "                        if n == 0:\n",
    "                            if m == 'randomforest' or m == 'cubist' or m == 'gbrt':\n",
    "                                #---- reched here due to tree based methods e.g. randomforest--\n",
    "                                spec = sampled_fod[100]\n",
    "                            else:\n",
    "                                spec = fod_spec\n",
    "                        else:\n",
    "                            #---- reached here with some n!=0----\n",
    "                            spec = sampled_fod[n]\n",
    "                                \n",
    "                    else:  \n",
    "                        if n == 0:\n",
    "                            if m == 'randomforest' or m == 'cubist' or m == 'gbrt':\n",
    "                                #---- reched here due to tree based methods e.g. randomforest--\n",
    "                                spec = sampled_cr[100]\n",
    "                            else:\n",
    "                                spec = cr_spec\n",
    "                        else:\n",
    "                            #---- reached here with some n!=0----\n",
    "                            spec = sampled_cr[n]\n",
    "                        \n",
    "                    #---- target selection and normalization ---\n",
    "                    if tp == 'none':\n",
    "                        y = T[target_names.index(t)]\n",
    "                        rand_n = rand_t[target_names.index(t)]  #-- for future use in train-test split\n",
    "                    else:\n",
    "                        y = NT[target_names.index(t)]\n",
    "                        rand_n = rand_nt[target_names.index(t)] #-- for future use in train-test split\n",
    "                        #print('one more target set')\n",
    "                            \n",
    "                    #---- performing train-test split----------------------\n",
    "                    X_train, X_test, y_train, y_test = train_test_split(spec, y, test_size= tst_siz, random_state=rand_n)\n",
    "                        \n",
    "                        \n",
    "                    #------INITIATING the appropriate models-----------------------------------------------\n",
    "                    #----- PLSR: best parameters, fitting, and prediction\n",
    "                    if m == 'plsr':\n",
    "                        n_com = best_param_PLSR (X_train, X_test, y_train, y_test, max_n_comp)\n",
    "                        Y['n_comp'] = n_com\n",
    "                        Model = PLSRegression(n_components=n_com, scale=True)\n",
    "                    #----- MULTILINEAR:  fitting, and prediction---------- \n",
    "                    elif m == 'mult':\n",
    "                        Model = linear_model.LinearRegression()    \n",
    "                    #----- RANDOM_FOREST:   fitting, and prediction---------- \n",
    "                    elif m == 'randomforest': \n",
    "                        Model = RandomForestRegressor(random_state= 23)    \n",
    "                    #----- CUBIST REGRESSION:    fitting and prediction---------\n",
    "                    elif m == 'cubist':\n",
    "                        Model = Cubist(n_rules = 50, n_committees = 5, random_state = 42)    \n",
    "                    #------ SUPPORT VECTOR MACHINE FOR REGRESSION: fitting and prediction-----------      \n",
    "                    elif m == 'svr': \n",
    "                        Model = SVR()\n",
    "                    #------ RIDGE REGRESSION: fitting and prediction-----------      \n",
    "                    elif m == 'ridge': \n",
    "                        Model = KernelRidge()\n",
    "                    #------ GRADIENT BOOSTING REGRESSION: fitting and prediction-----------      \n",
    "                    else: \n",
    "                        Model = GradientBoostingRegressor()                         \n",
    "                        \n",
    "                    Model.fit(X_train, y_train)\n",
    "                    y_pred = Model.predict(X_test)\n",
    "                    yhat_pred = Model.predict(X_train)\n",
    "                                \n",
    "                    Y['test'] = y_test\n",
    "                    Y['testP'] = y_pred\n",
    "                    Y['train'] = y_train\n",
    "                    Y['trainP'] = yhat_pred\n",
    "                    Y['iqrp_test'] = find_iqrp(y_pred, y_test)\n",
    "                    Y['r2_test'] = find_r2(y_pred, y_test)\n",
    "                    Y['rpd_test'] = find_rpd(y_pred, y_test)\n",
    "                    Y['rmse_test'] = find_rmse(y_pred, y_test)\n",
    "                                                                \n",
    "                                                                         \n",
    "    end = time.time()                            \n",
    "    os.system('say \"your program has finished\"')                            \n",
    "\n",
    "    print('End time - Start time =', (end-start)) \n",
    "    \n",
    "    return (tree.copy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbe7179",
   "metadata": {},
   "source": [
    "## Mtree initialisation (do not run below code every time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc012ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mtree ={}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d3136d",
   "metadata": {},
   "source": [
    "## Creating different branches of Mtree (for separate methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e879891",
   "metadata": {},
   "source": [
    "### PLSR Branch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c34738",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mtree['plsr'] = build_tree_for ('plsr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e6ce3a",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02641a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mtree['mult'] = build_tree_for ('mult')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9d0acc",
   "metadata": {},
   "source": [
    "\n",
    "### Random Forest Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867391a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mtree['randomforest'] = build_tree_for ('randomforest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4358d9",
   "metadata": {},
   "source": [
    "### SVM Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfe29be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mtree['svr'] = build_tree_for ('svr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e189c3",
   "metadata": {},
   "source": [
    "### GBRT Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6139101",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mtree['gbrt'] = build_tree_for ('gbrt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ff0fb2",
   "metadata": {},
   "source": [
    "### Ridge Regression Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93db53ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mtree['ridge'] = build_tree_for ('ridge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee13435",
   "metadata": {},
   "source": [
    "### Cubist Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062e07b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mtree['cubist'] = build_tree_for ('cubist')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e1faa5",
   "metadata": {},
   "source": [
    "## Best of all worlds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04241275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model_parameters (Mtree, target, method, scorer):\n",
    "    t=target\n",
    "    m= method\n",
    "    \n",
    "    best_score = -1\n",
    "    best_n_comp = 'NA'\n",
    "    \n",
    "    \n",
    "    for tp in prepare_target:\n",
    "        for n in nbands_sampling:\n",
    "            for p in prepare_spec:\n",
    "                Y = Mtree[m][t][tp][n][p]\n",
    "                    \n",
    "                if scorer == 'iqrp':\n",
    "                    cur_score = Y['iqrp_test']\n",
    "                elif scorer == 'rpd':\n",
    "                    cur_score = Y['rpd_test']\n",
    "                else:\n",
    "                    cur_score = Y['r2_test']  \n",
    "                    \n",
    "                if cur_score > best_score:\n",
    "                    best_score = cur_score\n",
    "                    best_tp = tp\n",
    "                    best_n = n\n",
    "                    best_p = p\n",
    "                    if m == 'plsr':\n",
    "                        best_n_comp = Y['n_comp']\n",
    "                            \n",
    "    param_list = [scorer, np.round(best_score,2), 'Spec Prc:', best_p, 'n_bands:', best_n, 'Tar Prc:', best_tp, 'n_comp: ', best_n_comp]                                 \n",
    "    return (param_list)                                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8e5bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_score_for (Mtree, target, scorer):\n",
    "    \n",
    "    for method in ml_methods:\n",
    "        param_list= best_model_parameters (Mtree, target, method, scorer)\n",
    "        print('For:'+target+'->', param_list, ':'+method)\n",
    "     \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b948ff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score_for(Mtree, 'sand', 'iqrp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41642a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score_for(Mtree, 'sand', 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d73321",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score_for(Mtree, 'TOC', 'iqrp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd50f3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score_for(Mtree, 'TOC', 'r2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe74d829",
   "metadata": {},
   "source": [
    "## Plotting Model Accuracy (ipywidgets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd90a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_acc (target, target_preprocessing, spec_preprocessing, n_bands, method):\n",
    "    \n",
    "    m = method\n",
    "    t = target\n",
    "    \n",
    "    i = target_names.index(target)\n",
    "    \n",
    "    \n",
    "    p = spec_preprocessing\n",
    "    n = n_bands\n",
    "    tp = target_preprocessing\n",
    "    \n",
    "    Y = Mtree[m][t][tp][n][p]\n",
    "    \n",
    "    y_test = Y['test']\n",
    "    y_pred = Y['testP']\n",
    "    y_train = Y['train']\n",
    "    yhat_pred = Y['trainP']\n",
    "    \n",
    "    if m == 'plsr':\n",
    "        n_com = Y['n_comp']\n",
    "        y_pred = y_pred[:,0]\n",
    "        yhat_pred = yhat_pred[:,0]\n",
    "    \n",
    "    \n",
    "    iqrp_test = Y['iqrp_test']\n",
    "    r2_test = Y['r2_test']\n",
    "    rpd_test = Y['rpd_test']\n",
    "    \n",
    "    iqrp_train = find_iqrp(yhat_pred, y_train)\n",
    "    r2_train = find_r2(yhat_pred, y_train)\n",
    "    rpd_train = find_rpd(yhat_pred, y_train)\n",
    "    \n",
    "    y_tp = pd.DataFrame({'actual':y_test.values, 'predic': y_pred})\n",
    "    z = np.polyfit(y_test, y_pred, 1)\n",
    "    \n",
    "    yhat_tp = pd.DataFrame({'actual':y_train.values, 'predic': yhat_pred})\n",
    "    zhat = np.polyfit(y_train, yhat_pred, 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(1,2, figsize=(18,8))\n",
    "    \n",
    "    #with plt.style.context(('ggplot')): ---- PLOT of test-prediction --------------------------------------\n",
    "    y_tp.plot.scatter(ax= axes[0], x=\"actual\", y=\"predic\", alpha=0.8, color = clr[i], edgecolors='k')\n",
    "    axes[0].plot(y_test, np.polyval(z, y_test),  c='blue', linewidth=1)\n",
    "    axes[0].plot(y_test, y_test, color='green', linewidth=1)\n",
    "    axes[0].tick_params(axis='both', labelsize=10)\n",
    "    axes[0].text(0.05, 0.95, target_names[i]+' (Test Data)', transform=axes[0].transAxes, fontsize = 20, color = clr[i])\n",
    "    axes[0].text(0.05, 0.90, 'IQRP ={:.2f}'.format(iqrp_test), transform=axes[0].transAxes, fontsize = 16)\n",
    "    axes[0].text(0.05, 0.85, 'RPD ={:.2f}'.format(rpd_test), transform=axes[0].transAxes, fontsize = 16)\n",
    "    axes[0].text(0.05, 0.80, 'R2 ={:.2f}'.format(np.round(r2_test,3)), transform=axes[0].transAxes, fontsize = 16)\n",
    "    axes[0].text(0.95, 0.15, 'Method: '+method, transform=axes[0].transAxes, \n",
    "                    horizontalalignment='right', fontsize = 20)\n",
    "    \n",
    "    if method == 'plsr':\n",
    "        axes[0].text(0.95, 0.05, 'n_component={:.2f}'.format(n_com), transform=axes[0].transAxes, \n",
    "                    horizontalalignment='right', fontsize = 12)\n",
    "    \n",
    "    #---------------------------------- ---- PLOT of train-prediction --------------------------------------\n",
    "    yhat_tp.plot.scatter(ax= axes[1], x=\"actual\", y=\"predic\", alpha=0.8, color = clr[i], edgecolors='k')\n",
    "    axes[1].plot(y_train, np.polyval(zhat, y_train),  c='blue', linewidth=1)\n",
    "    axes[1].plot(y_train, y_train, color='green', linewidth=1)\n",
    "    axes[1].tick_params(axis='both', labelsize=10)\n",
    "    axes[1].text(0.05, 0.95,  target_names[i]+' (Training Data)', transform=axes[1].transAxes,fontsize = 20, color = clr[i])\n",
    "    axes[1].text(0.05, 0.90, 'IQRP ={:.2f}'.format(iqrp_train), transform=axes[1].transAxes, fontsize = 16)\n",
    "    axes[1].text(0.05, 0.85, 'RPD ={:.2f}'.format(rpd_train), transform=axes[1].transAxes, fontsize = 16)\n",
    "    axes[1].text(0.05, 0.80, 'R2 ={:.2f}'.format(np.round(r2_train,3)), transform=axes[1].transAxes, fontsize = 16)\n",
    "    axes[1].text(0.95, 0.15, 'Method: '+method, transform=axes[1].transAxes, \n",
    "                    horizontalalignment='right', fontsize = 20)\n",
    "    return    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b9db47",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipywidgets.interact(plot_model_acc, target = target_names,target_preprocessing = prepare_target, \\\n",
    "                    method = ml_methods, spec_preprocessing = prepare_spec, n_bands = nbands_sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2593d17e",
   "metadata": {},
   "source": [
    "## Random Forest Regression (Hypertuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72673414",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg = RandomForestRegressor(random_state= 23)  \n",
    "\n",
    "# #to generate various random forests.\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 10, stop = 50, num = 10)]\n",
    "# max_depth = [int(x) for x in np.linspace(3, 4, num = 2)]\n",
    "# max_features = ['log2', 'sqrt']\n",
    "# min_samples_split = [3, 5, 8]\n",
    "\n",
    "# # Create the random grid\n",
    "# random_grid = {'n_estimators': n_estimators, 'max_depth': max_depth, 'max_features':max_features,\\\n",
    "#               'min_samples_split':min_samples_split}\n",
    "\n",
    "# print(random_grid)\n",
    "\n",
    "# scorer = make_scorer(r2_score, greater_is_better=True)\n",
    "# cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=23)\n",
    "# rf_random = RandomizedSearchCV(estimator=rf_reg, param_distributions = random_grid, cv = cv, n_iter = 300,\\\n",
    "#                             scoring=scorer, verbose=1, random_state = 10, error_score='raise', n_jobs=-1)\n",
    "\n",
    "t='sand'\n",
    "spec = sampled_cr[20]\n",
    "y = NT[target_names.index(t)]\n",
    "rand_n = rand_nt[target_names.index(t)]\n",
    "X_train, X_test, y_train, y_test = train_test_split(spec, y, test_size= tst_siz, random_state=rand_n)\n",
    "\n",
    "rf_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_reg.predict(X_test)\n",
    "y_pred = np.round(y_pred, 2)\n",
    "\n",
    "score_cv = r2_score(y_test, y_pred)\n",
    "print('Best R2 Score:', score_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c463b8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = X_train.iloc[:,[0,1,2,4,7,8,9,11,14,16,17,18,19]]\n",
    "X_test_new = X_test.iloc[:,[0,1,2,4,7,8,9,11,14,16,17,18,19]]\n",
    "\n",
    "rf_reg.fit(X_train_new, y_train)\n",
    "y_pred = rf_reg.predict(X_test_new)\n",
    "y_pred = np.round(y_pred, 2)\n",
    "\n",
    "score_cv = r2_score(y_test, y_pred)\n",
    "print('Best R2 Score:', score_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effd6cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "importance = rf_reg.feature_importances_ \n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    " print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bdd503",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf_random.best_estimator_)\n",
    "y_pred = rf_random.predict(X_test)\n",
    "y_pred = np.round(y_pred, 2)\n",
    "\n",
    "score_cv = r2_score(y_test, y_pred)\n",
    "print('Best R2 Score:', score_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8c3328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
