{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c173cf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openpyxl\n",
    "# !pip install imbalanced-learn\n",
    "# !pip3 install ipympl\n",
    "# !pip install shapely\n",
    "# !pip install SciencePlots \n",
    "# !pip install seaborn\n",
    "# !pip install tqdm\n",
    "# !pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22684781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scienceplots\n",
    "import os, sys\n",
    "from numpy import nan\n",
    "import re\n",
    "import ipympl\n",
    "# from IPython.core.display import display, HTML\n",
    "import ipywidgets\n",
    "import json\n",
    "from os import listdir\n",
    "import glob\n",
    "import math\n",
    "from IPython.display import Image, display, HTML\n",
    "from shapely.geometry import mapping\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, RepeatedKFold, cross_val_predict\n",
    "from sklearn.metrics import r2_score, mean_squared_error, precision_score, recall_score, mean_absolute_error, make_scorer\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, LeaveOneOut, cross_validate\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy import stats\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "pd.options.display.max_columns = 100\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "%matplotlib inline\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d6f0b7",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing (Spectra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f385b43",
   "metadata": {},
   "source": [
    "## Smoothing Filter ( First Order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e1d2441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input spectra as features\n",
    "\n",
    "def sgsmooth (spectrum,window):\n",
    "    filt_spec = spectrum.iloc[:,:].copy()\n",
    "    (row,col) = spectrum.shape\n",
    "    if row == 1:\n",
    "        print('you should have given spectra as a dataframe -- not series')\n",
    "    if window != 0:\n",
    "        for c in range (0,col):\n",
    "            if c>= window and c <= (col-window):      ## SAFE\n",
    "                filt_spec.iloc[:,c] = spectrum.iloc[:,(c-window):(c+window)].mean(axis=1).copy()\n",
    "            elif c < window and c <= (col-window):    ##  LEFT\n",
    "                filt_spec.iloc[:,c] = spectrum.iloc[:,0:(c+window)].mean(axis=1).copy()\n",
    "            elif c > (col-window) and c >= window:    ## RIGHT\n",
    "                filt_spec.iloc[:,c] = spectrum.iloc[:,(c-window):col].mean(axis=1).copy()\n",
    "            else:     ## LEFT & RIGHT  c < window and c > (col-window)\n",
    "                filt_spec.iloc[:,c] = spectrum.iloc[:, 0:col].mean(axis=1).copy()        \n",
    "    return (filt_spec.iloc[:,:].copy())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed4d4c2",
   "metadata": {},
   "source": [
    "## Smoothing Filter ( Savitzky Golay First and Second Order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aadaac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- Smoothing Spectra using sg1: (savgol order 1) and sg2: (savgol order 2)  -----------\n",
    "\n",
    "#--INPUT: window_len (should be odd positive integer), filt_type (should be 'sg1' or 'sg2')\n",
    "\n",
    "\n",
    "def filt_sg(spectra, window_len, filt_type):\n",
    "    sg = filt_type\n",
    "    w = window_len\n",
    "    \n",
    "    if sg == 'sg1':\n",
    "        if w ==0 or w == 1:\n",
    "            smth_spec = spectra.copy()   \n",
    "        else:\n",
    "            smth_spec = spectra.copy()\n",
    "            pd.DataFrame(savgol_filter(smth_spec, w, 1, axis=1), columns=smth_spec.columns, index=smth_spec.index)\n",
    "            \n",
    "    else:\n",
    "        if w ==0 or w == 1:\n",
    "            smth_spec = spectra.copy()   \n",
    "        else:\n",
    "            smth_spec = spectra.copy()\n",
    "            pd.DataFrame(savgol_filter(smth_spec, w, 2, axis=1), columns=smth_spec.columns, index=smth_spec.index)\n",
    "            \n",
    "    return (smth_spec)\n",
    "\n",
    "#--OUTPUT: smoothed spectra with same column names and row indices as original (input) spectra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52951a47",
   "metadata": {},
   "source": [
    "## First Order Derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4964477c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fod (spectra):\n",
    "    fo_spec = spectra.iloc[:,:].copy()\n",
    "    (row,col) = fo_spec.shape\n",
    "    \n",
    "    for i in range(0,col):\n",
    "        if i==col-1:\n",
    "            fo_spec.iloc[:,i] = fo_spec.iloc[:,i-1]\n",
    "        else:    \n",
    "            fo_spec.iloc[:,i] = (spectra.iloc[:,i+1]- spectra.iloc[:,i])\n",
    "        \n",
    "    #fo_spec = 100*fo_spec\n",
    "    return(fo_spec.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8166f002",
   "metadata": {},
   "source": [
    "## Continuum Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dff8a412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def continuum_removal(points, show=False):\n",
    "    x1, y1 = points.T\n",
    "    augmented = np.concatenate([points, [(x1[0], np.min(y1)-1), (x1[-1], np.min(y1)-1)]], axis=0)\n",
    "    hull = ConvexHull(augmented)\n",
    "    continuum_points = points[np.sort([v for v in hull.vertices if v < len(points)])]\n",
    "    continuum_function = interp1d(*continuum_points.T)\n",
    "    yprime = continuum_function(x1) - y1\n",
    "    #yprime = y1 / continuum_function(x1)\n",
    "\n",
    "    if show:\n",
    "        fig, axes = plt.subplots(2, 1, sharex=True)\n",
    "        axes[0].plot(x1, y1, label='Data')\n",
    "        axes[0].plot(*continuum_points.T, label='Continuum')\n",
    "        axes[0].legend()\n",
    "        axes[1].plot(x1, yprime, label='Data / Continuum')\n",
    "        axes[1].legend()\n",
    "\n",
    "    return yprime\n",
    "\n",
    "\n",
    "def continuum_removed(spectra):\n",
    "    cr_spec = spectra.copy()    \n",
    "    row, col = spectra.shape\n",
    "    x1 = np.arange (0, col, 1)\n",
    "    \n",
    "    \n",
    "    for r in range(0,row,1):\n",
    "        y1 = cr_spec.iloc[r,:]\n",
    "        points = np.c_[x1, y1]\n",
    "        yprime = continuum_removal(points, show=False)\n",
    "        cr_spec.iloc[r,:] = yprime\n",
    "        \n",
    "    return cr_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e58e754",
   "metadata": {},
   "source": [
    "## Resampling (n_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "951cc36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_spectra (spectra, n_band):\n",
    "    row, width = spectra.shape\n",
    "    if n_band == 0:\n",
    "        red_spectra = spectra.copy()\n",
    "    else:\n",
    "        w = width/n_band\n",
    "        \n",
    "        #----- obtaining the sampling locations in indx----\n",
    "        indx = []\n",
    "        for i in range (0,n_band,1):\n",
    "            indx.append(np.floor((i+0.5)*w))\n",
    "            \n",
    "        #------ applying smoothing filter on spectra---------\n",
    "        temp_smooth = sgsmooth (spectra, np.floor(0.5*w).astype(int))\n",
    "        \n",
    "        #------ picking values at sampling locations---------\n",
    "        red_spectra = temp_smooth.iloc[:, indx].copy()\n",
    "        \n",
    "    return (red_spectra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a81197",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing (Target Variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac8bf2e",
   "metadata": {},
   "source": [
    "## Z-score Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df07ba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score (target):\n",
    "    X = target.copy()\n",
    "    # outliers removal\n",
    "    mean = X.mean()\n",
    "    std = X.std()\n",
    "    X.loc[abs((X - mean)) >= 4*std] = mean\n",
    "    \n",
    "    X = (X-mean)/std\n",
    "    return (X.copy())\n",
    " \n",
    "\n",
    "# udf = pd.read_csv('uae.csv')\n",
    "# Y = lognormal (udf['TOC'].copy())\n",
    "# plt.hist(udf['TOC']/2.5, bins=98)\n",
    "# plt.show()\n",
    "# plt.hist(Y, bins=98)\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2fe9d7",
   "metadata": {},
   "source": [
    "## Standard Normalization (Log+MinMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92796a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normal (target):\n",
    "    X = target.copy()\n",
    "    # outliers removal\n",
    "    mean = X.mean()\n",
    "    std = X.std()\n",
    "    X.loc[abs((X - mean)) >= 4*std] = mean\n",
    "    # shift min to 1\n",
    "    m = X.min()\n",
    "    dis = (1-m)\n",
    "    X = X + dis    \n",
    "    # apply log transform\n",
    "    #X = np.log(X)    \n",
    "    # normalize/rescale using Min-Max method \n",
    "    minX = X.min()\n",
    "    maxX = X.max()\n",
    "    diff = maxX - minX\n",
    "    X = ((X-minX)*10)/diff    \n",
    "    return (X.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa24677",
   "metadata": {},
   "source": [
    "## Calculating Pearson Correlation Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c0f6d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson corelation between different wavelengths and Targets/Outputs (i.e, sand, clay, silt, and TOC) \n",
    "\n",
    "def find_rpval (spectra, tar):\n",
    "    (r, c) = spectra.shape\n",
    "    \n",
    "    r_val = spectra.iloc[[0], :].copy()\n",
    "    p_val = spectra.iloc[[0], :].copy()\n",
    "    \n",
    "    for j in range(0, c):\n",
    "        r_val.iloc[0,j], p_val.iloc[0,j] = stats.pearsonr(tar, spectra.iloc[:, j])\n",
    "    \n",
    "    return(r_val, p_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7e4f5e",
   "metadata": {},
   "source": [
    "# 3. Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f5be493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_split finds random state and minimum error for best train test split\n",
    "\n",
    "def best_split (X,y,tst_siz):\n",
    "    ymin = y.min()\n",
    "    ymax = y.max()\n",
    "    trn_siz = 1-tst_siz\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= tst_siz, random_state=0)\n",
    "    rand_st = 0\n",
    "    bin_train = np.histogram(y_train, bins = 8, range = (ymin,ymax), density=False)\n",
    "    bin_test = np.histogram(y_test, bins = 8, range = (ymin,ymax), density=False)\n",
    "    error = abs((bin_train[0])/trn_siz - (bin_test[0])/tst_siz)\n",
    "    cum_error = error.sum()\n",
    "    min_err= cum_error\n",
    "    \n",
    "    for i in np.arange(1,42,1):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= tst_siz, random_state=i)\n",
    "        bin_train = np.histogram(y_train, bins = 8, range = (ymin,ymax), density=False)\n",
    "        bin_test = np.histogram(y_test, bins = 8, range = (ymin,ymax), density=False)\n",
    "        error = abs((bin_train[0])/trn_siz - (bin_test[0])/tst_siz)\n",
    "        cum_error = error.sum()\n",
    "        if cum_error < min_err:\n",
    "            min_err = cum_error\n",
    "            rand_st = i\n",
    "            #print(i)\n",
    "\n",
    "    return (rand_st, min_err)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb36355",
   "metadata": {},
   "source": [
    "# 4. IQRP, RPD, R2, RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbcef815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_iqrp (Yp, Y):\n",
    "    mse = mean_squared_error(Yp, Y)\n",
    "    rmse = np.sqrt(mse)\n",
    "    X = Y.copy()\n",
    "    l = len(X)\n",
    "    q1 = math.floor(l/4)\n",
    "    q3 = math.floor(3*l/4)\n",
    "    X = X.sort_values().reset_index(drop=True)\n",
    "    res = (X[q3] - X[q1])/rmse\n",
    "    return(res)\n",
    "\n",
    "def find_rpd (Yp, Y):\n",
    "    mse = mean_squared_error(Yp, Y)\n",
    "    rmse = np.sqrt(mse)\n",
    "    res = Y.std()/rmse\n",
    "    return(res)\n",
    "\n",
    "def find_r2 (Yp, Y):\n",
    "    res = r2_score(Y, Yp)\n",
    "    return(res)\n",
    "\n",
    "def find_rmse(Yp, Y):\n",
    "    res = np.sqrt(mean_squared_error(Y, Yp))\n",
    "    return(res)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd23ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
